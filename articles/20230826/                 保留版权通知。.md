
作者：禅与计算机程序设计艺术                    

# 1.简介
  

## 概念

本文将介绍一种无监督学习方法——谱聚类(Spectral Clustering)，其主要思想是在图论领域中，寻找“相似性”的局部结构，并将数据划分成几个互相不重叠的子集，使得每一个子集中的样本都是具有较强的内在相似性的。也就是说，一个样本距离另一个样本越远，那么它所属的类别就越相似；而两个样本距离第三个样本越近，那么它们之间的类别差异就越大。

## 模型

### 数据表示

对无标签的数据进行谱聚类，可以把数据看作一张图(graph)的形式。图的每个节点表示一个样本，两两节点之间如果存在边连接，则表示这两者之间存在某种关系，如：相似、相关等。由于聚类分析的目标是建立每个样本到其他样本的“连接网络”，所以谱聚类是一种基于图论的无监督学习模型。

如何用矩阵表示图？假设有n个节点，记作$X=(x_i)$, i=1,...,n。对于任意两个节点$i$和$j$(i\neq j), 设其边权重为$W_{ij}$，可以用邻接矩阵A的形式表达这种关系:

$$ A=\begin{bmatrix}
 W_{11}&W_{12}&...&W_{1n}\\
 W_{21}&W_{22}&...&W_{2n}\\
...\\
 W_{n1}&W_{n2}&...&W_{nn}\end{bmatrix}$$ 

其中$W_{ij}$表示节点$i$和节点$j$之间的边权重。可以证明：若$G$是一个$n$节点的连通无向图，则$\lambda = \frac{2}{n} \sum_{i}^{n} \sigma_{ii}$, 其中$\sigma_{ii}$为节点$i$的特征值。因此，节点的特征向量可以表示为：

$$ x_i=\frac{1}{\sqrt{\lambda}}\begin{pmatrix}u_i \\ v_i \end{pmatrix},$$ 

其中$u_i$和$v_i$分别是节点$i$的左右特征向量。

### 图的连通性

谱聚类的输入是一个带权重的图(graph)。由于聚类问题的特点，一般情况下，输入数据应当是无向连通图，否则无法进行有效的聚类。

在构建初始图时，可以先对节点间的距离进行预处理，如：欧氏距离、切比雪夫距离等，然后按照距离的大小构造出邻接矩阵。但在实际应用中，可以考虑采用更为复杂的图生成算法，如：独立随机游走(ISRW)、Preferential Attachment模型等。

### 谱聚类

已知图的邻接矩阵$A$和特征向量$x_i$，如何通过图论的方法找到相应的类别划分呢?

首先，通过最小化拉普拉斯近似函数，求取节点的度矩阵$D$:

$$ D = \sum_{i<j}A_{ij}. $$

然后，通过K-means算法得到初始类别划分$c_k$, 这里选择的类别数目可以是预定义的也可以是自适应的。

之后，根据节点的特征向量及类别中心，计算图的特征矩阵F：

$$ F=\begin{bmatrix}
f_1^T\\
f_2^T\\
...\\
f_k^T\end{bmatrix}, \quad f_k = c_k. x_k, k=1,2,...,k.$$

这里，$f_k$ 是由类别$k$中所有节点的特征向量组成的行向量，且满足$\|f_k\|=1$. 根据拉普拉斯近似函数的性质，可知$f_k^TD^{-1/2}f_k\leqslant \|f_k\|\leqslant \frac{1}{\sqrt{|V|}}.$ 故有：

$$\max_{\|f_k\|=1} \|Af_k-\mu_k\|^2 + \frac{\lambda}{2} \left(\|f_k\|-1\right)^2.$$

为了求解该优化问题，可以使用遗传算法、梯度下降法或最速下降法。求解后得到类别中心的变换矩阵T：

$$ T = \frac{1}{\sqrt{|V|}}\begin{bmatrix}
t_{11}^T & t_{12}^T & \cdots & t_{1k}^T\\
t_{21}^T & t_{22}^T & \cdots & t_{2k}^T\\
\vdots   & \vdots   & \ddots & \vdots    \\
t_{k1}^T & t_{k2}^T & \cdots & t_{kk}^T 
\end{bmatrix}, \quad t_{ki}=h((x_k-c_k),(x_i-c_i)),$$

即：

$$ t_{ki}=h((x_k-\mu_k),(x_i-\mu_i)),$$

其中$h(\cdot,\cdot)$是核函数。 

最后，根据类别中心的变换矩阵及特征向量，可以计算每一个样本的类别概率分布：

$$ p_k(i)=e^{-\frac{1}{2}(x_i-t_{ik}^\dagger c_k)(A^TA+lI)^{-1}(x_i-t_{ik}^\dagger c_k)}$$ 

其中，$l>0$是正则化参数。注意：这里的求导是针对样本$i$的，而不是针对类别$k$的。

综上所述，谱聚类通过图的特征向量、类别中心、节点的特征向量及概率分布等信息，对样本进行了分类。