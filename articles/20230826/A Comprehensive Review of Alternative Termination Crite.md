
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Differential evolution (DE) is a popular black-box optimization algorithm that belongs to the family of stochastic population based optimization algorithms. It explores the search space by maintaining a population of candidate solutions and updating their positions in each iteration according to two basic rules: mutation and recombination. The mutation process introduces small random perturbations to the individuals, while the recombination combines the elements from different parent individuals to create new offspring. In this article we review several alternative termination criteria used in DE, including convergence criterion, fitness threshold, maximum number of iterations, time limit, and dynamic scaling. We also explain how these criteria can be applied to selectively terminate DE runs under various conditions such as early stopping or adaptive learning rate adaption. 

DE has been shown to perform well on a wide range of problems and it remains an effective tool for solving complex engineering optimization problems. However, some researchers have questioned its effectiveness when handling noisy objective functions due to the uncertainty introduced by non-deterministic nature of real world applications. Other criticisms include the lack of statistical rigorous analysis, limited ability to handle highly complex parameter spaces, high computational overhead due to frequent evaluations of objective function, and difficulty in tracking the convergence behavior across multiple generations. Despite these challenges, DE continues to serve as one of the most popular optimization techniques used in industry, academia, and research labs around the globe. Thus, there is a need to improve and advance DE's robustness, reliability, and applicability to more challenging real-world problems. This article aims to provide a comprehensive review of the available alternatives to traditional termination criteria used in DE, identify areas where current implementations could be improved, and suggest directions for future development.


In conclusion, the goal of this article was to present a detailed comparative study of the currently used alternative termination criteria for differential evolution (DE) algorithms, with the potential to identify areas where improvements are needed and provide suggestions for future work in improving DE's performance under noisy objective functions. These findings will allow researchers and engineers to choose appropriate termination criteria for their specific use cases and designs, leading to enhanced efficiency and better performance of DE. Moreover, since the relevant literature is vast and varied, authors should carefully read through all related references before making any critical decisions regarding DE's application in various scenarios. 


Keywords: differential evolution; termination criteria; noise; complexity; scalability; stability;

# 2.相关工作综述
Differential evolution (DE) is an optimization technique that belongs to the class of stochastic population based optimization algorithms. Population-based methods generate solutions iteratively by using a group of candidate solutions called a population. Each individual member of the population represents a possible solution, and they move through the search space by mutating and recombining other members of the population. Since the selection process relies on mathematical concepts such as probability distributions and roulette wheel method, DE is often referred to as a stochastic gradient descent method. As an optimization algorithm, DE operates under a variety of assumptions about the problem being optimized, which may result in suboptimal results for certain types of problems. To address this limitation, several variants of DE exist, which adjust the basic mutation and recombination operators to accommodate specific properties of the problem being solved. Additionally, state-of-the-art methods employ artificial intelligence techniques to guide the optimization process, which helps them avoid getting stuck in local optima. One widely used variant of DE known as asynchronous differential evolution (ADE) uses multiple processes or threads to speed up the computations and reduce the memory footprint. Nevertheless, ADE still falls short of the optimality guarantees provided by classic DE, particularly for large-scale problems. Therefore, further research is necessary to understand the relationship between these two approaches and how they can be combined together to form powerful optimization tools for practical applications. 

One of the key issues associated with DE is the choice of termination criteria. While traditional convergence criteria have been used for many years, recent works propose alternative termination criteria that can significantly enhance DE's performance. Examples of alternative termination criteria include fitness threshold, maximum number of iterations, time limit, and dynamic scaling. Fitness threshold terminates DE once the best solution found so far exceeds a predefined threshold value, enabling users to stop DE earlier if a satisfactory solution is achieved. Maximum number of iterations stops DE after a predetermined number of iterations regardless of whether a satisfactory solution has been reached. Time limit enables users to specify a maximum duration for DE to run, which can prevent it from running infinitely long and wasting resources unnecessarily. Dynamic scaling modifies the mutation step size dynamically during runtime depending on the progress of the optimization process. By doing so, DE can converge faster and find better solutions closer to the global optimum than traditional convergence criteria. 

However, while previous studies have proposed alternate termination criteria, little attention has been paid to identifying the right combination of criteria. In fact, the impact of selecting too few or too many termination criteria can vary dramatically, especially when dealing with noisy objective functions. This leads to confusion over which criteria should be considered important and which ones can be safely discarded without affecting the overall quality of the optimization process. In addition, despite the importance of thoroughly understanding DE's inner working mechanisms and limitations, most papers only briefly discuss these aspects without providing a concrete comparison among different termination criteria. To address this issue, several benchmarks were established to evaluate the performance of various termination criteria and measure their robustness and significance for a wide range of problems. Researchers focused on finding the tradeoff between sensitivity and specificity, i.e., choosing the set of termination criteria that minimizes the risk of missing the true minimum but maximizes the chance of ending the optimization prematurely. Unfortunately, although significant progress has been made towards developing better termination criteria for DE, there is still room for improvement.

Other research areas related to DE include multi-objective optimization, genetic programming, biology, finance, and marketing. In multi-objective optimization, DE has become increasingly popular for solving complex Pareto front problems, where multiple objectives must be simultaneously optimized. To solve this type of problem, a single DE instance cannot sufficiently explore the entire search space, and additional DE instances are required to focus on regions of the solution space that exhibit different tradeoffs among the objectives. Genetic programming (GP) is another branch of optimization that uses a similar approach to DE. Instead of directly optimizing a single target function, GP generates programs that mimic human language or natural languages. The generated code can then be evaluated against a test suite, enabling the discovery of faulty software components or vulnerabilities. Biology, finance, and marketing applications also involve optimization tasks, and several multiobjective DE frameworks have been developed recently to handle these types of problems efficiently. Despite these similarities, each area requires expertise and understanding beyond those involved in purely numerical optimization. Neverthethanher, this article focuses solely on the comparison of different termination criteria for DE and does not cover these other topics. Nonetheless, the comparison should highlight the essential similarities and differences between DE and related fields, indicating opportunities for cross-pollination of ideas and inspiring new directions for further research.



# 3.基本概念术语说明
## 3.1 DE概览
Differential evolution (DE) is a popular black-box optimization algorithm that belongs to the family of stochastic population based optimization algorithms. It explores the search space by maintaining a population of candidate solutions and updating their positions in each iteration according to two basic rules: mutation and recombination. The mutation process involves introducing small random perturbations to the individuals, while the recombination combines the elements from different parent individuals to create new offspring. DE typically applies a simple binary tournament selection operator to select parents for reproduction, a uniform crossover scheme to combine the characteristics of the selected parents, and a random mutation factor within a given range to introduce diversity into the population. Over the course of hundreds of iterations, DE converges to a local optimum that is expected to be a good approximation of the global optimum.

The main feature of DE is its ability to handle complex parameter spaces and fast convergence to efficient solutions. However, even though DE has proven itself successful in practice, it suffers from several drawbacks and limitations. For example, because DE is a stochastic optimization algorithm, its performance depends heavily on the initial population distribution and may not converge to the global optimum. Also, DE typically requires a large number of evaluation points to achieve satisfactory results, which can make it impractical for complicated engineering optimizations requiring millions or billions of evaluations per second. Finally, DE tends to converge very slowly compared to more advanced optimization techniques, such as particle swarm optimization or genetic algorithms.

To address these issues, several extensions and variations of DE have been proposed, including differential evolution variants that incorporate additional features such as adaptive mutation factors and population control strategies, novel mutation schemes, and alternate selection strategies. Despite these advances, there is still much to learn about how DE works internally and how to effectively apply it in real-world situations.

## 3.2 基本术语
### 3.2.1 Mutation Factor
Mutation factor refers to the degree of change introduced at each iteration by a particular mutation operation. In traditional DE, mutations operate on the position vector of a solution, adding a randomly chosen scalar multiple of a unit vector pointing in a random direction. The mutation factor determines how large the perturbations are, allowing users to control the extent of changes to the individuals in the search space. Larger values of the mutation factor lead to larger changes, while smaller values introduce less variance but potentially less exploration of the search space. 

### 3.2.2 Crossover Scheme
Crossover is a process where two parent individuals are combined to produce a child individual that inherits traits from both parent individuals. Traditional DE employs a binary crossover operator that selects pairs of parent individuals and swaps their gene segments according to a fixed ratio. Crossover allows DE to exploit information shared by both parent individuals, resulting in faster convergence and higher likelihood of finding better solutions.

### 3.2.3 Recombination Rate
Recombination rate refers to the frequency at which children are produced by combining parent genes. At each generation, DE randomly selects a subset of the population to undergo recombination, and performs recombination operations on the selected individuals to create offspring. Recombination is the primary mechanism by which DE maintains diversity in the population and encourages exploration of the search space. Larger values of the recombination rate increase the diversity of the population, but may lead to slower convergence rates and higher computation times.

### 3.2.4 Selection Strategy
Selection strategy refers to the rule used to determine which individuals in the population will be subject to recombination and mutation. In traditional DE, a binary tournament selection scheme is commonly used, which consists of two competitors competing to win the race by comparing their fitness scores. The fittest individual moves on to reproduce, while the least fit individual is replaced by another randomly sampled individual. Binary tournament selection is a simple yet efficient way to ensure that DE avoids the risk of converging to a local minimum instead of exploring the search space completely.

Additionally, other selection strategies such as linear ranking, tournament, and truncation selection can be used instead of binary tournament selection. Linear ranking involves assigning a rank to each individual based on their fitness score, and participants in the competition are ordered sequentially by rank until the top n% percentile is selected for reproduction. Tournament selection involves a group of randomly chosen participants competing to win, while truncation selection discards the bottom n% of individuals and only keeps the top n% for reproduction. Although these strategies provide additional flexibility and freedom to explore the search space, they may lead to slower convergence rates compared to traditional binary tournament selection.

## 3.3 标准化评价函数

对于不同的优化问题，标准化评价函数（scaled fitness function）可以帮助解决最优化问题。在标准化评价函数中，不仅将目标函数的指标范围映射到[0,1]之间，而且还把两个目标值之间的差距转换成了可比度，使得不同的目标值的贡献相等。这样做的原因是，不同目标值的重要性可能不同。例如，对于一个问题来说，某个目标函数比另一个目标函数更重要，但是两个目标值的大小关系却没有意义。因此，标准化评价函数正好用来衡量两者的相对重要性。


## 3.4 动态缩放

Dynamic scaling refers to the modification of the mutation factor or recombination rate over time based on the progress of the optimization process. Typically, DE adapts the mutation and recombination parameters by reducing or increasing them gradually throughout the optimization process. Dynamic scaling helps to maintain a balance between exploration and exploitation, which improves the performance of the algorithm. Another benefit of dynamic scaling is that it prevents DE from becoming trapped in local minima by continuously changing the mutation and recombination parameters. Overall, dynamic scaling provides a powerful tool for controlling the convergence behavior of DE and promoting diverse exploration of the search space.