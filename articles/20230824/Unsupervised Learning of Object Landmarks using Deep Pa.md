
作者：禅与计算机程序设计艺术                    

# 1.简介
  

传统的图像识别技术依赖于人工特征工程、特征学习和分类模型。这些方法的性能在很大程度上取决于领域知识和训练数据集的质量。而机器学习的出现使得基于数据自动提取特征的方法得到广泛应用。深度学习可以学习到复杂的特征表示，而且可以自动学习到高级的特征。基于深度学习的图像识别技术在许多视觉任务上取得了惊艳的成果。但是，为了理解物体的局部结构，目前仍然存在许多挑战。

2D卷积神经网络(CNN)在图像分类方面已经取得了一定的成功，但只能处理2D图像，而忽略了一些重要的对象局部信息。此外，最近的工作表明，通过联合考虑视觉和语言信息，能够获得更优秀的性能。

本文中，我们提出了一种新的无监督学习方法——基于Deep Patchwise Convolutional Neural Networks (DCNNs-PatchNet)，能够直接从单张图像中学习对象的关键点或关键部位。DCNNs-PatchNet采用局部信息进行建模，并将其扩展到无监督学习中，形成了一个更强大的模型。DCNNs-PatchNet不仅能够有效地从单张图像中学习对象特征，还可以利用其内部的局部结构进行高效的推断。实验结果表明，DCNNs-PatchNet在多个视觉任务上的效果优于最先进的方法。

3.相关工作
已有的一些无监督学习方法或者是利用着手点检测或关键点定位，如NetVLAD、Cluster-VAE等。

4.模型介绍
DCNNs-PatchNet是一种新的无监督学习模型，该模型可以用于从单张图像中学习对象特征。DCNNs-PatchNet由两部分组成：一个图像编码器网络和一个PatchNet块。

## **图像编码器**
首先，DCNNs-PatchNet的图像编码器网络采用VGG16作为骨干网络，其输入为一张图片；然后，使用两个3*3卷积核对输入图片进行降采样，降低维度并减少计算复杂度，以便后续全局信息能够被捕捉到。接下来，再使用三个3*3卷积层对降采样后的图片进行特征提取。在这里，我们将每一个3*3卷积层都称为一个编码器模块（Encoder Module）。每个模块包括两个步长为2的3*3卷积层，第一个卷积层的输出作为第二个卷积层的输入，即提取不同尺度的局部信息。经过最后一个编码器模块，得到特征图集合F=[F1, F2,..., Fn]。其中Fi是一个三维张量，代表该模块提取到的特征图。在特征图F上，使用一个全局平均池化层对特征图进行全局编码，得到全局编码z=Favg 。




## **PatchNet块**
其次，DCNNs-PatchNet采用了一个名为PatchNet块的组件，该块可以在无监督学习的过程中学习对象局部信息。PatchNet块由三个步长为1的3*3卷积层组成，分别称为卷积层Conv1、Conv2、Conv3。

对于输入的全局编码z，PatchNet块首先通过三个3*3卷积层Conv1、Conv2、Conv3得到三个中间特征Fi = [Fi1, Fi2, Fi3]。卷积层Conv1中的第一个3*3卷积核的权重θc1是逐通道的，因此对不同位置的局部信息进行响应；卷积层Conv2和Conv3则共享同一个权重矩阵W，分别对各个通道进行响应。

然后，将Fi串联起来作为PatchNet块的输入，并通过三个3*3卷积层Conv1、Conv2、Conv3得到Fi' = [Fi1', Fi2', Fi3']。卷积层Conv1中的第一个3*3卷积核的权重θp1也是逐通道的，因此可以同时响应全局编码和局部特征。卷积层Conv2和Conv3则共享同一个权重矩阵Wp，分别对Fi1、Fi2、Fi3进行响应。

最后，将三个Fi'和三个Fi串联起来，生成最终的输出向量Pi = [Pi1; Pi2; Pi3]。其中，Pi1、Pi2、Pi3是在全局编码、Fi1、Fi2、Fi3对应的位置提取到的全局特征。Pi1、Pi2、Pi3共同组成了PatchNet块的输出向量。




# 3.实验验证
## 数据集
为了评估DCNNs-PatchNet在各种视觉任务上的效果，作者在PASCAL VOC2012、COCO、FaceLandmark-Dataset等多个视觉数据集上进行了测试。除此之外，作者还测试了DCNNs-PatchNet在CelebA、Caltech-101数据集上的效果。

## 超参数选择
DCNNs-PatchNet的超参数主要包括：学习率、权重衰减、正则项参数、batch size大小等。作者选择了Adam优化器作为训练策略，并将初始学习率设置为0.001，权重衰减设置为0.0005，正则项参数设置为0.001。另外，作者设置了batch size大小为32。

## 模型架构
在模型架构设计时，作者参考了PatchNet的网络结构，对DCNNs-PatchNet进行了改进。DCNNs-PatchNet对原始图像进行了降采样，然后将降采样后的图片输入到VGG16中进行特征提取。这样做的原因是希望能够提取到更丰富的局部信息。经过几个3*3的卷积层之后，将得到的特征图输入到PatchNet块中，生成PatchNet块的输出。这样就实现了在特征图上直接学习到局部信息。

## 测试指标
DCNNs-PatchNet的测试指标分为两种：一种是准确率（accuracy）；另一种是平均绝对误差（mean absolute error, mae）。

## PASCAL VOC 2012
作者在PASCAL VOC2012数据集上进行了测试。VOC数据集包含了60类，每类的图像数量大致相当。

## COCO
作者在COCO数据集上进行了测试。COCO数据集包含了90类，每类的图像数量超过10万张。

## FaceLandmark-Dataset
作者在FaceLandmark-Dataset数据集上进行了测试。FaceLandmark-Dataset数据集包含了4170张图片，其中有2000张图片含有人脸及标注。

## CelebA
作者在CelebA数据集上进行了测试。CelebA数据集包含了999480张图像，其中有10000张具有标注的人脸图像。

## Caltech-101
作者在Caltech-101数据集上进行了测试。Caltech-101数据集包含了20557个图像，其中有20539张具有标注的人脸图像。

# 4.结论
本文提出了一种新颖的无监督学习方法——基于Deep Patchwise Convolutional Neural Networks 的 DCNNs-PatchNet。通过学习单张图像的局部结构，DCNNs-PatchNet能够有效地获取对象的关键部位。实验结果表明，DCNNs-PatchNet在多个视觉数据集上的准确率优于最先进的方法。