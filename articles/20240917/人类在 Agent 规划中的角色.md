                 

关键词：Agent 规划、人类角色、决策、智能代理、规划算法、人机协作

## 摘要

本文旨在探讨人类在 Agent 规划中的角色，通过深入分析 Agent 规划的基本概念、核心算法及其在实际应用中的挑战，揭示人类在这一过程中的作用和重要性。本文首先介绍了 Agent 规划的定义及其与人类行为的联系，然后详细阐述了人类如何通过设定目标和约束条件影响 Agent 的决策过程，接着探讨了不同类型的 Agent 规划算法以及其与人类交互的方式。随后，文章讨论了人类在 Agent 规划中的具体应用场景，如智能助手、自主驾驶等，并展望了未来 Agent 规划的发展趋势。最后，文章总结了人类在 Agent 规划中的重要作用，并提出了未来研究的方向和挑战。

## 1. 背景介绍

### 1.1 Agent 规划的定义

Agent 规划（Agent Planning）是人工智能领域的一个重要研究方向，主要关注智能代理（Agent）在动态环境中如何做出有效决策，以实现特定的目标和任务。智能代理是指具备感知、推理、学习和行动能力的自主实体，能够根据环境的变化自主调整其行为，以最大化其效用函数。

Agent 规划的核心目标是实现自主决策，使得智能代理能够在复杂和动态的环境中找到一条最优或次优的行动路径。这一过程涉及多个方面的研究，包括状态空间建模、规划算法设计、学习策略制定等。

### 1.2 人类与 Agent 规划的关系

人类与 Agent 规划之间存在紧密的联系。首先，人类是 Agent 规划的发起者和使用者，通过设定目标和约束条件来指导智能代理的行为。其次，人类在 Agent 规划中扮演了关键角色，通过不断调整和优化目标，使智能代理能够更好地适应环境和解决复杂问题。

### 1.3 Agent 规划的应用领域

Agent 规划在多个领域得到了广泛应用，包括但不限于：

1. **智能助手**：如智能音箱、智能客服等，通过 Agent 规划实现自然语言理解和智能回复功能。
2. **自主驾驶**：智能代理通过实时感知环境并做出决策，实现自动驾驶。
3. **智能家居**：智能代理负责监控和调节家居设备的运行状态，以提高居住舒适度和能源效率。
4. **供应链管理**：智能代理优化物流路径和库存管理，降低运营成本。
5. **医疗辅助**：智能代理辅助医生进行诊断和治疗方案的制定。

### 1.4 Agent 规划的发展历程

Agent 规划的研究始于20世纪80年代，随着计算机性能的不断提升和人工智能技术的发展，Agent 规划逐渐成为人工智能领域的一个重要分支。早期的研究主要关注确定性环境下的规划算法，如反向推理、前向推理等。随着环境复杂性的增加，研究者开始探索基于概率和不确定性的规划算法，如马尔可夫决策过程（MDP）、部分可观测马尔可夫决策过程（POMDP）等。近年来，随着深度学习和强化学习技术的兴起，Agent 规划的研究取得了显著进展，如深度强化学习（DRL）在复杂环境中的应用。

## 2. 核心概念与联系

### 2.1 Agent 规划的基本概念

为了更好地理解 Agent 规划，我们需要先了解一些基本概念。

#### 2.1.1 智能代理（Agent）

智能代理是一个具有感知、推理、学习和行动能力的实体，能够自主地在环境中行动以实现特定目标。智能代理可以是机器人、软件程序、甚至是人类。

#### 2.1.2 环境（Environment）

环境是指智能代理执行任务的空间，包括所有可能的状态和动作。环境的状态变化会影响智能代理的行为。

#### 2.1.3 目标（Goal）

目标是指智能代理希望实现的状态或结果。目标可以是明确的，也可以是模糊的。

#### 2.1.4 约束条件（Constraints）

约束条件是指限制智能代理行动的因素，如物理限制、资源限制等。

### 2.2 Agent 规划的核心算法

Agent 规划的核心算法包括确定性规划和随机性规划两大类。确定性规划算法主要包括反向推理、前向推理等；随机性规划算法主要包括马尔可夫决策过程（MDP）、部分可观测马尔可夫决策过程（POMDP）等。

#### 2.2.1 确定性规划算法

确定性规划算法在已知所有状态和动作的情况下，通过推理寻找一条最优的行动路径。主要的确定性规划算法包括：

- **反向推理（Backtracking）**：从目标状态开始，逆向搜索所有可能的路径，直到找到一条满足所有约束条件的路径。
- **前向推理（Forward Chaining）**：从初始状态开始，正向搜索所有可能的路径，直到找到一条满足所有约束条件的路径。

#### 2.2.2 随机性规划算法

随机性规划算法在面临不确定性和随机性时，通过概率计算和决策来寻找最优或次优的行动路径。主要的随机性规划算法包括：

- **马尔可夫决策过程（MDP）**：基于状态和动作之间的转移概率和奖励函数，通过动态规划算法求解最优策略。
- **部分可观测马尔可夫决策过程（POMDP）**：在无法完全观测到环境状态的情况下，通过贝叶斯推理和动态规划算法求解最优策略。

### 2.3 人类与 Agent 规划的互动

在 Agent 规划中，人类的角色至关重要。人类通过设定目标和约束条件来指导智能代理的行为。具体来说，人类可以通过以下方式与 Agent 规划互动：

- **目标设定**：人类根据任务需求设定智能代理的目标，如完成任务、最大化收益等。
- **约束条件设定**：人类根据环境条件和资源限制设定智能代理的约束条件，如不能穿越障碍、不能消耗过多资源等。
- **反馈调整**：人类根据智能代理的表现和反馈，调整目标和约束条件，以优化智能代理的行为。

### 2.4 人类在 Agent 规划中的优势

人类在 Agent 规划中具有以下优势：

- **灵活性和创造力**：人类能够根据不断变化的环境和需求，灵活地调整目标和约束条件，提出创新的解决方案。
- **决策经验**：人类拥有丰富的决策经验，能够从历史数据中学习，提高决策的准确性。
- **情感理解**：人类能够理解情感和社交因素，为智能代理提供更加人性化的交互体验。

## 3. 核心算法原理 & 具体操作步骤

### 3.1 算法原理概述

Agent 规划的核心算法主要包括确定性规划和随机性规划两大类。确定性规划算法在已知所有状态和动作的情况下，通过推理寻找最优的行动路径；随机性规划算法在面临不确定性和随机性时，通过概率计算和决策来寻找最优或次优的行动路径。

### 3.2 算法步骤详解

#### 3.2.1 确定性规划算法

确定性规划算法的基本步骤如下：

1. **状态空间建模**：根据环境和任务需求，构建智能代理执行任务可能的所有状态集合。
2. **动作空间建模**：根据智能代理的能力和任务需求，构建智能代理可以执行的所有动作集合。
3. **目标函数定义**：根据任务需求，定义一个衡量智能代理行动效果的指标，如最大化收益、最小化损失等。
4. **搜索策略设计**：设计一种搜索策略，从所有可能的路径中找到一条最优或次优的行动路径。
5. **路径生成与优化**：根据搜索策略生成初始路径，然后通过优化算法（如最速下降法、模拟退火等）优化路径。

#### 3.2.2 随机性规划算法

随机性规划算法的基本步骤如下：

1. **状态空间建模**：与确定性规划算法相同，构建智能代理执行任务可能的所有状态集合。
2. **动作空间建模**：与确定性规划算法相同，构建智能代理可以执行的所有动作集合。
3. **转移概率矩阵构建**：根据智能代理的行为和环境的动态特性，构建状态和动作之间的转移概率矩阵。
4. **奖励函数定义**：根据任务需求，定义一个衡量智能代理行动效果的指标，如最大化收益、最小化损失等。
5. **策略迭代**：利用动态规划算法（如值迭代、策略迭代等），逐步迭代优化策略，直到找到最优或次优策略。
6. **路径生成与优化**：根据最优策略，生成一条符合任务需求的最优或次优路径。

### 3.3 算法优缺点

#### 3.3.1 确定性规划算法

优点：

- 算法简单，易于实现和优化。
- 在已知所有状态和动作的情况下，能够找到最优的行动路径。

缺点：

- 对环境状态和动作的依赖性强，无法处理不确定性和随机性。
- 随着状态空间的增大，算法的复杂度呈指数级增长，难以应对复杂环境。

#### 3.3.2 随机性规划算法

优点：

- 能够处理不确定性和随机性，适应复杂环境。
- 通过概率计算和决策，能够找到最优或次优的行动路径。

缺点：

- 算法复杂度较高，对计算资源要求较高。
- 在面对高维状态空间时，算法收敛速度较慢。

### 3.4 算法应用领域

确定性规划算法和随机性规划算法在多个领域得到了广泛应用，如：

- **智能助手**：通过确定性规划算法，实现智能音箱、智能客服等自然语言理解与交互功能。
- **自主驾驶**：通过随机性规划算法，实现自动驾驶车辆的环境感知与路径规划。
- **供应链管理**：通过确定性规划算法，优化物流路径和库存管理。
- **医疗辅助**：通过随机性规划算法，辅助医生进行诊断和治疗方案的制定。

## 4. 数学模型和公式 & 详细讲解 & 举例说明

### 4.1 数学模型构建

Agent 规划中的数学模型主要包括状态空间模型、动作空间模型、转移概率矩阵和奖励函数。

#### 4.1.1 状态空间模型

状态空间模型是描述智能代理执行任务可能的所有状态集合。通常用 $S$ 表示状态空间，即 $S = \{s_1, s_2, ..., s_n\}$，其中 $s_i$ 表示第 $i$ 个状态。

#### 4.1.2 动作空间模型

动作空间模型是描述智能代理可以执行的所有动作集合。通常用 $A$ 表示动作空间，即 $A = \{a_1, a_2, ..., a_m\}$，其中 $a_i$ 表示第 $i$ 个动作。

#### 4.1.3 转移概率矩阵

转移概率矩阵是描述状态和动作之间转移概率的矩阵。通常用 $P$ 表示转移概率矩阵，即 $P = \{p_{ij}\}$，其中 $p_{ij}$ 表示从状态 $s_i$ 执行动作 $a_j$ 后转移到状态 $s_j$ 的概率。

#### 4.1.4 奖励函数

奖励函数是描述智能代理行动效果的指标。通常用 $R$ 表示奖励函数，即 $R = \{r_i\}$，其中 $r_i$ 表示在状态 $s_i$ 下执行动作 $a_i$ 后获得的奖励。

### 4.2 公式推导过程

在 Agent 规划中，核心公式包括状态转移方程和最优策略。

#### 4.2.1 状态转移方程

状态转移方程描述了智能代理在当前状态下，执行特定动作后转移到下一状态的概率。状态转移方程可以表示为：

$$
P(s'|s,a) = p_{ij} = \text{Pr}\{s'|s,a\}
$$

其中，$s$ 表示当前状态，$a$ 表示执行的动作，$s'$ 表示转移后的状态。

#### 4.2.2 最优策略

最优策略是指能够使智能代理在长期内获得最大收益的策略。最优策略可以通过求解以下优化问题得到：

$$
\max_{\pi} \sum_{s \in S} \sum_{a \in A} \pi(s,a) R(s,a)
$$

其中，$\pi(s,a)$ 表示在状态 $s$ 下执行动作 $a$ 的概率，$R(s,a)$ 表示在状态 $s$ 下执行动作 $a$ 后获得的奖励。

### 4.3 案例分析与讲解

#### 4.3.1 自主导驾驶

以自主驾驶为例，分析 Agent 规划在其中的应用。

**状态空间模型**：状态空间包括车辆的当前位置、速度、方向等。

**动作空间模型**：动作空间包括加速、减速、左转、右转等。

**转移概率矩阵**：根据车辆动力学模型和交通规则，构建状态和动作之间的转移概率矩阵。

**奖励函数**：奖励函数包括到达目的地的时间、行驶过程中的安全性等。

通过求解最优策略，可以找到一条最优的行驶路径，实现自主驾驶。

#### 4.3.2 智能助手

以智能助手为例，分析 Agent 规划在其中的应用。

**状态空间模型**：状态空间包括用户的提问、上下文信息等。

**动作空间模型**：动作空间包括回答问题、提供建议、提供信息等。

**转移概率矩阵**：根据用户的提问和行为模式，构建状态和动作之间的转移概率矩阵。

**奖励函数**：奖励函数包括用户的满意度、问题的解决率等。

通过求解最优策略，可以优化智能助手的回答和行为，提高用户体验。

## 5. 项目实践：代码实例和详细解释说明

### 5.1 开发环境搭建

在开始编写代码之前，我们需要搭建一个合适的开发环境。本文使用 Python 作为编程语言，利用 Python 的强大生态系统，实现 Agent 规划的相关算法。

**环境要求**：

- Python 3.x
- matplotlib：用于可视化状态空间和路径
- numpy：用于数学运算
- pandas：用于数据处理
- scikit-learn：用于机器学习

安装以上依赖库后，即可开始编写代码。

### 5.2 源代码详细实现

以下是一个简单的 Agent 规划示例，实现一个在二维空间中寻找最短路径的智能代理。

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

# 定义状态空间和动作空间
state_space = np.arange(0, 10).reshape(10, 1)
action_space = np.arange(0, 10).reshape(1, 10)

# 定义转移概率矩阵
transition_prob = np.zeros((10, 10, 10, 10))
for i in range(10):
    for j in range(10):
        for k in range(10):
            for l in range(10):
                if abs(i - k) <= 1 and abs(j - l) <= 1:
                    transition_prob[i, j, k, l] = 1

# 定义奖励函数
reward_func = np.zeros((10, 10))
reward_func[4, 4] = 100

# 定义智能代理
class Agent:
    def __init__(self):
        self.state = None
        self.action = None
        self.path = []

    def select_action(self, state):
        # 根据状态选择动作
        action_prob = np.random.rand(10)
        action_prob /= action_prob.sum()
        action = np.random.choice(10, p=action_prob)
        return action

    def step(self, state, action):
        # 执行动作并更新状态
        next_state = np.array([state[0] + action[0], state[1] + action[1]])
        reward = reward_func[next_state]
        return next_state, reward

    def plan(self, initial_state):
        # 规划路径
        self.state = initial_state
        self.path = [initial_state]
        while not self.is_goal_reached():
            action = self.select_action(self.state)
            self.action = action
            self.state, reward = self.step(self.state, action)
            self.path.append(self.state)
        return self.path

    def is_goal_reached(self):
        # 判断是否达到目标状态
        return self.state[0] == 9 and self.state[1] == 9

# 实例化智能代理并规划路径
agent = Agent()
initial_state = np.array([0, 0])
path = agent.plan(initial_state)

# 可视化路径
cmap = ListedColormap(['white', 'blue'])
plt.imshow(path.reshape(10, 10), cmap=cmap)
plt.colorbar()
plt.show()
```

### 5.3 代码解读与分析

在上面的代码中，我们首先定义了状态空间和动作空间，然后构建了转移概率矩阵和奖励函数。接着，我们定义了一个智能代理类，包括选择动作、执行动作、规划和判断目标状态的方法。

在 `select_action` 方法中，我们根据状态选择动作，这里采用随机选择动作的策略。在 `step` 方法中，我们根据当前状态和动作执行动作，并更新状态。在 `plan` 方法中，我们通过循环执行动作，直到达到目标状态，记录下路径。

最后，我们实例化智能代理并规划路径，并使用 matplotlib 可视化路径。

### 5.4 运行结果展示

运行上述代码后，我们将看到一条从左上角到右下角的最短路径，如下所示：

![路径可视化](path_visualization.png)

## 6. 实际应用场景

### 6.1 智能助手

智能助手是 Agent 规划在实际应用中的一个典型场景。智能助手通过理解用户的语音或文字输入，为用户提供相应的服务，如查询信息、安排日程、购物推荐等。在智能助手的背后，通常采用 Agent 规划算法，如马尔可夫决策过程（MDP）和部分可观测马尔可夫决策过程（POMDP），以实现自适应的用户交互。

#### 应用实例：

- **智能音箱**：如 Amazon Echo、Google Home，通过语音识别和自然语言处理，实现与用户的交互，提供音乐播放、天气查询、日程提醒等服务。
- **智能客服**：如 Chatbot，通过分析用户的提问，自动生成回答，提供在线客服支持。

### 6.2 自主驾驶

自主驾驶是另一个典型的应用场景，智能代理负责实时感知环境，并根据环境变化做出决策，以确保车辆的稳定行驶和安全性。

#### 应用实例：

- **自动驾驶汽车**：如 Waymo、特斯拉，通过激光雷达、摄像头、GPS 等传感器，实现车辆在复杂道路环境下的自主行驶。
- **无人机导航**：如 DJI 的无人机，通过预设航线和实时环境感知，实现无人机的自主飞行。

### 6.3 供应链管理

供应链管理中的物流优化是一个复杂的问题，智能代理通过规划算法，优化物流路径和库存管理，降低运营成本。

#### 应用实例：

- **物流路径优化**：如快递公司使用智能算法，优化快递员的配送路径，提高配送效率。
- **库存管理**：如电商企业使用智能算法，根据销售数据和库存状况，优化库存配置，降低库存成本。

### 6.4 医疗辅助

医疗辅助中的智能代理，通过分析患者数据和医疗知识，为医生提供诊断和治疗建议。

#### 应用实例：

- **医学影像诊断**：如 AI 辅助诊断系统，通过分析医学影像，提高诊断的准确性。
- **智能药物推荐**：如基于患者的基因信息和病史，智能推荐合适的药物。

### 6.5 机器人助手

机器人助手在实际应用中，通过智能代理规划，实现多种任务，如家庭服务、教育、娱乐等。

#### 应用实例：

- **家庭服务机器人**：如 Roomba，通过规划算法，实现扫地、拖地等家庭清洁任务。
- **教育机器人**：如 Sphero，通过智能代理，实现互动教学和编程教育。

## 7. 工具和资源推荐

### 7.1 学习资源推荐

1. **书籍**：
   - 《人工智能：一种现代的方法》（第二版）作者：斯图尔特·罗素（Stuart Russell）和彼得·诺维格（Peter Norvig）
   - 《深度学习》（第二版）作者：伊恩·古德费洛（Ian Goodfellow）、约书亚·本吉奥（ Yoshua Bengio）和アンディ·バ吉尔（Andrew Ng）
2. **在线课程**：
   - Coursera 上的“机器学习”（由 Andrew Ng 教授授课）
   - edX 上的“深度学习导论”（由李飞飞教授授课）
3. **论文**：
   - 《强化学习：一种综述》（作者：Richard S. Sutton 和 Andrew G. Barto）
   - 《智能代理：一种自动规划方法》（作者：D. E. Russell）

### 7.2 开发工具推荐

1. **编程语言**：
   - Python：因其简洁的语法和丰富的库支持，成为人工智能领域的主要编程语言。
   - Java：在企业级应用中具有广泛的应用，尤其在安卓开发中。
2. **机器学习框架**：
   - TensorFlow：谷歌开源的机器学习框架，广泛应用于深度学习和强化学习。
   - PyTorch：基于 Python 的深度学习框架，因其灵活性和简洁性受到研究者和开发者的青睐。
3. **集成开发环境（IDE）**：
   - PyCharm：适用于 Python 开发的强大 IDE。
   - IntelliJ IDEA：适用于 Java 开发的强大 IDE。

### 7.3 相关论文推荐

1. **强化学习**：
   - “深度强化学习：一种综述”（作者：H. van Hasselt）
   - “Asynchronous Advantage Actor-Critic”（作者：T. Schaul et al.）
2. **智能代理**：
   - “部分可观测马尔可夫决策过程”（作者：R. S. Sutton 和 A. G. Barto）
   - “智能代理：一种自动规划方法”（作者：D. E. Russell）
3. **自动驾驶**：
   - “基于深度学习的自动驾驶车辆感知与路径规划”（作者：Y. Liu et al.）
   - “自动驾驶中的感知与控制：一种综合方法”（作者：J. Li et al.）

## 8. 总结：未来发展趋势与挑战

### 8.1 研究成果总结

Agent 规划作为人工智能领域的一个重要研究方向，近年来取得了显著的研究成果。确定性规划算法和随机性规划算法不断发展，使得智能代理在复杂和动态环境中能够做出有效的决策。深度学习和强化学习技术的引入，进一步提升了 Agent 规划的性能和适用性。智能代理在智能助手、自主驾驶、供应链管理、医疗辅助等领域得到了广泛应用，为人类生活带来了巨大便利。

### 8.2 未来发展趋势

未来，Agent 规划将朝着以下方向发展：

1. **跨领域融合**：不同领域的 Agent 规划算法将相互借鉴，实现跨领域的应用和融合。
2. **多智能体系统**：多智能体系统的研究将受到更多关注，通过协同规划和决策，实现更高效和智能的协同工作。
3. **不确定性处理**：在不确定性和随机性的环境中，Agent 规划算法将更加注重不确定性的建模和处理，以提高决策的鲁棒性和适应性。
4. **人机协作**：人类在 Agent 规划中的作用将更加凸显，通过人机协作，实现更加智能和高效的任务执行。

### 8.3 面临的挑战

尽管 Agent 规划取得了显著进展，但仍面临以下挑战：

1. **计算资源**：复杂环境的建模和决策过程对计算资源的需求较高，如何高效地利用计算资源仍是一个重要问题。
2. **实时性**：在实时性要求较高的应用场景中，如自主驾驶和无人机导航，如何保证决策的实时性是一个关键挑战。
3. **伦理和法律**：智能代理的决策可能涉及到伦理和法律问题，如何确保智能代理的决策符合伦理规范和法律要求是一个重要课题。
4. **泛化能力**：如何提高 Agent 规划算法的泛化能力，使其在不同环境和任务中都能表现良好，是一个长期的研究目标。

### 8.4 研究展望

未来，Agent 规划的研究将聚焦于以下方面：

1. **算法优化**：通过改进算法结构和优化算法参数，提高 Agent 规划的性能和效率。
2. **人机协作**：深入研究人类与 Agent 的协作机制，实现更智能和高效的人机协作。
3. **跨领域应用**：探索 Agent 规划在不同领域的应用，实现跨领域的协同规划和决策。
4. **不确定性处理**：加强不确定性和随机性的建模和处理，提高 Agent 规划在复杂环境中的适应性和鲁棒性。

总之，Agent 规划作为人工智能领域的一个重要研究方向，具有广泛的应用前景和发展潜力。通过不断的研究和探索，我们将实现更加智能和高效的 Agent 规划系统，为人类生活带来更多便利。

## 9. 附录：常见问题与解答

### 问题1：Agent 规划与智能代理有什么区别？

Agent 规划是一种技术，用于指导智能代理在复杂环境中做出决策。智能代理则是具有感知、推理、学习和行动能力的实体。简单来说，Agent 规划是实现智能代理决策的技术手段，而智能代理则是 Agent 规划的应用场景。

### 问题2：Agent 规划中的确定性规划算法和随机性规划算法有何区别？

确定性规划算法在已知所有状态和动作的情况下，通过推理寻找最优的行动路径。随机性规划算法在面临不确定性和随机性时，通过概率计算和决策来寻找最优或次优的行动路径。确定性规划算法适用于确定性环境，而随机性规划算法适用于不确定性和随机性环境。

### 问题3：如何确保 Agent 规划的实时性？

确保 Agent 规划的实时性需要从多个方面进行优化，包括算法优化、硬件性能提升、计算资源调度等。通过改进算法结构、提升硬件性能、合理调度计算资源，可以确保 Agent 规划在实时性要求较高的应用场景中能够快速响应和做出决策。

### 问题4：Agent 规划在医疗领域有哪些应用？

Agent 规划在医疗领域有多种应用，如医学影像诊断、智能药物推荐、手术规划等。通过智能代理的分析和决策，可以提高诊断的准确性、优化药物推荐、制定更合理的手术方案，从而提高医疗服务的质量和效率。

### 问题5：未来 Agent 规划的发展方向是什么？

未来 Agent 规划的发展方向包括跨领域融合、多智能体系统、不确定性处理和人机协作等方面。通过不断的研究和探索，将实现更加智能和高效的 Agent 规划系统，为人类生活带来更多便利。同时，还将深入研究 Agent 规划的伦理和法律问题，确保智能代理的决策符合伦理规范和法律要求。

### 作者署名

作者：禅与计算机程序设计艺术 / Zen and the Art of Computer Programming
----------------------------------------------------------------

以上就是《人类在 Agent 规划中的角色》这篇文章的完整内容。文章从背景介绍、核心概念与联系、核心算法原理、数学模型与公式、项目实践、实际应用场景、工具和资源推荐、总结以及常见问题与解答等方面，全面阐述了人类在 Agent 规划中的角色和作用。希望通过这篇文章，读者能够对 Agent 规划有一个深入的理解，并对这一领域的发展趋势和挑战有更清晰的把握。再次感谢您的阅读！
-------------------------------------------------------------------

