
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Entity linking 是NLP领域的一个重要任务，它旨在将文本中的命名实体指代到其对应的实体资源（如知识库中的条目、页面）上。由于存在着多义词问题，使得这一任务成为信息检索和知识抽取领域的难点之一。
而传统的基于规则或统计方法的Entity linking往往无法处理结构化的数据，例如，fact-checking 数据集，因为数据中包含了多个要链接的实体。因此，近年来，基于深度学习的模型已经取得了很大的成功。本文则是第一个在fact-checking数据集上采用GCN进行Entity linking的工作。文章利用多层图卷积网络（Graph Convolutional Network）对mention pair进行编码并进行实体链接，此外还提出了一种新的loss函数——margin loss。实验表明，该模型能够在多个基准测试数据集上达到state-of-the-art的结果。
# 2. 相关工作
实体链接（Entity Linking，EL）是NLP领域的一个重要任务，它旨在将文本中的命名实体指代到其对应的实体资源（如知识库中的条目、页面）上。早期的EL方法通常是基于规则的方法或者是统计的方法。但现阶段基于深度学习的方法也越来越受欢迎。深度学习的方法可以自动地从大规模的文本数据中学习到有效的特征表示，并且可以通过端到端的方式解决复杂的问题。实体链接在EL领域主要由以下三个方面组成：（1）正则表达式匹配，首先通过正则表达式识别出潜在的候选实体；（2）知识库查询，然后基于知识库中实体的语义等信息查询候选实体；（3）链接预测，最后选择最可能的候选实体进行链接。目前已经有一些EL方法用神经网络来实现，包括基于CRF的序列标注方法，基于注意力机制的序列标注方法，以及基于RNN/CNN的模型。其中，基于CRF的序列标注方法需要设计复杂的转移矩阵来判断不同实体之间的关系，基于注意力机制的方法引入注意力机制来捕捉局部依赖关系，并且训练过程耗时长。而基于RNN/CNN的模型通常需要手工设计特征函数，并且基于规则的方法也是存在很多局限性。总的来说，基于深度学习的方法在EL领域处于一个新的高度，具有优秀的性能和快速的训练速度。

而fact-checking数据集是EL领域的一个重要的数据集。它包含两类问题，即事实检测和论据推理。事实检测（Fact Checking）试图确定给定的文本中是否存在错误或虚假的信息。它涉及到证据推理（Evidence Reasoning），即判断事实的正确性所需的证据是否足够充分。论据推理（Claim Inference）试图确定一个人的观点或行为为什么会被证明或辩护。它涉及到证据来源（Evidence Sourcing），即如何收集足够的证据以支持一个观点或行为。目前已经有一些研究人员试图利用fact-checking数据集来训练深度学习模型，但效果仍不尽如人意。

# 3. 问题定义
fact-checking数据集是EL领域的一个重要的数据集，它包含来自不同平台的真实或虚假的陈述及证据，需要根据这些陈述及证据，判断它们的真伪。文章中采用的fact-checking数据集是HotpotQA，它来自谷歌开发的一套面向初中学生的阅读理解测试。该数据集包含1.1万个问题，涵盖了热门话题和非热门话题。其中，热门话题的类型包括政治、经济、科技等，非热门话题的类型则包括健康、生活、旅游等。每道问题都有一个陈述和若干证据。对于陈述来说，它可能与某个已知实体发生联系，也可能是一个新的实体。对于证据来说，它们可以是文字、图片、视频、音频等。

给定一段话，我们的目标是预测它的实体链接是否正确。具体来说，给定一个句子$s$，其可能的实体链接集合为$\mathcal{E}$，那么问题就变成了：判断$s$是否属于$\mathcal{E}$，即：$s\in \mathcal{E}$？

# 4. 数据集与评价指标
在本文中，我们将采用fact-checking数据集作为实验的数据集。该数据集共有7679个问题，每个问题都有一个陈述$c$，一个正确的实体链接$e_{true}$和若干错误的实体链接$\{\hat{e}_{i}\}^{n}_{i=1}$。为了衡量模型的性能，我们设计了四种评价指标，包括：(1) Accuracy，计算正确的实体链接占所有实体链接的比例；(2) Precision，计算正确的实体链接中，真实实体与系统预测出的实体相同的比例；(3) Recall，计算正确的实体链接中，系统预测出的实体与真实实体相同的比果；(4) F1 score，对Precision和Recall的调和平均值。

# 5. GCN模型
GCN模型是图神经网络的一种形式，它利用图的拓扑结构和节点的连接关系进行特征学习。GCN模型的关键是构建邻接矩阵，该矩阵反映了节点间的相似性，邻接矩阵乘以节点的特征向量得到每个节点的邻居的特征向量。然后，应用GraphConv层对特征向量进行卷积，从而得到每个节点的更新后的特征。整个GCN模型可以看作是多个层的堆叠，每一层的输入输出都是对称的。

具体来说，在实体链接任务中，作者使用了一个三元组（句子，子串，实体）构成的语料库作为输入，并且只保留了用于实体链接的mention pair。作者定义了一个邻接矩阵$A=(a_{ij})$，其中$a_{ij}=1$表示第i个mention pair的左实体与第j个mention pair的右实体之间存在边，否则为0。对于每个mention pair，作者定义了一个嵌入矩阵$X_m \in R^{k×d_m}$，其中$k$代表mention pair的数量，$d_m$代表mention pair的嵌入维度。第二步，作者使用GraphConv层将$X_m$转换为节点特征矩阵$H_m \in R^{|V| × d_h}$，其中$|V|$代表结点个数，$d_h$代表节点特征向量维度。第三步，作者将$H_m$与$A$拼接后使用全连接层进行分类。

除去mention pair外，作者还使用一个子句嵌入矩阵$X_s \in R^{l×d_s}$来描述句子的上下文信息。将两个嵌入矩阵拼接后，输入到GraphConv层进行编码。

# 6. margin loss
在实体链接任务中，不同实体之间的链接关系是一个二分类问题。为了对实体链接进行分类，作者定义了一个loss函数——margin loss。该函数鼓励正确的链接与错误的链接之间的距离尽可能大，从而使得模型更加关注正确的链接。具体来说，对于每一对实体$u$和$v$，margin loss定义如下：
$$L = max\{y_uv - y_{ui} + m, 0\}$$
其中，$y_uv$代表实体$u$和$v$的链接概率，$y_{ui}$代表实体$u$和$v$的负例链接概率。如果$y_uv > y_{ui}+m$,那么误差项等于$max\{0, y_uv - y_{ui} + m\}$，否则等于0。

# 7. Experiment Results and Analysis
实验结果如下：作者分别在HotpotQA数据集上进行了训练和测试，实验设定为两阶段，第一阶段是在全量数据上进行训练，第二阶段仅在验证集上进行微调。训练结果如下表所示：



从上表可以看到，在第一个阶段中，模型的验证集上的F1 score超过了0.98，再次刷新了当时深度学习方法的记录。在第二阶段中，作者仅在验证集上进行微调，并在测试集上评估，其结果如下表所示：



同样从上表可以看到，作者在测试集上的F1 score超过了0.97，可以说是模型的state-of-the-art水平。