在传统的深度学习算法中，我们通常将隐状态表示为特征，然后通过非线性激活函数如ReLU、tanh等来转换为输出。在深度玻尔兹曼机模型中，我们一般不会采用这种方式，因为在深度玻尔兹曼机中，隐状态实际上不是输出，而是整个网络中的变量。换句话说，在深度玻尔兹曼机中，输出层的输出仅仅是隐藏层的输入。