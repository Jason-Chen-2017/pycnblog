SVD 是一种最常用的矩阵奇异值分解方法，通过它可以将任意维度的矩阵分解成若干个包含主要特征值的向量和若干个副主成分(side-information)，这些特征值对应的特征向量构成一个新的低秩的矩阵表示。通常情况下，只保留矩阵中重要的特征向量和重要的特征值，而舍弃其他无关紧要的特征。在机器学习等领域有着广泛的应用。