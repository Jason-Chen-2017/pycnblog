9. Dropout Regularization - Dropout is a regularization technique that randomly drops out some nodes during training to prevent overfitting. During testing, only the remaining nodes are activated and produce outputs. By doing this, we do not rely solely on one particular example to fit the model well. Instead, we encourage the model to learn robust representations regardless of noise in the data. 