
作者：禅与计算机程序设计艺术                    

# 1.简介
  

视频标题生成(Caption Generation)是一个基于图像、文本等多种信息的任务，而现实生活中很多事件都是在发生之时产生的，比如直播里出现热门主持人等。所以对于这些事件的演变过程或者原因进行描述，并能够给出足够清晰的文字版视频标题，就成为重要的一环。最近，随着新技术的飞速发展，机器学习领域也逐渐成为研究重点，越来越多的论文尝试解决这一难题，其中最具代表性的是Facebook AI Research团队提出的“Visual Storytelling”（VST），通过自动生成对视频内容的总结或情节提要，从而帮助用户理解该视频的内容。但该模型仍存在两个主要问题：一方面它并没有考虑到多媒体数据的时序特性；另一方面，它生成的字幕本身并不具有可信度。为了解决以上两个问题，作者在本文中提出了一个基于图形结构的视频标题生成模型——Explanatory Structures for Video Captioning (ESVC)，其可以直接利用多媒体数据中的时间顺序信息，同时输出可信度高的视频标题。具体来说，ESVC模型首先构造了视频对象相互之间的关系网络，包括前后帧之间的关联关系、静止体与运动体之间的时间关系、物体形状变化、光照变化、背景纹理等，并将其建模成了一张图网络。接着，借助动态图模型来预测每个时刻的视频字幕，包括了句子级别的特征以及单词级别的特征，还融合了自动生成机制和人工辅助机制。最后，基于约束优化方法，ESVC可以更好地处理一系列视频场景和长尾问题，有效地生成可信度高的视频标题。本文首次将图形结构的视觉语言模型应用于视频标题生成，并且为此构建了一个实验平台，论证了该模型的有效性和优势。
# 2.相关工作
目前关于视频标题生成的研究已经十分丰富，主要可以分为三类：基于序列模型的生成方式、使用图神经网络的多模态表示及文本理解任务，以及探索人机共同生成的交互方式。
### （1）基于序列模型的生成方式
如图所示，目前基于序列模型的视频标题生成方法通常由两步组成：首先，提取出视频的特征向量，即时刻特征向量或动作特征向量，然后基于特征向量生成标题序列。这种方法的特点是简单直接，但是生成的标题质量不一定很高，而且针对不同的视频场景可能会存在较大的偏差。另外，由于采用单向RNN模型，只能回溯一步，无法捕捉全局的依赖关系，因此生成的标题往往过于局限。
### （2）使用图神经网络的多模态表示
近年来，许多研究人员试图通过对多模态数据（例如图像、文本等）建模的方式来解决视频标题生成的问题。主要思路是将多模态数据整合到统一的框架下，通过学习节点和边的表示，来生成描述视频的句子。典型的方法是使用图神经网络(Graph Neural Network, GNNs)，通过学习节点的邻居信息，来预测目标节点的特征。然而，这种方法存在两个主要缺陷：第一，不同模态间的关系不容易建模；第二，由于引入了空间信息，因此生成的标题可能过于复杂或抽象。
### （3）探索人机共同生成的交互方式
一些研究提出了一种新的视频标题生成方式，即人机共同生成的模式。这种方法允许两方面的参与者来共同生成视频的标题，称为协作生成。传统的做法是让一个人的声音去影响其他人的声音，比如专家助手声音可以驱动大众读懂。另一种做法则是使用机器翻译模型，只需提供一段文本作为输入，即可得到对应的文本翻译。两种方式都有很大的局限性，在某些情况下，生成的标题可能无法准确反映事件的原因或演化过程。
# 3.关键词
基于图形结构的视频标题生成；计算机视觉与图神经网络；视听语言理解
# 4.1 视频标题生成问题定义
## （1）任务描述
给定一段视频，我们的目标是根据该视频内容，自动生成一段具有可读性的、表达视频的主要主题。比如，在电视剧中，标题就起到了导向剧情的作用；在舞蹈视频中，标题则会将全貌呈现出来。
## （2）输入输出格式
### **输入**：多帧图像
### **输出**：视频标题序列，每个标题对应一段视频片段。