
作者：禅与计算机程序设计艺术                    

# 1.简介
  

矩阵分解(Matrix Factorization) 是一种非常重要的数据分析方法，在计算机视觉、自然语言处理等领域都得到了广泛应用。它可以将高维数据进行降维，提取出主要特征向量或因子，进而进行分析、预测或者表示。一般来说，矩阵分解可分为奇异值分解(SVD)和谱聚类两种方式。矩阵分解的主要目的是从原始数据中找出合适的基底(factors)，使得原始数据的信息损失最小，从而达到压缩、降维、分类的目的。

# 2.基本概念术语说明
## （1）矩阵（Matrices）
一个矩阵是一个由若干个元素排成的方阵，其中每行都有相同的个数c，称之为列数；每列都有相同的个数r，称之为行数。

例如，下面的矩阵A是一个3x2的矩阵:
$$ A = \begin{bmatrix} 1 & 2 \\ 3 & 4 \\ 5 & 6\end{bmatrix}$$

另一个例子，下面的矩阵B是一个4x3的矩阵:
$$ B = \begin{bmatrix} a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33} \\ a_{41} & a_{42} & a_{43}\end{bmatrix}$$

## （2）秩（Rank）
矩阵A的秩（rank），记作rk(A), 表示矩阵的行满秩(row rank)。如果矩阵的秩等于行数n，则矩阵A是满秩的；如果秩小于n，则矩阵A是缺少某些行的半满秩(semi-full rank)。当矩阵的秩等于某个整数k时，它被称为k秩(k-rank)矩阵。

例如，矩阵A的秩为2，因为只有两行满足两个元素都不为零，因此是满秩矩阵。

## （3）行列式（Determinant）
矩阵A的行列式（determinant）den(A), 记作det(A), 是指将矩阵A的各个元素看做变元，在其周围曲线上的参数的值。对于二阶矩阵，它的行列式的值为:

$$ det(A)=a_{11}*a_{22}-a_{12}*a_{21}$$ 

如果det(A)!=0，则A是可逆的。如果det(A)==0，则A是奇异矩阵(singular matrix)。

例如，矩阵A的行列式为(-2)，表示存在两个元素互相抵消，但无法消除。

## （4）矩阵乘积（Product of matrices）
设A为m×n的矩阵，B为n×p的矩阵，则它们的乘积C=AB的结果是一个m×p的矩阵C=(ca_{ij})，其中ca_{ij}=Σk=1~n (a_{ik}b_{kj})，即第i行第j列的元素是由第i行的元素与第j列的元素的乘积和。

例如，矩阵A为3x2，矩阵B为2x4。那么，它们的乘积C=(3x4)的结果是一个3x4的矩阵C。

$$ C=\begin{bmatrix} c_{11} & c_{12} & c_{13} & c_{14}\\ c_{21} & c_{22} & c_{23} & c_{24}\\ c_{31} & c_{32} & c_{33} & c_{34}\end{bmatrix}$$

$$ C = AB = \begin{bmatrix} a_{11} & a_{12}\\ a_{21} & a_{22}\\ a_{31} & a_{32}\end{bmatrix} * \begin{bmatrix} b_{11} & b_{12} & b_{13} & b_{14}\\ b_{21} & b_{22} & b_{23} & b_{24}\end{bmatrix}$$

$$ c_{ij}=\sum_{k=1}^{n}(a_{ik}*b_{kj})$$

## （5）逆矩阵（Inverse matrix）
设A为m×n的非奇异矩阵，如果存在另外一个矩阵B，使得AB=BA=E，其中E是单位矩阵I，则称矩阵B为A的逆矩阵。也就是说，如果存在B，使得Ax=b，y=Bx，则y=x，此时A的逆矩阵B称作x的伪逆矩阵pseudo-inverse(Pinv_x).

## （6）特征值与特征向量（Eigenvalue and Eigenvectors）
设A为m×n的矩阵，如果存在数λ和对应的向量v，使得Av=λv，且向量v与其他任何向量都无关，则称数λ为矩阵A的特征值，相应的单位特征向量v为矩阵A的特征向量。

## （7）奇异值分解（Singular Value Decomposition, SVD）
奇异值分解(SVD)又称希尔伯特正交化分解(Hessenberg form factorization)，是通过把矩阵A分解成三个不同的矩阵U, Σ, Vt来实现的。其中，U为m×m实对角矩阵(unitary diagonal matrix)，Vt为n×n实对角矩阵，Σ是对角矩阵(diagonal matrix)，对角线上的值分别为A的奇异值。

## （8）谱聚类（Spectral clustering）
谱聚类(spectral clustering)是基于拉普拉斯矩阵(laplacian matrix)的聚类方法。所谓拉普拉斯矩阵，是指对给定的矩阵A，定义为A^T*A。通过计算A^T*A，得到的拉普拉斯矩阵是一个对称正定矩阵，并且它的值在主对角线上(对角线上的所有值均为负数)有着特殊的性质。

因此，如果用拉普拉斯矩阵来构造距离矩阵，就能找出距离较近的点属于同一簇，距离较远的点属于不同簇。然后，用带权重的K-means算法对簇进行聚类，就可以发现数据的内在结构，并对其进行分类。