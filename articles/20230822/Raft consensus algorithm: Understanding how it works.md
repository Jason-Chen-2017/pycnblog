
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Raft 是一个分布式一致性算法，由美国计算机科学家斯坦福大学的工程师 Ervin DeCampos 和著名计算机科学博士 Lamport 在 2013 年提出，并在 Google 的很多项目中得到应用。它的目标是在不牺牲可用性的前提下提供更高的性能。

Raft 是一种用来管理复制状态机（Replicated State Machine）的协议，也是一种非常成熟的分布式系统设计范式。简单来说，就是一个分布式集群中只能有一个领导者节点，其余的节点都是跟随者节点，并且在正常情况下，只有领导者节点才可以参与到所有事务的决策流程中，而跟随者节点则只能作为日志的承接人，没有任何投票权利。通过选举产生新的领导者节点，将领导者节点故障转移给其他节点，并且当出现网络分区时，也能确保集群的正常运行。Raft 算法的特点主要包括下面几点：

1. 强Leader：Raft 使用一种被称作“强领导者”的机制来保证集群中只存在唯一的领导者节点，领导者节点决定着整个集群的行动方向，所以它是集群内最重要的角色。Raft 将这一特性建模为分布式共识问题——选举出一个节点作为领导者，让整个集群陷入一致性。
2. 选举过程：Raft 的领导者节点通过竞争的方式获得广泛支持，当其他节点发现自己成为领导者时，会向集群中广播消息，要求其转换自己的角色。这就需要有一种机制能够检测到节点之间是否存在冲突，Raft 采取了一种被称为“随机超时”的方法，使得领导者节点在随机的时间段内重新发起选举，以期望得到集群的多数派支持。
3. 成员变化：Raft 提供了一个可靠的、持久化的存储服务用于保存集群成员信息，并且它采用了一种“分裂、合并、同步”的方式处理节点动态加入和退出的问题。集群中的成员信息记录在一个易于理解的日志中，所有修改都在日志上进行，这样便于追踪集群状态变化。

Raft 技术在开源社区里经历了一段时间的发展，目前已经被越来越多的公司、组织所采用。例如， etcd、CockroachDB、TiDB、Dubbo 等众多知名项目都采用了 Raft 作为其数据一致性模块。

Raft 本身有一些复杂的功能特性，比如利用虚拟相似进化（Virtual Synchrony Biasing V-Sisyphean Bias）等方法来缓解网络延迟或结点故障导致的拜占庭将军问题。不过，这些特性对日常的工程实践应该不是很重要。本文就仅关注于 Raft 的核心算法本身。

# 2.Raft 分布式一致性算法概述
Raft 是一个实现分布式一致性的容错算法，其共识机制是通过选举产生新的领导者节点，并确保在正常情况下只有领导者节点才能参与到所有事务的决策流程中，而跟随者节点则只能作为日志的承接人，没有任何投票权利。

Raft 使用一个固定大小的日志来记录集群中各个节点上提交的命令，并且每次 leader 节点完成一次提交操作后，都会将相关信息发送给所有的 follower 节点，follower 节点会把该信息存放在本地磁盘上，直到日志被完全提交到集群中。这样一来，即便出现网络分区，或者 leader 节点出现故障，也可以从已有的副本中恢复出来，形成一个完整的集群。

Raft 共识机制中的几个角色：

1. Leader：负责全局调度，所有的客户端请求首先都要先访问 leader 节点，然后由 leader 节点分配到其他 follower 节点去执行。如果 leader 节点宕机了，那么就会选择一个新的 leader。
2. Follower：只接受 client 请求，记录日志并响应 client 请求，但不能投票。
3. Candidate：负责新一轮的选举，在接收到过半 followers 的响应后，宣布自己成为 candidate ，并向其他的节点发送 request vote 消息。如果超过一定的时间没有收到赢得选举的 response,则变成 candidate again 。
4. Term：Raft 中主要用 term 来表示任期的概念，每个任期都是一个连续的编号，初始时第一个节点启动时 term 为 0，leader 可以改变自己的 term，因此可以解决脑裂的问题。

Raft 的日志结构如下图所示：


Raft 使用心跳机制来感知集群的活跃程度，当 follower 长期没有收到 leader 的心跳，那么它会认为 leader 已经失效，则开始选举，一旦获得 majority 地 approval ，则成为新的 leader 继续服务。同时，如果在选举过程中，产生了一个胜者，则停止当前的选举，将消息通知给 others 切换到该节点。

为了保证选举的平稳性，Raft 使用两阶段提交（Two-Phase Commit）的方式，在选举产生新的领导者之前，要确保整个集群达到一致性，不能出现脑裂。这种机制保证了系统在正常情况下的可用性。

# 3.Raft 分布式一致性算法原理及运作流程
## 3.1 选举机制
Raft 使用一种被称作“强领导者”的机制来保证集群中只存在唯一的领导者节点，领导者节点决定着整个集群的行动方向，所以它是集群内最重要的角色。Raft 将这一特性建模为分布式共识问题——选举出一个节点作为领导者，让整个集群陷入一致性。

Raft 使用一个被称作 “heartbeat” 的机制来感知集群的活跃程度，每隔一段时间（默认 150ms），follower 节点都会发送一个消息，告诉 leader 当前节点依然存活。如果 follower 在指定的时间内没有接收到 leader 的心跳，它就会认为 leader 已经挂掉了，此时它就会变成 candidate ，并发起一次选举，寻找一个合适的领导者节点。Raft 算法会在 candidate 发起选举之后等待一段时间（默认 100ms 到 300ms），如果没有任何 leader 的 heartbeat ，则将 candidate 声明为新的 leader 。

Raft 使用一个随机超时的方法来降低选举失败率，当一个 follower 等待了足够的时间（由一个随机值决定），却没有收到 leader 的心跳，它就会发起一个请求投票的 RPC 调用。如果选举成功，那么 leader 会给 candidate 返回一个赞成票；否则，它返回一个弃权票。

当 leader 节点发现有某个 follower 节点有一定数量的票数，那么它会让这个 follower node 执行心跳检测，直到 leader 检测到所有的 follower 都停止回复心跳，才会让一个 follower 节点转换成 candidate 。另外，如果 follower 不再给 leader 发送心跳，超过一段时间，它会发起自己的选举，寻找一个合适的领导者节点。Raft 通过选举产生一个领导者节点，并将其写入所有副本中，确保整个集群都认同这个节点作为新的领导者。

## 3.2 Log replication
Raft 最重要的功能之一，就是数据的一致性，这体现在两个方面：

- 一是数据安全性：Raft 必须保证数据的安全性，这意味着 leader 只需要向所有的 follower 节点复制数据就可以保持数据的一致性。由于使用的是强领导者，所有的修改只能由 leader 进行，其他节点都是看不到或者不允许执行的，因此数据不会因少数的错误节点而损坏。
- 二是系统容错性：Raft 需要在节点之间复制日志以保证系统的容错性。在大多数情况下，日志在不同节点上是相同的，日志的内容也相同。如果一个节点损坏了，可以从另一个节点上获取正确的日志数据，确保系统的正常运行。

为了维护数据一致性，Raft 每次 leader 提交一个事务的时候，都会将相应的命令同时记录到所有 follower 上，并且也会让 follower 将对应的日志提交到本地磁盘中。这样一来，leader 节点和 follower 节点的数据总是一致的。同时，Raft 使用一种类似于二阶段提交的机制来确保数据的安全性，这意味着 leader 会等待 follower 将日志提交到本地磁盘中，确认它们之间的状态达到了一致，然后才提交事务。

Follower 节点定期发送给 leader 节点心跳消息，并且 leader 节点根据 follower 节点的日志信息来决定是否需要提交某些日志条目。一旦某个 follower 节点发现 leader 失联或者某些事情发生了变化，例如发生了网络分区，那它就会向其他节点发送消息，要求 leader 做出决策。

## 3.3 Membership Changes
Raft 通过让 leader 节点来协调集群成员的变化，使得集群可以动态地增加或者删除节点。这里描述一下 membership changes 的工作流程：

1. 当一个节点想加入到 Raft 集群中时，首先他必须先向集群中的某一个已知节点发送一条加入消息，并等待该节点的确认消息。
2. 如果加入消息被接受，并且被选举为新的领导者，那么被加入的节点会被添加到 Raft 集群的成员列表中。
3. 如果加入消息被接受，但是被选举为新的领导者，但是却没有成为新的 leader ，那么被加入的节点不会被添加到 Raft 集群的成员列表中，因为它仍处于老领导者的控制之下。
4. 如果加入消息被拒绝，那么被拒绝的节点会被通知。
5. 当某个节点想要离开 Raft 集群时，它只需发送一条离开消息给集群中任意一个已知节点，如果消息被接收，则被离开的节点会被从集群中移除。
6. 如果某个节点想要从 Raft 集群中重新加入时，它必须首先被清除掉，然后再重新加入。

为了保证成员变化的一致性，Raft 使用了一种被称作 “Joint Consensus” 的方式，使得多个节点在任意时刻都能感知到成员变化的存在。这个过程如下：

1. 当一个节点想要修改 Raft 集群中的成员列表时，它会将该消息发往其他所有成员节点，询问是否允许该节点进行成员变更。
2. 如果成员变更被批准，那么该节点会将修改后的成员列表追加到自己的日志末尾，然后向所有成员节点发送通知消息，告诉他们该节点的修改已生效。
3. 如果成员变更被否决，那么该节点会将自身的成员列表重置为旧的值。
4. 当一个成员节点收到通知消息后，它会更新自己的成员列表，重新同步集群数据。

在 Joint Consensus 方式下，集群中的所有节点都能尽快感知到成员变化，因此可以避免因成员变化造成的不可用情况。

# 4.Raft 算法代码解析
Raft 算法实现通常比较复杂，因此，我准备将它分为三个部分进行解析：

- Basic raft concepts and data structures
- The raft consensus algorithm
- Implementations of the raft algorithm in several programming languages

## 4.1 Basic Raft Concepts and Data Structures
Raft 算法的基本概念如前面所述，本节简单介绍一下一些基本的数据结构和过程。

### Logs and Entries
Raft 算法使用了一个固定大小的日志来记录集群中各个节点上提交的命令，并且每次 leader 节点完成一次提交操作后，都会将相关信息发送给所有的 follower 节点，follower 节点会把该信息存放在本地磁盘上，直到日志被完全提交到集群中。每个日志由一个 Entry 对象表示，其中包含一个状态机命令和一个索引值。


### Replicas and States
Raft 使用一个固定大小的日志来记录集群中各个节点上提交的命令，并且每次 leader 节点完成一次提交操作后，都会将相关信息发送给所有的 follower 节点，follower 节点会把该信息存放在本地磁盘上，直到日志被完全提交到集群中。每个日志由一个 Entry 对象表示，其中包含一个状态机命令和一个索引值。

Raft 算法中包含两种类型的节点，分别是 leader 和 follower，每个节点的角色都是由 Raft 集群的状态决定的。每个节点都维护了一份完整的日志。在任意时刻，只有一个节点（可能是 leader 或 follower ）能成为 leader。


Leader 节点可以通过以下两种方式来决定是否要提交日志：

- （1）定时：如果一个节点距离上次发送 AppendEntries 消息的时间超过 election timeout（一般为 150~300 毫秒），那么它会认为当前 leader 失效，并开始新一轮的选举，选举出的节点成为新的 leader 。
- （2）自主：Leader 节点会从 follower 获取心跳信息，如果在一定时间内没有获取到有效的心跳信息，则会将对应 follower 标记为疑似下线，并重新发起选举。

如果一个 follower 节点失联（失去联系），则它的 logs 可能处于不一致的状态，当它回归到集群后，它会找不到对应的 leader ，所以它会开启新一轮的选举，重新选举出 leader 。当一个 leader 失效，或者发生网络分区时，leader 节点会自动转换成 follower 节点。

### Client Requests
客户端的请求可以直接发往 leader 节点，也可以转发给 follower 节点。一旦一个请求被确定为被提交，客户端就可以得到结果。

### Safety Properties
Raft 有一些属性来保证数据一致性，这里给出其中的一些。

1. Safety Property 1：对于一个给定的任期 t，日志只能从一个唯一的 leader 追加到它的后面。
2. Safety Property 2：永远不会删除日志，只会覆盖掉之前的日志。
3. Safety Property 3：如果一个服务器已经按照当前的领导人的值存储了某个日志条目，那么其他服务器在同一任期内不会提交和覆盖这个条目。
4. Safety Property 4：如果一个服务器存储了一个日志条目，那么这个条目必然已经被其他服务器的大多数选举出来。
5. Safety Property 5：如果一个服务器没有覆盖掉自己的日志，那么它肯定不会覆盖掉已经提交的日志。

## 4.2 Raft Consensus Algorithm
Raft 算法的核心是 leader 节点对集群状态的仲裁，其中的关键步骤如下：

1. Request Vote RPC：candidate 节点会向其他节点发送 RequestVote RPC 请求投票，该 RPC 包含当前 candidate 的 ID 和日志的最大索引位置。
2. AppendEntries RPC：在正常情况下，leader 节点接收到 client 请求后，会将该请求封装成一个 Entry 并添加到自己的日志中，并立即向 follower 节点发送 AppendEntries RPC 消息。
3. Election Safety：在任意时刻，最多只能有一个 leader。如果一个 follower 拒绝了一个 candidate 的投票，它就会变成 candidate 然后再次发起选举，直到它被选中为 leader 为止。
4. Log Completeness：日志必须是无损的，如果日志损坏了，即便 follower 节点也无法通过日志找到缺失的位置。
5. Catchup Procedure：如果 leader 节点落后太多，为了追赶上 follower 节点，它会停止自己生成新的日志并执行 catchup 过程。catchup 过程会让 leader 从 follower 的最新位置下载完整的日志，并在此基础上进行正常的日志复制。

除了这些步骤外，Raft 还引入了一种特殊的角色，叫做 pre-vote，它可以在选举过程中节省时间。pre-vote 的作用是，在发起 RequestVote RPC 时，候选人先不给自己投票，先发一个 pre-vote ，等待其他节点的响应。如果得到的反馈都是没有赞成票，那么候选人就会放弃投票。如果有超过一半的节点支持这个预选举，那么候选人才正式开始投票。

在实际的实现中，Raft 的性能表现通常比 Paxos 好，原因有以下几个方面：

1. Raft 使用了批量通信，减少了通信量。
2. Raft 使用了随机超时，减少了因滞后导致的选举失败率。
3. Raft 使用了更加简洁的消息协议，使得系统更容易理解和开发。
4. Raft 更倾向于达成共识而不是单纯的复制，减少了日志复制的延迟。

## 4.3 Implementations of the Raft Algorithm in Several Programming Languages
Raft 有多种语言版本的实现，如 Java 版的 JRaft、Go 版的 Graft、Rust 版的 RustRaft、C++ 版的 Stanford Raft 等。下面详细讨论 Go 语言版本的 Raft 实现，以及 Go 版本 Raft 的一些特点。

### Go Version of Raft Implementation
Go 语言版的 Raft 实现源自 github 上的 chubaofs/chubaofs。

#### Overview of Go Implementation of Raft
Go 语言版的 Raft 使用 gossip 协议来解决集群配置问题。Raft 集群中的所有节点通过 gossip 协议来传播集群配置信息。每个节点会维护一张拓扑图，其中记录了节点之间的连接关系，以及节点之间的磁盘使用信息。

Raft 的 log 机制由一个内存 buffer 和日志文件组成。Go 实现中日志文件的大小为 32MiB。如果 buffer 中的数据超过了限制，那么日志文件就会被刷新到磁盘上。

Raft 使用内部线程池来处理客户端请求，并将任务划分到多个后台 worker 线程中。后台 worker 线程采用读写锁模式，保证数据的一致性和正确性。

#### Implementation Details of Go Implementation of Raft
Go 版本的 Raft 实现使用 channel 模型来处理并发请求。每个节点都维护一个 Gossip 服务，用于同步集群配置。每个节点会定时向其他节点发送周期性的心跳包，接收到的心跳包数量会影响新选举的速率。当某个节点崩溃或网络断开时，它会把该节点标记为 suspected，直到网络恢复正常。当某个节点被标记为 suspected 时，它会从集群中踢出，并重新启动选举。

每个节点都维护了一张状态机，用于存储数据。状态机的数据保存在内存中，通过后台 worker 线程持久化到磁盘上。通过前缀压缩的方式，可以压缩状态机的元数据。

每个节点都维护一个后台 worker 线程，用于处理客户端请求。客户端的请求会直接发往 leader 节点，其他节点只是转发。当 leader 收到客户端请求时，它会将其添加到自己的日志中，并在内存中创建一个 applyFuture 句柄，表示已经收到了客户端的请求，但尚未真正地执行。Leader 会将 Apply Msg 发送给 follower 节点，让 follower 将该 Entry 写入自己的日志中。当所有的 follower 都成功复制了该 Entry，leader 节点才会通知客户端结果。

Go 版本的 Raft 使用了动态并发方案。Raft 的线程模型会创建一些后台 worker 线程，这些线程负责处理客户端请求、日志复制、状态机快照等操作。这些后台 worker 线程会通过读取锁模式来保证数据一致性。

Go 版本的 Raft 还引入了一些优化措施，来提升性能。如预读、日志缓存、批量写入等。

Go 版本的 Raft 对外提供了 RPC 接口，可以使用 Thrift、gRPC 等框架进行开发。

#### Future Work on Go Implementation of Raft
在 Raft 算法的早期版本中，Go 版本的实现是独立实现的。但是随着时间的推移，其稳定性、健壮性和可扩展性逐渐受到关注。下面是 Raft 实现的一些待办项：

1. 完善集群启动时的恢复过程。目前 Raft 只能重启集群来处理成员变更等操作。
2. 探索更有效的网络拓扑形态。当前 Raft 基于疎连接，会遇到网络拥塞的问题。
3. 支持更多的编程语言。如支持 Python、C# 等。