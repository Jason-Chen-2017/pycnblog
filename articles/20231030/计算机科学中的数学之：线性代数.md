
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


## 概念定义
线性代数(Linear Algebra)又称线性方程组演算学、实数分析学、数字计算学中的一个分支，它研究的是由向量空间、矩阵运算及其关系所组成的一套数学结构体系。在此基础上，人们建立起了许多重要的数学理论和技术。比如：计算几何、图形学、信号处理、数值分析、优化理论、物理学等。


## 发展历史
近百年来，线性代数一直是数学的一项重要分支，它的发展经历了一系列的阶段，包括早期希腊、罗马共和时期出现的几何学派，欧几里得几何学派、实数学派、向量分析派、矩阵分析派等等。这些派别都试图发现数理统计学、概率论、力学、电磁学等多种领域中的一些基本性质，并通过代数学理论推导出其对应法则。在二十世纪七十年代后期，由于数值计算能力日益增强，线性代数也被应用到许多科学、工程领域。

线性代数作为最基础的数学学科，发展得非常快速，过去十几年间产生了很多创新性的理论与方法。当前，线性代数已经成为人工智能、机器学习、图论、信息论、计算复杂性理论等众多学科的基础，它是许多重要的理论与工具的基石。

## 研究目标
线性代数的研究目标是研究向量、矩阵、张量等抽象实体之间的关系和运算。主要研究对象是向量空间$V$，它们可以是二维或三维空间、高维空间。研究的内容有两个方面：一是研究不同空间上的向量、矩阵、张量等抽象实体之间是否存在相同的表示形式；二是探索向量、矩阵、张量等抽象实体的各种运算规则及其运用。


# 2.核心概念与联系
## 一元一次方程：一条直线上的一点
对于在直线$y=ax+b$上的一点$(x_0, y_0)$来说，当$a\neq 0$时，它可以唯一确定一条直线$y-ay+b=0$。如果方程两边同时乘上$-1/a$，那么得到的新的方程$x+\frac{1}{a}y=-\frac{b}{a}$，其中$-\infty<x,\;y<\infty$。也就是说，对于任意一点$(x_0, y_0)$，它只可能有一个对应的值$t_0=\frac{-b}{a}$。把$(x_0, y_0)$和$t_0$对应起来，$y=ax_0+b+at_0$。

## 向量、矢量
- **标量（scalar）** 是单个数值，通常记作 $s$, $k$, 或 $\lambda$. 在数学中，$s$ 通常是一个实数，而 $k$ 可以是整数或者无理数。
- **向量 （vector）** 是有方向和大小的量，通常记作 $\boldsymbol{\mathrm{v}}$, $\boldsymbol{\mathbf{w}}$, 或 $\boldsymbol{\boldsymbol{\omega}}}$. 每个向量都由若干分量组成，分量的数量称为向量的秩，记作 $\operatorname{rank}(\boldsymbol{\mathrm{v}})= |\boldsymbol{\mathrm{v}}|$. 如果向量的秩为零，则它被称为空向量，记作 $\boldsymbol{0}$.
- **行向量 (row vector)** 是指具有 $n$ 个元素的向量，每一列为一个元素，用 $[\boldsymbol{u}_1, \boldsymbol{u}_2,..., \boldsymbol{u}_m]$ 表示，其中 $m$ 为维度 (dimension), $\boldsymbol{u}_i$ ($i = 1,..., m$) 为列向量 (column vector).
- **列向量 (column vector)** 是指具有 $m$ 个元素的向量，每一行为一个元素，用 $\begin{bmatrix}\boldsymbol{u}_1 \\ \boldsymbol{u}_2 \\... \\ \boldsymbol{u}_n\end{bmatrix}$, 或简写为$\boldsymbol{u}^T$ 表示，其中 $n$ 为维度 (dimension), $\boldsymbol{u}_j$ ($j = 1,..., n$) 为行向量 (row vector)。
- **零向量 (zero vector)** 是指长度为 $n$ 的单位向量，其各分量均等于 $0$, 用 $\boldsymbol{0}= [0,0,...,0]^T$ 表示。
- **单位向量 (unit vector)** 是长度为 $1$ 的向量，即方向相同但大小为 $1$ 的向量。单位向量有着特殊的数学性质，它是区分其他向量的尺度因子。
- **标准化向量 (standardized vector)** 是指归一化 (normalized) 后的向量，即它的方向和大小相对固定。一般情况下，标准化向量通常用希腊字母 $\bar{\boldsymbol{\mathbf{x}}}$ 来表示。
- **线性组合 (linear combination)** 是将给定的向量线性叠加 (summing up) 而得到的向量，即满足如下关系：

  $$\alpha_1\boldsymbol{v}_1 + \cdots + \alpha_m\boldsymbol{v}_m = \sum_{i=1}^{m}\alpha_i\boldsymbol{v}_i$$
  
  其中 $\alpha_1, \ldots, \alpha_m$ 为实数，$\boldsymbol{v}_1, \ldots, \boldsymbol{v}_m$ 为向量。

- **外积 (outer product)** 是两个向量的乘积，即

  $$\boldsymbol{u}\cdot\boldsymbol{v}=[u_1 v_1, u_2 v_2,..., u_n v_n]$$
  
  其中 $\boldsymbol{u}, \boldsymbol{v}$ 为向量，$\cdot$ 为叉乘符号。其结果是一个 $n \times n$ 矩阵。

- **范数 (norm)** 是测量向量距离或大小的函数，它定义为：

  $$||\boldsymbol{v}||=\sqrt{\left(\boldsymbol{v}(1)\right)^2+\cdots+\left(\boldsymbol{v}(n)\right)^2}$$
  
  它表示向量 $\boldsymbol{v}$ 的长度 (magnitude)，也称为向量的大小 (size)。不同的范数对应的就是不同的距离度量方法。有以下几种常用的范数：
  - $L^p$ 范数：$L^p$ 范数表示向量中每个分量的绝对值的 $p$ 次方的总和的开方。当 $p=2$ 时，$L^2$ 范数表示向量中每个分量的平方的总和的开方。
  - $L^\infty$ 范数：$L^\infty$ 范数表示向量中所有分量的绝对值的最大值。

- **投影 (projection)** 是指将向量 $\boldsymbol{v}$ 投影到向量 $\boldsymbol{w}$ 上面的那部分。投影向量的长度等于 $\boldsymbol{v}$ 在 $\boldsymbol{w}$ 方向上的投影，方向为 $\boldsymbol{w}$。投影公式为：

  $$\text{proj}_{w}\boldsymbol{v} = (\boldsymbol{w}\cdot\frac{\boldsymbol{v}}{\|\boldsymbol{v}\|}) \boldsymbol{w} = (\boldsymbol{w}\cdot\frac{\boldsymbol{v}}{\|\boldsymbol{v}\|})\frac{\boldsymbol{w}}{\|\boldsymbol{w}\|}$$
  
  当 $\frac{\boldsymbol{v}}{\|\boldsymbol{v}\|}$ 和 $\frac{\boldsymbol{w}}{\|\boldsymbol{w}\|}$ 是单位向量时，上式可以简化成：
  
  $$\text{proj}_{w}\boldsymbol{v} = (\boldsymbol{w}\cdot\boldsymbol{v})\frac{\boldsymbol{w}}{\|\boldsymbol{w}\|}$$
  
- **Gram 矩阵 (Gram matrix)** 是一种矩阵形式的内积，用于衡量向量的线性相关性。

  Gram 矩阵的元素 $G_{ij}$ 定义为：

  $$G_{ij}=\langle\boldsymbol{v}_i,\boldsymbol{v}_j\rangle=\frac{1}{\|\boldsymbol{v}_i\|}\sum_{\ell=1}^{m}\langle\boldsymbol{v}_i,\boldsymbol{v}_{\ell}\rangle\langle\boldsymbol{v}_{\ell},\boldsymbol{v}_j\rangle$$
  
  其中 $\boldsymbol{v}_i$ 和 $\boldsymbol{v}_j$ 分别是向量，$\|\boldsymbol{v}_i\|$ 是向量 $\boldsymbol{v}_i$ 的模 (norm)。
 
- **正交 (orthogonal)** 是指两个向量不再变化的条件。在某个向量空间中，任意两个不为零向量是正交的，它们的内积等于零，即 $\boldsymbol{u}\cdot\boldsymbol{v}=0$, $\forall \boldsymbol{u}, \boldsymbol{v}$.

- **基 (basis)** 是一组互相正交的基向量的集合，也是某些特殊向量空间的坐标系。

- **基变换 (basis change)** 是将向量从一个坐标系转换到另一个坐标系的映射，它依赖于一个基。

## 矩阵、矩阵式
- **矩阵 (matrix)** 是由若干行与列的数组成的表格式，通常表示成 $A=(a_{ij}), a_{ij}$ 为 $i$ 行 $j$ 列的元素。矩阵的秩为矩阵的行数与列数的最大公约数。若矩阵 $A$ 的某一行全为 $0$，则称 $A$ 为零矩阵。
- **矩阵乘积 (product of matrices)** 设 $C$ 为 $A$ 和 $B$ 的矩阵乘积，则 $c_{ik}=\sum_{j=1}^{r}a_{ij}b_{jk}$, $1\leq k \leq r$ 为 $C$ 中第 $i$ 行，$1\leq j \leq s$ 为 $C$ 中第 $j$ 列，则 $A \times B = C$ 。矩阵的乘积满足结合律。
- **转置矩阵 (transpose matrix)** 设 $A^T$ 为矩阵 $A$ 的转置矩阵，$a_{ij}=a_{ji}$，$A^TA$ 的行列式的值与 $AA^T$ 的行列式的值相同。
- **对角矩阵 (diagonal matrix)** 是对称矩阵，仅对角线上的元素非零。
- **上三角矩阵 (upper triangular matrix)** 是矩阵的主对角线以上位置的元素为非零的矩阵。
- **下三角矩阵 (lower triangular matrix)** 是矩阵的主对角线以下位置的元素为非零的矩阵。
- **单位阵 (identity matrix)** 是方阵，对角线上元素的值都是 $1$，其余元素为 $0$。
- **反对称阵 (skew-symmetric matrix)** 是实对称阵，即 $A=A^T$，其中 $A_{ij}=-A_{ji}$。
- **对称阵 (symmetric matrix)** 是实矩阵，即 $A=A^T$。
- **同次方程组 (system of linear equations)** 是方程式组中关于未知变量的一个方程，它有如下的形式：

  $$
    A\boldsymbol{x}=\boldsymbol{b}
  $$

  其中 $A$ 为系数矩阵，$\boldsymbol{x}$ 是未知的变量，$\boldsymbol{b}$ 为右端常数项。该方程组的解 $\boldsymbol{x}$ 称为方程组的通解 (solution)。