
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


径向基函数(Radial basis function, RBF)是一种计算高维空间中的距离的方法。它的主要思想是用一个基函数来逼近数据点处的值，使得任意输入的点都可以由基函数的加权求和得到其近似值。在解决机器学习问题、模式识别等方面具有广泛的应用。
RBF有很多种不同的实现方法，本文将采用最基本的实现方式——多项式径向基函数（Polynomial radial basis functions）——来讲述其基本概念、性质及其应用。
# 2.核心概念与联系
## 2.1 定义及性质
径向基函数是一种基于函数的映射，它将一个点到原点的距离映射到一个非负实数值上，并由此对这个距离进行放缩和加权。给定一个点x∈Rd，其径向基函数f(x)表示其距离原点的距离d：f(x)=||x-c||，其中c是一个超平面的参数，即距离原点最近的点。由定义可知，径向基函数是一个双射，它是一个从Rd到Rn的映射，其中n为基函数的个数，Nn是基函数组成的矩阵。当n=N时，基函数组成的矩阵就是Nn。Nn中每个元素nn(i,j)代表第i个基函数和第j个输入维度的组合的效果。
## 2.2 多项式径向基函数
多项式径向基函数是指利用多项式基函数构成的基函数族。对于每个输入变量xi，将其映射到一个非负实数上，其形式为：
f(x)=θ1*r^3+θ2*r^2+θ3*r+θ4
其中r=(||x-c||)^2，c是一个超平面的参数，θ1~θ4是系数，可以使得距离原点较远的点的映射更精确。一般来说，多项式基函数模型往往比较简单，并且易于处理。但由于基函数过多容易造成过拟合现象，所以实际工程应用中通常需要选取合适的基函数数目。
## 2.3 内核技巧
### 2.3.1 局部近似
如果输入变量xi满足条件，则可以使用局部近似进行高效求解。比如，如果xi=zxj，则可以简化该模型，只需考虑一个局部区域即可。这样做可以提高计算效率，因为不需要考虑所有输入变量。
### 2.3.2 共轭梯度法（conjugate gradient method）
当给定的函数是凸函数时，通过共轭梯度法（conjugate gradient method）可以有效求解线性代数方程。这种方法是一种迭代法，利用搜索方向来寻找使代价函数最小的点，直到达到收敛。
### 2.3.3 软间隔支持向量机（soft margin support vector machine, SVM）
支持向量机（support vector machine, SVM）是一个很经典的机器学习模型。SVM希望找到一个超平面把不同类别的数据分开。但是，直线或其他的超平面可能并不好，因此，引入松弛变量(slack variable)来允许误分类的点在边界上。软间隔SVM可以在训练过程中加入惩罚项，鼓励支持向量偏离边界，使得算法鲁棒性更强。
### 2.3.4 径向基函数网络（radial basis function network, RBFNet）
径向基函数网络（RBFNet）是神经网络的一种扩展。它在传统神经网络的基础上增加了径向基函数作为隐藏层节点，相比传统神经网络有着显著的优势。RBFNet能够自动地根据样本学习基函数，并形成能够捕获非线性关系的自适应函数。
# 3.核心算法原理和具体操作步骤以及数学模型公式详细讲解
## 3.1 输入输出空间映射
假设输入空间Rd中有m个输入变量xi，输出空间Rn中有k个输出变量yi。基函数个数为n，由Nn与输入/输出向量形成映射：
y=Nn(x)+b
## 3.2 梯度下降法优化
假设代价函数J(w,b)=||Nn(x)+b-y||^2，由于求导非常复杂，因此我们使用共轭梯度法优化：
w←w-αnabla J(w,b),b←b-αnbeta J(w,b)
其中，α为步长，nabla J(w,b)和nbeta J(w,b)分别是nabla J(w,b)和beta J(w,b)。利用共轭梯度法的目的是求出最佳的参数w,b。