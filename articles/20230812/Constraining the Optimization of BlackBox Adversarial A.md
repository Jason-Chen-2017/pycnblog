
作者：禅与计算机程序设计艺术                    

# 1.简介
  

近年来，基于图结构模型（Graph Structured Modeling，GSM）构建的黑盒攻击方法得到了广泛关注。然而，在研究和实践中发现，这些攻击方法往往难以有效防御网络中的对抗样本，原因主要包括以下几点：

1. 在训练阶段，GSM 模型学习到的是全局的数据统计信息，而没有考虑到局部数据的特性，因此可能会被噪声数据所欺骗；
2. GSM 学习到的节点之间的关联性并不一定准确反映真实的节点关系，从而影响了对抗样本生成过程。

为了解决上述问题，作者提出了一个改进的 GSM 黑盒攻击方法，即 GSM-PGD ，它通过拟合非凸目标函数对抗样本，使得攻击者只能得到相似但稍微逾越边界的样本。该方法虽然可以有效地避免生成较差质量的样本，但是仍存在着攻击效率低下、样本易受噪声攻击等问题。为了进一步提高攻击效率和防御能力，作者提出了一种 GNN-PGD 的优化方法，该方法可以直接在攻击过程中限制 GSM 模型预测出的概率分布，实现更精确的控制和降低攻击代价。此外，还可以进一步探索对抗训练和限制梯度的方法，来进一步提升模型鲁棒性。

本文详细阐述了 GSM-PGD 和 GNN-PGD 方法，并且给出了针对不同的攻击任务的研究结论，验证其有效性，并进行了实验分析。希望这份技术综述能够帮助读者更好地理解和应用 GSM 模型和 GNN 对抗攻击方法。

# 2.基本概念术语说明
## 2.1 图结构模型
图结构模型（Graph Structured Modeling，GSM）是利用图论、概率论和优化理论等知识对复杂系统行为建模、分析、预测和控制的一类模型。它广泛用于互联网领域、生物信息学领域、金融领域、制造领域、社会网络分析等场景。GSM 使用图来刻画系统中的实体之间的相互作用关系，并将每个实体作为图上的顶点，实体间的连接关系作为图上的边。例如，在社交媒体领域，用户关系网络可以表示用户之间关系的图，用户可以作为顶点，彼此间的联系作为边。图结构模型的目的就是找出系统中最重要的、具有代表性的子集，根据这些子集来预测或控制整个系统。

## 2.2 黑盒攻击
黑盒攻击是指攻击者无法知晓对手模型内部结构、计算逻辑，只能知道输入输出形式及一些参数设定。黑盒攻击通常分为两类，一类是模型外攻击，攻击者完全不知道对手模型的内部结构，也就无法构造有效的对抗样本；另一类是模型内攻击，攻击者可以观察到对手模型的内部结构，依据模型的特点构造对抗样本，常用的方法有FGSM、BIM等。

## 2.3 PGD 攻击
PGD 是 Projected Gradient Descent （投影梯度下降）的缩写，是一种迭代优化算法。在攻击过程中，采用 PGD 可以快速找到靶机模型最优分类器的方向，然后沿着这个方向进行更细致的搜索，最终生成很好的攻击样本。PGD 算法的流程如下：

1. 初始化扰动 delta;
2. 求取每一个样本 x+delta 的预测值 y+ = F(x+delta);
3. 更新 delta : delta = clip(alpha * delta + epsilon * sign(grad_F(x+delta)), -epsilon, epsilon); alpha 表示学习速率，一般设置为0.01~0.1；epsilon 表示扰动幅度，一般设置为0.03~0.3；grad_F() 是输入 x+delta 的梯度值，可以用反向传播法求得；clip 函数限制了扰动的范围。
4. 重复 2-3 步，直至模型误分类错误或达到最大循环次数；
5. 返回最终的 delta 。

## 2.4 限制梯度
限制梯度（Constrained Gradient）是限制对手模型输出结果的梯度，使之符合期望值或约束条件，可以有效地减少无效攻击。对于二元分类问题来说，限制梯度可以分为两类，一类是 L1-约束，即限制输出值的绝对值大小；另一类是 L2-约束，即限制输出值的平方和大小。GNN-PGD 中使用的限制梯度可以分为三种类型：

1. L1-约束：在 GNN 抽取出的特征中选择贡献最小的一些特征，并令其对应的输出值等于0。这种方式即要求模型输出结果只包含关键特征，缺失部分输出值为0；
2. L2-约束：同样是在 GNN 抽取出的特征中选择贡献最小的一些特征，不过令它们的输出值的二范数等于1。这种方式会使得模型输出值的均方根变小，即特征的权重更加突出；
3. 多标签约束：在训练阶段，预测得到多个标签的概率分布，将其统一为单个标签的概率分布，然后再应用 L1 或 L2 约束。例如，预测多个国家的人口数量，实际只有一个国家是真正的目标国家，则可以通过将所有其他国家的概率都置为0来约束模型输出，使其仅预测正确的国家。

## 2.5 对抗训练
对抗训练是一种训练机器学习模型的方法，目的是让模型具备对抗性，即在正常情况下，模型应该做出正确的预测；在对抗攻击时，模型需要在输出分布上产生足够大的变化，以至于普通的防御机制检测不到它的存在。对抗训练的一个重要方法是扭曲函数（Distortion function），它会将正常的输入映射到一个扭曲后的输出空间。对抗训练常用的方法有 FAST、Virtual Adversarial Training、Adversarial Learning、BYOL、SimSiam 等。

# 3.核心算法原理和具体操作步骤以及数学公式讲解
## 3.1 GSM-PGD 方法
### 3.1.1 原理简介
GSM-PGD 采用 PGD 算法在 GSM 上进行攻击，首先生成扰动 delta，然后在更新 delta 时使用 GSM 生成的边缘概率分布以及 GNN 预测出的节点特征，来限制对手模型的输出分布，使之服从攻击者指定的 L1/L2 约束。GNN-PGD 方法的具体步骤如下：

1. 初始化扰动 delta;
2. 随机初始化目标节点 u，通过 GNN 预测出其特征 f_u;
3. 根据 GSM 生成的边缘概率分布生成 p_uv = Pr(v | u)，这里 v 是邻居节点，u 是源节点；
4. 如果 v 在 {N^-}_{i} 中，则选择 v 和 u，生成 delta^+(f_u, f_v) = clip(|f_u| / |p_uv| * grad_Q(f_u))，这里 Q 是假设的损失函数，如交叉熵损失；否则，如果 v 在 {N^{+}}_{i} 中，则选择 v 和 u，生成 delta^-(f_u, f_v) = clip(-|f_u| / |p_uv| * grad_Q(f_u))，这里 grad_Q(f_u) 是输入 f_u 的梯度值，通过反向传播求得；
5. 用 delta^+(f_u, f_v) 来更新 f_v，用 delta^-(f_u, f_v) 来更新 f_u;
6. 将 delta 乘以一个因子 gamma，gamma 是一个超参数，用来调整 delta 的大小；
7. 当 u 和 v 都邻接且 p_uv 大于 0 时，停止迭代；
8. 返回最终的 delta 。

### 3.1.2 优化目标函数
GSM-PGD 的优化目标函数可以看作是在 GSM 上的一个非凸目标函数。在正常情况下，对手模型应该生成具有目标分布的样本。但是由于 GSM 学习的局限性，导致模型过于倾向于生成弱有力的对抗样本，因此，我们需要限制对手模型生成的对抗样本的质量。GSM-PGD 提出的优化目标函数是：

maximize || delta^+ - delta^- ||_{\infty} + \lambda || H* - E_P [\frac{1}{2} \Vert X + D(\delta) - Z\Vert_2^2] + C ||_{\infty},

其中 delta^+, delta^- 为在 GSM-PGD 中的扰动，H* 为在 GNN-PGD 中的节点邻接矩阵；X 为原始样本，Z 为攻击样本；D(.) 为对抗扰动，C 为罚项参数 lambda。我们通过最大化上面这个函数，来限制对手模型生成的对抗样本的质量，同时鼓励模型适应对手模型的扰动分布。

### 3.1.3 实验结果
作者用不同模型结构的 GSM 和 GNN 训练模型，分别在 CIFAR-10 数据集上进行测试。测试结果表明，在对抗样本数量、成功率和时延方面，GSM-PGD 方法都比最新方法表现要好。

作者证明了 GSM-PGD 方法的理论有效性，即生成的对抗样本在某些方面与原始样本相似，而且能够满足给定的 L1/L2 约束。并且，作者通过实验验证了 GNN-PGD 方法的可行性，即 GNN-PGD 方法能够在一定程度上限制模型对抗性。

# 4.具体代码实例和解释说明
代码链接：https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/implementations/gsm_pgd/gsm_pgd.py