
作者：禅与计算机程序设计艺术                    

# 1.简介
         

卷积神经网络(CNN)近年来在图像识别、目标检测、视频分析等方面取得了广泛的成功，其在小数据量的情况下也取得了较好的效果。但是随着移动端的普及，设备硬件性能的提升和计算资源的限制，CNN在移动端的推广越来越受到限制。为了解决这个问题，作者们提出了一种新的模型——MobileNets——用来提升CNN在移动端上的效率。

MobileNets是基于深度可分离卷积（Depthwise Separable Convolution）的轻量化模型。它通过设计有效的低延迟算法来实现快速且准确的结果，并能在较少的参数数量下达到很高的精度。

本文将详细介绍MobileNets的结构和原理，并给出它的在不同数据集上的实验结果。

# 2.相关工作
MobileNets是作者们在深度学习领域里提出的一种新型模型。早期的一些模型如AlexNet、VGGNet、GoogLeNet都采用深度可分离卷积模块作为基本单元，能够在一定程度上降低参数量和计算量，并在同等的准确率下获得更好的效果。

不过，这些模型主要关注于解决单一任务的问题，比如图像分类、目标检测等。而对于移动端来说，它们的设计往往具有更快的响应时间要求，因此不能忽视对效率的追求。

# 3.模型架构
## 3.1 深度可分离卷积层 ( Depthwise Separable Convolution Layer )
深度可分离卷积 ( Depthwise Separable Convolution ) 是指对卷积进行拆分，即先执行一次普通卷积，然后再执行逐通道卷积。通过这种方式，可以减少模型中的参数数量，同时又保留了局部空间特征。

在传统卷积中，卷积核大小是固定的，这使得模型只能抽取到固定大小的局部空间信息。而深度可分离卷积则可以在保持全局特征的情况下，提取出多个尺度的信息。

## 3.2 模块组成
MobileNets由五个模块组合而成。每个模块包括三个卷积层，前两个卷积层带有ReLU激活函数，第三个卷积层没有激活函数。第一个模块的输入是原始输入图片；后续各个模块的输入都是前一个模块输出的结果，并且按照特征图尺寸逐步减小。这样做的好处是允许模型从多个尺度提取特征，并且不必担心过大的感受野导致计算量爆炸。


### 3.2.1 第一模块 Inverted Residual Block (IRB1)
IRB1由三个卷积层组成，第一个卷积层带有64个滤波器，第二个卷积层带有64个滤波器，第三个卷积层带有32个滤波器。前两个卷积层称作深度可分离卷积层，在宽高方向上分别执行两次。第二个卷积层在输入通道数上进行转置，最后得到的输出经过一次线性整流函数激活后送入下一个模块。

### 3.2.2 第二模块 Inverted Residual Block (IRB2)
IRB2和IRB1类似，只是第一个卷积层和第三个卷积层的滤波器个数不同。

### 3.2.3 第三模块 Inverted Residual Block (IRB3)
IRB3和IRB2类似，只是第一个卷积层的滤波器个数为96。

### 3.2.4 第四模块 Inverted Residual Block (IRB4)
IRB4和IRB3类似，但第一个卷积层的滤波器个数为320，并且在深度可分离卷积层上的执行次数增加了一倍。

### 3.2.5 Classifier block
最后的Classifier block没有激活函数，输出的是最终的预测结果。分类任务时用的最多的softmax函数。

## 3.3 模型参数量和FLOPs统计
MobileNets在ImageNet数据集上训练，其中每张图像的尺寸为224x224像素，输入通道数为3，输出类别数为1000。

模型总参数量为：
7,088,104 （M）
其中：
224 x 224 x 3 × 3 = 2,359,808
224 / (32 x 2) x 224 / (32 x 2) x 32 x 32 x 32 x 16 = 64
224 / (64 x 2) x 224 / (64 x 2) x 64 x 64 x 64 x 24 = 40
224 / (128 x 2) x 224 / (128 x 2) x 128 x 128 x 128 x 32 = 16
224 / (160 x 2) x 224 / (160 x 2) x 160 x 160 x 160 x 64 = 10
224 / (320 x 2) x 224 / (320 x 2) x 320 x 320 x 320 x 160 = 4

模型的FLOPs (Floating Operations Per Second) 分别是：
0.7 M * 10^6 （MFlops）
其中：
192 + 1472 + 1472 + 2560 + 320 + 320 + 12800 + 1000 = 1,232,640 FLOPS