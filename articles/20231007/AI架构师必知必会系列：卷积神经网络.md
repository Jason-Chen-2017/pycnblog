
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


## 概述
卷积神经网络（Convolutional Neural Network，CNN）是一种深度学习技术，通常被用来处理图像、视频和语音识别等多种模态数据。其特点在于通过对输入数据提取特征、学习到抽象特征并转换成输出，并在学习过程中解决了梯度消失和 vanishing 的问题，因此在图像分类、目标检测、人脸识别、文字识别等领域都取得了非常好的效果。而 CNN 作为最具代表性的深度学习技术之一，也是当下最火爆的 AI 技术方向之一。那么什么时候该用 CNN，什么时候不该用 CNN？下面我们就一起了解一下这两个问题吧！
## 为什么要用 CNN？
### 模型参数量少且易训练
首先来说说卷积层（convolution layer）的作用。卷积层从输入图像中提取高维空间结构信息，并进行非线性变换得到输出特征图（feature map）。同时它还引入了权重共享机制，即同一个权重被用于不同通道的卷积，使得网络的参数规模可以较大程度上减小，且计算量也降低。另外，通过池化层（pooling layer），可以进一步减少特征图大小，便于后续的全连接层处理。因此，对于具有相似模式或相关关系的输入数据，可以先利用卷积提取局部特征，再利用池化进行特征整合，最后进行更复杂的任务，如图像分类。因此，由于卷积层的位置无关性，所以参数量很少且易训练。
### 平移不变性、旋转不变性和尺度不变性
卷积神经网络中的卷积操作对平移不变性、旋转不变性和尺度不变性保持极高的自然性。例如，卷积核能够捕获图像中的目标，而不管它在图像中的位置如何移动或缩放。此外，通过引入池化层，能够实现不变性的最大化。池化层能够降低参数数量，并保持输入数据的大体分布，从而达到提升模型鲁棒性的目的。除此之外，另一个原因就是卷积神经网络中的权重共享机制能充分利用先验知识，从而有效地缓解过拟合的问题。
### 稠密连接网络容易收敛且精度高
卷积神经网络在设计时为了增加网络的深度、宽度和丰富性，采用了稠密连接网络。网络的每一个隐藏层都会接收来自上一层的所有节点的输入信号。这样做的好处是方便了梯度传播，并且能够加快模型的收敛速度。另外，通过降低网络的参数数量，训练过程更容易收敛，模型的精度也较高。
### 特征提取能力强
卷积神经网络在图像识别、目标检测、人脸识别、行为分析、声音识别等方面都取得了显著的成果。这些应用的共同特点在于需要识别或检测出某些特征的存在。而通过卷积操作和池化操作，卷积神经网络能够自动从数据中提取这种特征，并且学习到这种特征的有效表示。因此，卷积神经网络在各个领域都有着广泛的应用前景。
### 其它优点
- 参数共享：卷积核权重共享使得参数规模较小，可以在多尺寸输入上训练；
- 深度可分离性：通过引入跳跃连接，卷积层能够将前面的特征学习成一组特征，提取全局信息；
- 缺陷可纠正：在一定程度上能够避免梯度消失、减少模型参数的数量；
- 普适性：卷积神经网络所学习到的特征是通用的，既可以用于图像、文本、语音等各类模态的数据，也可以用于其他类型的数据。
## 为什么不要用 CNN？
### 数据量太大时不能采用 CNN
卷积神经网络是一个深度学习方法，它需要大量的数据来训练模型。而一般来说，图像、文本、语音等各种模态的数据都是比起文本数据量更大的。因此，如果我们处理的数据量很大的话，就没有必要使用 CNN 来训练我们的模型。而且，CNN 在训练的时候需要占用大量的 GPU 资源，也会严重拖慢整个训练过程。
### 时间计算需求大
在图像分类等问题上，CNN 虽然表现出了良好的性能，但是训练的时间往往是其他深度学习方法的几十倍，而且无法并行化。因此，对于那些处理时间要求比较苛刻的应用场景，比如工业界的监控摄像头实时跟踪等，还是用传统的方法吧。