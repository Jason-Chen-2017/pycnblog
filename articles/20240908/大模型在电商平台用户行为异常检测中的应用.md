                 

### 主题：大模型在电商平台用户行为异常检测中的应用

#### 相关领域的典型问题/面试题库

##### 1. 如何设计一个基于大模型的用户行为异常检测系统？

**答案解析：**

设计一个基于大模型的用户行为异常检测系统，可以分为以下几个步骤：

1. **数据收集与预处理：** 收集用户在电商平台上的行为数据，如浏览历史、购买记录、搜索关键词、评论等。对数据进行清洗、归一化和特征提取，为模型训练提供高质量的数据。

2. **模型选择：** 根据用户行为数据的特点，选择合适的大模型。例如，可以选用深度学习中的卷积神经网络（CNN）、循环神经网络（RNN）或Transformer模型。对于时间序列数据，RNN和Transformer模型表现较好；对于图像和文本数据，CNN和Transformer模型较为适合。

3. **特征工程：** 对原始数据进行特征提取，将连续的数值特征进行离散化，将类别特征进行编码。对于文本数据，可以使用词嵌入（word embedding）技术将文本转化为向量表示。

4. **模型训练：** 使用训练集对模型进行训练。训练过程中，可以通过调整模型参数、优化算法和超参数来提高模型性能。

5. **模型评估：** 使用验证集对模型进行评估，根据评估指标（如准确率、召回率、F1值等）选择最佳模型。

6. **模型部署：** 将训练好的模型部署到实际生产环境中，实时检测用户行为异常。在部署过程中，需要考虑模型的计算资源需求、响应速度和可扩展性。

**示例代码：**

```python
# 假设已经完成数据收集、预处理和特征提取
train_data, val_data = ...

# 选择合适的深度学习框架，如TensorFlow或PyTorch
import tensorflow as tf

# 定义模型架构
model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=128, activation='relu', input_shape=(num_features,)),
    tf.keras.layers.Dense(units=1, activation='sigmoid')
])

# 编译模型
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# 训练模型
model.fit(train_data, epochs=10, validation_data=val_data)

# 评估模型
accuracy = model.evaluate(val_data)
print("Validation accuracy:", accuracy[1])
```

##### 2. 如何处理异常检测中的数据不平衡问题？

**答案解析：**

在异常检测中，数据不平衡问题可能会导致模型性能下降。以下是一些处理数据不平衡问题的方法：

1. **过采样（Over-sampling）：** 增加少数类样本的数量，使得训练集的分布更加均匀。例如，可以使用复制或随机生成的方式增加异常类样本的数量。

2. **欠采样（Under-sampling）：** 减少多数类样本的数量，使得训练集的分布更加均匀。例如，可以使用随机删除的方式减少正常类样本的数量。

3. **合成少数类样本（Synthetic Minority Class Generation）：** 使用合成方法生成少数类样本，如SMOTE算法。

4. **调整分类器权重：** 在模型训练过程中，可以调整不同类别的权重，使得模型更加关注少数类样本。

5. **集成学习方法：** 结合多个不同的模型，通过投票或加权平均的方式提高模型对异常类样本的识别能力。

**示例代码：**

```python
# 假设已经完成数据预处理
X_train, y_train = ...

# 调整分类器权重
class_weights = {0: 1, 1: 5}  # 正常类权重为1，异常类权重为5

# 使用SMOTE算法生成合成少数类样本
from imblearn.over_sampling import SMOTE

smote = SMOTE()
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# 训练模型
model.fit(X_train_resampled, y_train_resampled, epochs=10, class_weight=class_weights)
```

##### 3. 如何在异常检测中评估模型性能？

**答案解析：**

在异常检测中，评估模型性能的指标与传统分类问题有所不同。以下是一些常用的评估指标：

1. **准确率（Accuracy）：** 衡量模型正确识别异常类和正常类的比例。但在数据不平衡的情况下，准确率可能不具有参考价值。

2. **召回率（Recall）：** 衡量模型正确识别异常类的比例。召回率越高，模型对异常类的识别能力越强。

3. **精确率（Precision）：** 衡量模型正确识别异常类的比例。精确率越高，模型对异常类的识别精度越高。

4. **F1值（F1-score）：** 是精确率和召回率的加权平均，综合考虑模型对异常类的识别能力和识别精度。

5. **ROC曲线和AUC值（Receiver Operating Characteristic Curve and Area Under Curve）：** 用于评估模型在所有阈值下的分类性能。AUC值越高，模型的分类性能越好。

6. **成本敏感度分析（Cost-sensitive Analysis）：** 考虑不同类别错误分类的成本，对不同类别设置不同的权重，评估模型在成本敏感度下的性能。

**示例代码：**

```python
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score

# 假设已经完成模型预测
y_pred = model.predict(X_test)

# 计算评估指标
accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)
roc_auc = roc_auc_score(y_test, y_pred)

print("Accuracy:", accuracy)
print("Recall:", recall)
print("Precision:", precision)
print("F1-score:", f1)
print("ROC-AUC:", roc_auc)
```

##### 4. 如何应对异常检测中的冷启动问题？

**答案解析：**

在异常检测中，冷启动问题指的是当新用户或新商品首次出现在数据集中时，模型难以对其行为进行准确预测。以下是一些应对冷启动问题的方法：

1. **使用元学习（Meta-Learning）：** 在训练过程中，引入元学习算法，使得模型能够快速适应新用户或新商品的行为特征。

2. **基于规则的检测方法：** 使用基于规则的方法，根据业务知识对新的用户或商品进行初步筛选，降低冷启动对模型性能的影响。

3. **使用迁移学习（Transfer Learning）：** 使用已在其他任务上训练好的模型作为预训练模型，对新用户或新商品进行微调，提高模型对新数据的适应能力。

4. **动态学习率调整：** 在新用户或新商品加入数据集后，动态调整学习率，使得模型能够更快地适应新数据。

**示例代码：**

```python
# 假设已经完成模型训练
model = ...

# 新用户或新商品加入数据集
new_data = ...

# 使用迁移学习进行微调
model.fit(new_data, epochs=5, initial_epoch=len(X_train) // batch_size)

# 重新评估模型性能
accuracy = model.evaluate(X_test, y_test)
print("Accuracy:", accuracy[1])
```

##### 5. 如何在异常检测中处理实时数据流？

**答案解析：**

在异常检测中，处理实时数据流需要考虑以下几个方面：

1. **数据采集与存储：** 使用分布式数据采集框架（如Fluentd、Logstash等），实时收集用户行为数据。使用分布式存储系统（如Hadoop、HBase等），存储大量实时数据。

2. **实时数据处理：** 使用分布式数据处理框架（如Apache Storm、Apache Flink等），对实时数据进行预处理、特征提取和模型预测。

3. **模型更新与部署：** 根据实时数据流，定期更新模型参数，提高模型在实时数据上的性能。使用容器化技术（如Docker、Kubernetes等），快速部署和更新模型。

4. **实时监控与报警：** 使用实时监控系统（如Prometheus、Grafana等），监控模型性能和系统资源使用情况。当模型性能下降或系统资源不足时，自动触发报警。

**示例代码：**

```python
# 假设已经完成实时数据处理框架的配置
from flink import ...

# 实时处理用户行为数据
stream = ...

stream.map(process_data).map(extract_features).map(predict).print()

# 定期更新模型参数
model.fit(new_data, epochs=5, initial_epoch=len(X_train) // batch_size)

# 实时监控模型性能
监控系统 = ...
监控系统.add_metric(accuracy, "model_accuracy")
```

##### 6. 如何在异常检测中处理隐私保护问题？

**答案解析：**

在异常检测中，隐私保护问题是一个重要的考虑因素。以下是一些处理隐私保护问题的方法：

1. **数据匿名化：** 在数据收集和存储过程中，对用户行为数据进行匿名化处理，隐藏用户身份信息。

2. **差分隐私（Differential Privacy）：** 在模型训练过程中，使用差分隐私算法，使得模型对个人隐私信息的依赖性降低。

3. **联邦学习（Federated Learning）：** 在多个参与方之间共享模型参数，而不需要共享原始数据。通过这种方式，可以在保护用户隐私的同时，提高模型性能。

4. **安全多方计算（Secure Multi-party Computation）：** 在多方参与的计算过程中，确保数据的安全性和隐私性。

**示例代码：**

```python
# 假设已经完成数据匿名化和联邦学习框架的配置
from federated_learning import ...

# 训练联邦学习模型
model.fit(federated_data)

# 更新本地模型
model.update_local_model()

# 预测用户行为
predictions = model.predict(new_data)
```

#### 算法编程题库

##### 1. 实现一个基于 k-均值聚类算法的用户行为聚类模型。

**题目描述：**

实现一个基于 k-均值聚类算法的用户行为聚类模型，输入用户行为数据，输出用户行为聚类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- k：聚类个数。

**输出：**

- 聚类结果：一个包含用户所属聚类编号的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
k = 2

输出：
cluster_assignment = [0, 1, 1, 0]
```

**参考代码：**

```python
import numpy as np

def k_means_clustering(user_behaviors, k):
    # 初始化聚类中心
    centroids = user_behaviors[np.random.choice(user_behaviors.shape[0], k, replace=False)]

    # 循环迭代，直到聚类中心不再变化
    while True:
        # 计算每个用户与聚类中心的距离
        distances = np.linalg.norm(user_behaviors - centroids, axis=1)

        # 分配用户到最近的聚类中心
        cluster_assignment = np.argmin(distances, axis=1)

        # 更新聚类中心
        new_centroids = np.array([user_behaviors[cluster_assignment == i].mean(axis=0) for i in range(k)])

        # 检查聚类中心是否变化
        if np.all(centroids == new_centroids):
            break

        centroids = new_centroids

    return cluster_assignment

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
k = 2

cluster_assignment = k_means_clustering(user_behaviors, k)
print(cluster_assignment)
```

##### 2. 实现一个基于 KNN（K-近邻）算法的用户行为分类模型。

**题目描述：**

实现一个基于 KNN（K-近邻）算法的用户行为分类模型，输入用户行为数据，输出用户行为分类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- 标签数据：一个包含用户行为标签的向量。

- k：近邻个数。

**输出：**

- 分类结果：一个包含用户行为分类结果的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]
k = 2

输出：
predicted_labels = [0, 1, 1, 0]
```

**参考代码：**

```python
import numpy as np

def euclidean_distance(point1, point2):
    return np.linalg.norm(point1 - point2)

def knn_classification(user_behaviors, labels, k):
    # 计算每个用户与测试数据的欧几里得距离
    distances = np.array([euclidean_distance(user_behaviors[i], test_point) for i in range(len(user_behaviors))])

    # 获取距离最近的 k 个邻居及其标签
    nearest_neighbors = np.argpartition(distances, k)[:k]
    nearest_neighbor_labels = labels[nearest_neighbors]

    # 计算每个邻居的投票权重
    weights = 1 / (distances[nearest_neighbors] + 1e-5)

    # 计算分类结果
    predicted_label = np.argmax(np.average(nearest_neighbor_labels, axis=0, weights=weights))

    return predicted_label

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]
k = 2

test_point = [5, 5, 5]
predicted_labels = [knn_classification(user_behaviors, labels, k) for _ in range(len(user_behaviors))]
print(predicted_labels)
```

##### 3. 实现一个基于决策树的用户行为分类模型。

**题目描述：**

实现一个基于决策树算法的用户行为分类模型，输入用户行为数据，输出用户行为分类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- 标签数据：一个包含用户行为标签的向量。

**输出：**

- 分类结果：一个包含用户行为分类结果的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

输出：
predicted_labels = [0, 1, 1, 0]
```

**参考代码：**

```python
from sklearn.tree import DecisionTreeClassifier

def decision_tree_classification(user_behaviors, labels):
    # 创建决策树分类器
    clf = DecisionTreeClassifier()

    # 训练模型
    clf.fit(user_behaviors, labels)

    # 预测分类结果
    predicted_labels = clf.predict(user_behaviors)

    return predicted_labels

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

predicted_labels = decision_tree_classification(user_behaviors, labels)
print(predicted_labels)
```

##### 4. 实现一个基于朴素贝叶斯算法的用户行为分类模型。

**题目描述：**

实现一个基于朴素贝叶斯算法的用户行为分类模型，输入用户行为数据，输出用户行为分类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- 标签数据：一个包含用户行为标签的向量。

**输出：**

- 分类结果：一个包含用户行为分类结果的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

输出：
predicted_labels = [0, 1, 1, 0]
```

**参考代码：**

```python
from sklearn.naive_bayes import GaussianNB

def naive_bayes_classification(user_behaviors, labels):
    # 创建高斯朴素贝叶斯分类器
    clf = GaussianNB()

    # 训练模型
    clf.fit(user_behaviors, labels)

    # 预测分类结果
    predicted_labels = clf.predict(user_behaviors)

    return predicted_labels

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

predicted_labels = naive_bayes_classification(user_behaviors, labels)
print(predicted_labels)
```

##### 5. 实现一个基于支持向量机（SVM）的用户行为分类模型。

**题目描述：**

实现一个基于支持向量机（SVM）算法的用户行为分类模型，输入用户行为数据，输出用户行为分类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- 标签数据：一个包含用户行为标签的向量。

**输出：**

- 分类结果：一个包含用户行为分类结果的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

输出：
predicted_labels = [0, 1, 1, 0]
```

**参考代码：**

```python
from sklearn.svm import SVC

def svm_classification(user_behaviors, labels):
    # 创建支持向量机分类器
    clf = SVC()

    # 训练模型
    clf.fit(user_behaviors, labels)

    # 预测分类结果
    predicted_labels = clf.predict(user_behaviors)

    return predicted_labels

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

predicted_labels = svm_classification(user_behaviors, labels)
print(predicted_labels)
```

##### 6. 实现一个基于神经网络的用户行为分类模型。

**题目描述：**

实现一个基于神经网络算法的用户行为分类模型，输入用户行为数据，输出用户行为分类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- 标签数据：一个包含用户行为标签的向量。

**输出：**

- 分类结果：一个包含用户行为分类结果的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

输出：
predicted_labels = [0, 1, 1, 0]
```

**参考代码：**

```python
import tensorflow as tf

def neural_network_classification(user_behaviors, labels):
    # 创建神经网络模型
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(units=64, activation='relu', input_shape=(user_behaviors.shape[1],)),
        tf.keras.layers.Dense(units=32, activation='relu'),
        tf.keras.layers.Dense(units=1, activation='sigmoid')
    ])

    # 编译模型
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # 训练模型
    model.fit(user_behaviors, labels, epochs=10)

    # 预测分类结果
    predicted_labels = model.predict(user_behaviors)
    predicted_labels = np.round(predicted_labels)

    return predicted_labels

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

predicted_labels = neural_network_classification(user_behaviors, labels)
print(predicted_labels)
```

##### 7. 实现一个基于迁移学习的用户行为分类模型。

**题目描述：**

实现一个基于迁移学习的用户行为分类模型，输入用户行为数据，输出用户行为分类结果。

**输入：**

- 用户行为数据：一个包含用户行为特征的矩阵，每行表示一个用户的行为特征。

- 标签数据：一个包含用户行为标签的向量。

**输出：**

- 分类结果：一个包含用户行为分类结果的向量。

**示例：**

```
输入：
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

输出：
predicted_labels = [0, 1, 1, 0]
```

**参考代码：**

```python
import tensorflow as tf
from tensorflow.keras.applications import VGG16

def transfer_learning_classification(user_behaviors, labels):
    # 加载预训练的 VGG16 模型，去除最后的全连接层
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
    base_model.trainable = False

    # 创建神经网络模型，添加全连接层和输出层
    model = tf.keras.Sequential([
        base_model,
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(units=64, activation='relu'),
        tf.keras.layers.Dense(units=1, activation='sigmoid')
    ])

    # 编译模型
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

    # 训练模型
    model.fit(user_behaviors, labels, epochs=10)

    # 预测分类结果
    predicted_labels = model.predict(user_behaviors)
    predicted_labels = np.round(predicted_labels)

    return predicted_labels

# 示例
user_behaviors = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 9],
    [10, 11, 12]
]
labels = [0, 1, 1, 0]

predicted_labels = transfer_learning_classification(user_behaviors, labels)
print(predicted_labels)
```

#### 完整代码示例

以下是一个完整的代码示例，演示了如何使用大模型在电商平台用户行为异常检测中的应用。

```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.applications import VGG16

# 加载用户行为数据
user_behaviors = pd.read_csv('user_behaviors.csv')
labels = pd.read_csv('labels.csv')

# 数据预处理
user_behaviors = user_behaviors.dropna()
labels = labels[~user_behaviors.index.duplicated(keep='first')]

# 特征提取
X = user_behaviors.values
y = labels.values

# 数据分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# KNN 分类
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, y_train)
predicted_knn = knn.predict(X_test)

# 决策树分类
dt = DecisionTreeClassifier()
dt.fit(X_train, y_train)
predicted_dt = dt.predict(X_test)

# 朴素贝叶斯分类
nb = GaussianNB()
nb.fit(X_train, y_train)
predicted_nb = nb.predict(X_test)

# 支持向量机分类
svm = SVC()
svm.fit(X_train, y_train)
predicted_svm = svm.predict(X_test)

# 神经网络分类
nn = Sequential([
    Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(units=32, activation='relu'),
    Dense(units=1, activation='sigmoid')
])
nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
nn.fit(X_train, y_train, epochs=10)
predicted_nn = nn.predict(X_test)

# 迁移学习分类
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
vgg16.trainable = False
model = Sequential([
    vgg16,
    Flatten(),
    Dense(units=64, activation='relu'),
    Dense(units=1, activation='sigmoid')
])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=10)
predicted_tnl = model.predict(X_test)

# 评估分类结果
accuracy_knn = accuracy_score(y_test, predicted_knn)
recall_knn = recall_score(y_test, predicted_knn)
precision_knn = precision_score(y_test, predicted_knn)
f1_knn = f1_score(y_test, predicted_knn)
roc_auc_knn = roc_auc_score(y_test, predicted_knn)

accuracy_dt = accuracy_score(y_test, predicted_dt)
recall_dt = recall_score(y_test, predicted_dt)
precision_dt = precision_score(y_test, predicted_dt)
f1_dt = f1_score(y_test, predicted_dt)
roc_auc_dt = roc_auc_score(y_test, predicted_dt)

accuracy_nb = accuracy_score(y_test, predicted_nb)
recall_nb = recall_score(y_test, predicted_nb)
precision_nb = precision_score(y_test, predicted_nb)
f1_nb = f1_score(y_test, predicted_nb)
roc_auc_nb = roc_auc_score(y_test, predicted_nb)

accuracy_svm = accuracy_score(y_test, predicted_svm)
recall_svm = recall_score(y_test, predicted_svm)
precision_svm = precision_score(y_test, predicted_svm)
f1_svm = f1_score(y_test, predicted_svm)
roc_auc_svm = roc_auc_score(y_test, predicted_svm)

accuracy_nn = accuracy_score(y_test, predicted_nn)
recall_nn = recall_score(y_test, predicted_nn)
precision_nn = precision_score(y_test, predicted_nn)
f1_nn = f1_score(y_test, predicted_nn)
roc_auc_nn = roc_auc_score(y_test, predicted_nn)

accuracy_tnl = accuracy_score(y_test, predicted_tnl)
recall_tnl = recall_score(y_test, predicted_tnl)
precision_tnl = precision_score(y_test, predicted_tnl)
f1_tnl = f1_score(y_test, predicted_tnl)
roc_auc_tnl = roc_auc_score(y_test, predicted_tnl)

# 打印评估结果
print("KNN:")
print("Accuracy:", accuracy_knn)
print("Recall:", recall_knn)
print("Precision:", precision_knn)
print("F1-score:", f1_knn)
print("ROC-AUC:", roc_auc_knn)

print("Decision Tree:")
print("Accuracy:", accuracy_dt)
print("Recall:", recall_dt)
print("Precision:", precision_dt)
print("F1-score:", f1_dt)
print("ROC-AUC:", roc_auc_dt)

print("Naive Bayes:")
print("Accuracy:", accuracy_nb)
print("Recall:", recall_nb)
print("Precision:", precision_nb)
print("F1-score:", f1_nb)
print("ROC-AUC:", roc_auc_nb)

print("SVM:")
print("Accuracy:", accuracy_svm)
print("Recall:", recall_svm)
print("Precision:", precision_svm)
print("F1-score:", f1_svm)
print("ROC-AUC:", roc_auc_svm)

print("Neural Network:")
print("Accuracy:", accuracy_nn)
print("Recall:", recall_nn)
print("Precision:", precision_nn)
print("F1-score:", f1_nn)
print("ROC-AUC:", roc_auc_nn)

print("Transfer Learning:")
print("Accuracy:", accuracy_tnl)
print("Recall:", recall_tnl)
print("Precision:", precision_tnl)
print("F1-score:", f1_tnl)
print("ROC-AUC:", roc_auc_tnl)
```

