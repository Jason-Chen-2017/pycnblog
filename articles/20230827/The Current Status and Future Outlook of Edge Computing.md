
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Edge computing refers to a class of cloud-based services that are designed for the processing and storage of data at the periphery or near the source of information, where it is accessed by users who need quick access to critical information but may be physically distant from the center of the network. Traditional edge servers have been centralized in some locations such as branch offices, while others have emerged as standalone devices with their own computational power and networking capabilities. Edge computing has received significant attention over the past few years due to its promising potential in reducing latency and improving overall system performance. However, there remains much to learn about this rapidly evolving field and future research opportunities are plentiful. In this article, we will review recent advances and challenges in the field, highlighting key concepts, algorithms, and technical approaches. We also discuss current technology trends and explore how these advancements can further shape our understanding of the role of edge computing in today’s global economy and society. Finally, we offer recommendations for future directions and call out current limitations and gaps. 

# 2.基本概念术语说明
## 2.1. What is Edge Computing? 
Edge computing refers to a class of cloud-based services that are designed for the processing and storage of data at the periphery or near the source of information, where it is accessed by users who need quick access to critical information but may be physically distant from the center of the network. Edge computing technologies include hardware platforms such as routers, gateways, and smart sensors that are deployed close to the end user's location, allowing them to receive real-time data and provide various services such as machine learning inference, pattern detection, and security monitoring without relying on interconnected systems in the cloud. This allows businesses to gain new insights into customer behavior, monitor industrial processes, track assets, and analyze financial transactions more quickly than traditional solutions based on wide-area networks (WAN) and complex architectures. While the concept of edge computing was first proposed by Napster and Google, the term has become more widely known since the early days of the Internet and the rise of cloud computing.


## 2.2. Key Terms and Concepts  
- **Cloud**: Cloud computing refers to a model of service delivery where shared resources like network bandwidth, software, and storage are provided as a utility to customers on demand. Essentially, cloud providers host virtual machines that users can run applications on, which can store and process large volumes of data using distributed computing techniques. Cloud computing has become an integral part of modern business operations and enables companies to scale up and down their IT infrastructure quickly and easily, according to demand. Examples of popular public clouds include Amazon Web Services, Microsoft Azure, and Google Cloud Platform.

- **IoT**: IoT stands for internet of things, which is a subset of the Internet of Things (IoT), which encompasses all aspects of the physical world around us including electronics, mechanical components, appliances, etc., connected through communication protocols and standard interfaces. IoT devices collect data and send it back to the cloud, enabling organizations to build intelligent systems that can act autonomously, improve efficiency, reduce costs, increase productivity, and unlock new revenue streams. One example of an IoT device is a self-driving car that sends sensor readings to a cloud server, analyzes them, determines appropriate actions, and controls the vehicle's movement accordingly. Another use case involves smart refrigerators that leverage IoT technologies to detect when food is left in the fridge and automatically dispense water cisterns within range. These examples demonstrate how edge computing can enable novel and impactful products and services for consumers, businesses, and governments alike.

- **Edge Node**: An edge node is a computer located at the periphery of a network that serves to perform computationally intensive tasks and transmit data across a distance. It typically consists of specialized processors, memory, and networking hardware capable of running complex applications such as machine learning algorithms or video streaming, depending on the needs of the application domain. Edge nodes often come equipped with additional peripherals such as sensors, cameras, microphones, speakers, and display screens, making them well-suited for performing real-time data analysis and other compute-intensive tasks. Common uses cases include robotics, mobile analytics, industrial automation, motion control, and augmented reality applications.

- **Network Function Virtualization (NFV)** : Network function virtualization (NFV) is a method of virtualizing network functions (NFs) that combines multiple virtualized instances of identical network functions onto a single NF-VI platform. By leveraging NFV, enterprises can achieve higher density and resiliency compared to monolithic NF deployments, while still providing similar levels of service and flexibility. Specifically, NFV provides the ability to optimize resource utilization, cost effectiveness, and agility, while ensuring compliance and securing network traffic flow. Furthermore, NFV offers scalability, elasticity, mobility, and redundancy, making it ideal for dynamic environments with changing workload requirements. Additionally, NFV reduces operational overhead, making it easier to manage and operate hybrid NFV/CNF networks.

- **Microservices Architecture**: Microservices architecture refers to a design approach that structures an application as a collection of loosely coupled services, each implementing a small set of features or functionalities. Each service runs in its own container and communicates with other services via HTTP APIs. This architectural style makes it easier to develop, test, deploy, and scale individual services independently of other parts of the system. Microservices make it easy to break down complex systems into smaller, modular pieces that can be developed, tested, scaled, and updated individually. Popular open-source frameworks such as Docker Swarm, Kubernetes, and Apache Mesos support microservices architecture.

- **Fog Computing**: Fog computing is a type of cloud computing technique that exploits the characteristics of geographic distribution and heterogeneity in order to maximize resource usage. Fog computing consists of computing devices that are closer to the source of data and communicate directly with those devices rather than connecting to the cloud via WAN links. Fog nodes aggregate local data and distribute it to nearby fog devices, effectively extending the reach of cloud-based services to users physically far away from the cloud provider. There are three main types of fog computing: Mobile Fog, Wireless Local Area Networks (WLAN-LAN) Fog, and Collaborative Fog. Examples of fog computing include disaster recovery scenarios, environmental monitoring, healthcare industry, and medical imaging. Despite the benefits, deploying fog computing requires careful planning, implementation, testing, and optimization, which takes time and effort. Therefore, it is essential to continuously evaluate the latest techniques and tools in the field to ensure they continue to deliver value for businesses and consumers. 


## 2.3. Edge Devices vs Edge Servers
There are two main categories of edge servers - edge devices and edge servers. Both types of devices serve different purposes and differ in terms of form factor, size, and connectivity options. Some differences between edge devices and edge servers are summarized below:

**Edge Device:**

- Size: Edge devices usually consist of low-cost personal computers or tablets, smartphones, or IoT devices that are powered by batteries. They are suitable for battery-powered applications and workloads that do not require high availability or fault tolerance. Typical sizes range from a few kilobytes to several megabytes of memory and disk space.

- Connectivity: Edge devices connect to the wireless network or cellular base stations, making them ideal for applications requiring high bandwidth and low delay. They can also be configured with wired connections for specific applications, such as video streaming or VoIP calls. They are limited by the available radio spectrum and cannot reliably handle high traffic rates or network congestion.

- Cost: Edge devices are generally cheaper to purchase compared to edge servers because they consume less power and are optimized for low-latency and low-power consumption. Moreover, edge devices tend to be more secure and have fewer attack vectors than edge servers. However, edge devices are best suited for simple edge-computing applications that require minimal processing or computing power.

**Edge Server:**

- Size: Edge servers typically have larger sizes and feature high computing power. They are designed to handle massive amounts of data or workloads that are sensitive to latency and throughput constraints. They vary in size ranging from tens of gigabytes to hundreds of terabytes of hard drive capacity.

- Connectivity: Edge servers typically rely on broadband internet connectivity, so they are well-suited for applications that require reliable connections and fast transfer speeds. They are also commonly deployed behind firewalls or proxies to protect against malicious activities.

- Cost: Edge servers are generally more expensive to buy than edge devices because they have significantly higher power and cooling requirements. Moreover, they are subject to higher security risks due to their complexity and greater dependency on third parties. However, they are best suited for applications that require high computing power, reliability, and high availability.



# 3.Core Algorithms and Technical Approaches  

## 3.1. Distributed Hash Tables (DHT)
A DHT is a distributed hash table that stores key-value pairs in a decentralized way using peer-to-peer (P2P) protocols. The primary goal of a DHT is to distribute keys evenly among nodes in the network to avoid any one entity having too many keys. As nodes join and leave the network, the number of buckets and key distributions change dynamically. To resolve conflicts during key lookups, the DHT uses a routing algorithm called Kademlia. When looking up a key, the client first selects a random node from the list of active nodes and requests the key-value pair from that node. If the key is not found, the client continues the search along a path towards another node until either the key is found or no more nodes remain. This approach works well under normal conditions but can lead to slow lookup times if there are frequent changes in membership or load balancing is uneven. There have been many improvements in DHT algorithms over the last couple of years, including Optimized PING (OPT), Recursive Routing (RRT), and Improvements to Kademlia (KAD).


Anomaly Detection: DHTs can be used for anomaly detection by storing metrics collected from different sources such as temperature, humidity, and ambient light level. Clients can periodically push updates to the DHT and then query for patterns that indicate abnormal behavior. For instance, clients could check for sudden increases in temperature or decrease in humidity levels that occur frequently outside typical operating parameters. Alternatively, DHTs can be combined with clustering algorithms to identify groups of nodes that behave similarly and potentially share common patterns. These patterns can be correlated with historical data to determine the root cause of the issue and take corrective action.

Caching: Caching improves response time and saves bandwidth by retrieving frequently requested data from the cache instead of querying the origin server. DHTs can be used to implement caching strategies by storing frequently queried objects such as images, videos, and documents. Clients can selectively push copies of these objects to neighboring nodes to create a cache overlay. When a request comes in for a cached object, the closest neighbor caches the object locally and returns it to the client. If the object is not present in the cache, the client can retrieve it from the origin server and update its copy in the cache before returning it to the user.

Load Balancing: Load balancing ensures that incoming requests are evenly distributed among nodes to prevent overload and improve responsiveness. With DHTs, clients can register themselves as available resources and advertise their capacity to other peers. Peers then distribute requests between available resources to minimize response time. Similar to DNS load balancers, DHTs can be implemented using various algorithms such as Consistent Hashing (CH) or Rendezvous Hashing (RH). CH partitions the keyspace into equal sized intervals and assigns nodes to those intervals. RH chooses nodes randomly based on a predefined seed or XOR of IP addresses, MAC addresses, or other unique identifiers. 

## 3.2. Push Technology
Push technology involves sending notifications or messages to mobile phones, tablets, or laptops in real-time whenever certain events happen. For example, when a user receives a message, a push notification can alert them immediately. Push messaging can be done using a variety of technologies such as Apple APNS (Apple Push Notification Service), Firebase Cloud Messaging (FCM), webpush, or SMS text messages. The choice of technology depends on the target audience, frequency of pushes, desired content, and other factors such as sender cost, recipient preferences, and regulatory requirements. Push technologies are becoming increasingly popular due to their convenience and lower cost compared to other alternatives such as email marketing campaigns.