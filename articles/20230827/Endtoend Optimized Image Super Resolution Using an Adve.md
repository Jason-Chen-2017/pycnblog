
作者：禅与计算机程序设计艺术                    

# 1.简介
  

图像超分辨率(Image Super Resolution,ISR)是指通过某种手段将低分辨率(Low-resolution, LR)图像提高到高分辨率(High-resolution, HR)图像的过程。通常情况下，ISR是指从低分辨率图像恢复其对应的高分辨率图像。由于传感器、传播方法等因素的限制，低分辨率图像的采集和生成都是一件困难且昂贵的工作。因此，采用ISR对图像进行放大，可以极大的增加其利用价值和广泛性。目前，有很多基于深度学习的ISR模型，它们可以将低分辨率图像提升至与原始图像相同或更高的分辨率，而且还可以避免传统方法中的模糊、锯齿等 artifacts 的产生。但是，这些模型往往都不是端到端训练的，即它们仅仅是学习了单一的网络结构。为了能够在真实场景中使用，需要在网络设计上进行改进。本文提出了一个全新的基于生成对抗网络(Generative Adversarial Networks,GANs)的端到端优化的图像超分辨率模型，该模型同时学习HR图像和LR图像之间的映射关系，并不断提升生成质量，同时保持对抗网络的稳定性。该模型能够将复杂的高频信息保存在低分辨率图像中，并根据网络自身的输出生成精细的高分辨率图像。文章总结了目前已有的基于GANs的ISR模型的一些缺陷，并提供了一种新的ISR模型——EDSR，通过引入重建损失函数和特征一致性损失函数，提升生成质量并保留对抗网络的稳定性。最后，论文还给出了实验结果，展示了该模型的有效性和性能。综合来说，本文的创新之处在于：第一，提出了一套基于GANs的ISR模型——EDSR，通过引入重建损失函数和特征一致性损失函数，提升生成质量并保留对抗网络的稳定性；第二，介绍了对抗训练的训练策略，以及如何训练ESRGAN及其他基于GANs的ISR模型，取得了比较好的效果；第三，对当前基于GANs的ISR模型进行了分析和总结，为下一步的研究和开发提供借鉴。
# 2.基本概念术语说明
## 2.1 GANs
 Generative Adversarial Networks (GANs), 2014 年由 Ian Goodfellow, Ilya et al. 提出的一种对抗训练（adversarial training）的方法，被认为是最先进的无监督学习技术之一。GANs 在 GAN (Generative Adversary) 与 Discriminator (判别器) 的交互过程中不断优化自己的参数，使得生成器（Generator）产生越来越逼真的样本，而判别器（Discriminator）也在识别生成器的“假”图片，并反馈给训练进程提供宝贵的信息。换句话说，生成器负责生成看起来像真实图片的图片，而判别器则相当于一个好坏无所不能的审核员，可以帮助判断生成样本是否真实。其主要特点包括：
 - 生成模型：通过判别器学习数据分布，通过生成器生成分布，从而实现数据的高效生成。
 - 对抗训练：生成器和判别器作为博弈的两个方面，通过梯度下降的方法不断更新自己参数，以此达到一个平衡的状态。
 - 概率密度估计：生成器学习概率密度函数 p_G(x)，而判别器则需要区分 p_G 和真实数据分布之间的差异。
 - 标签伪造攻击：GAN 并没有采用真实标签，而是直接预测输出属于哪个类别，从而可以有效防止标签泄露问题。

## 2.2 EDSR
 ED 模型全称是Enhanced Deep Residual Networks for Single Image Super-Resolution, 是继 ESRGAN 以后的另一种图像超分辨率模型。它与 ESRGAN 有着类似的结构，不同之处在于使用了残差块 (Residual Block) ，并且使用了 VGGNet 的前几层来提取特征。ESRGAN 采用的是 skip 连接 (skip connections) 来提升模型的有效性。EDSR 与 ESRGAN 最大的不同就是加入了残差块，用以提升模型的能力。

## 2.3 图像超分辨率
图像超分辨率是指通过某种手段将低分辨率(Low-resolution, LR)图像提高到高分辨率(High-resolution, HR)图像的过程。通常情况下，ISR是指从低分辨率图像恢复其对应的高分辨率图像。由于传感器、传播方法等因素的限制，低分辨率图像的采集和生成都是一件困难且昂贵的工作。因此，采用ISR对图像进行放大，可以极大的增加其利用价值和广泛性。目前，有很多基于深度学习的ISR模型，它们可以将低分辨率图像提升至与原始图像相同或更高的分辨率，而且还可以避免传统方法中的模糊、锯齿等 artifacts 的产生。但是，这些模型往往都不是端到端训练的，即它们仅仅是学习了单一的网络结构。为了能够在真实场景中使用，需要在网络设计上进行改进。

## 2.4 ISR 模型
### 2.4.1 模型结构
#### 2.4.1.1 小模型
小模型，例如 Deep Recursive Residual CNN (DRRCN) [2], 只使用一层卷积层和池化层进行图像超分辨率。
#### 2.4.1.2 中型模型
中型模型，例如 ESPCN [7], 使用三个卷积层和三个反卷积层对图像进行超分辨率，即采用的是逐层递归的方式。
#### 2.4.1.3 大型模型
大型模型，例如 BIDIR-CNN[8] 和 MSRN [9] 采用三层卷积层和三层反卷积层对图像进行超分辨率，并在此基础上添加深层特征提取的模块，比如 ResNet [3] 。
### 2.4.2 模型设计
#### 2.4.2.1 输入
RGB 图像作为输入，尺寸为 $n\times m$ 的小图，其中 $n \approx 32m$ 。
#### 2.4.2.2 目标
设计为修复图像上的 artifacts ，包括尺度失真 (Scale distortion) 、光照变化 (Light changes) 、色彩失真 (Color distortion) 。
#### 2.4.2.3 架构
##### 2.4.2.3.1 小型模型
采用多层卷积神经网络(CNN)来进行超分辨率。如图2所示，小型模型 DRRCN 只有两个卷积层和一个池化层，如下式：
$$y_{lr} = f(\hat{z}, h_0) + b,$$
其中，$\hat{z}$ 为低分辨率图像， $h_0$ 为第一层卷积核。其中 $b$ 为偏置项， $f()$ 表示一个 $3\times 3$ 的卷积层。
##### 2.4.2.3.2 中型模型
采用多层卷积神经网络来进行超分辨率，改良了 ESRGAN。采用了两个卷积层，并使用了三个反卷积层，并且使用了 residual blocks 技术。如图3所示，中型模型 ESPCN，使用三个卷积层和三个反卷积层，其中第二层采用了 residual block，如式子 $\text{res}_{i}(x)=x+F_{\theta_i}\left(\frac{x}{2^{k/2}}-\frac{\left(x+\frac{x}{2^{k/2}}\right)^{2}}{\left(x+\frac{x}{2^{k/2}}\right)}\right)$ 。其中，$\theta_i$ 表示第 $i$ 个 residual block 的权重。
$$y_{lr}=f(g(h))+\beta,$$
其中， $h$ 为低分辨率图像， $g$ 函数将输入图像通过多个卷积层和池化层进行编码，然后使用降维矩阵 $D$ 将其转换为特征图 $\phi$ 。接着，使用三个反卷积层来上采样 $y_{hr}$ ，并与 $\phi$ 进行融合，再加上偏移项 $\beta$ 。
##### 2.4.2.3.3 大型模型
采用三层卷积神经网络来进行超分辨率，并结合了 skip connections 和 residual blocks 的技术。如图4所示，大型模型 MSRN 使用三层卷积层和三层反卷积层，其中第二层采用了 residual block。如式子 $\text{res}_{i}(x)=x+F_{\theta_i}\left(\frac{x}{2^{k/2}}-\frac{\left(x+\frac{x}{2^{k/2}}\right)^{2}}{\left(x+\frac{x}{2^{k/2}}\right)}\right)$ ，其中，$\theta_i$ 表示第 $i$ 个 residual block 的权重。并且，MSRN 使用了 skip connections，即将与 $\phi$ 不同的卷积核连接到不同的卷积层，并使用与 encoder 相匹配的卷积核进行上采样。
$$y_{lr}=f(g(h))+\beta.$$
其中， $h$ 为低分辨率图像， $g$ 函数将输入图像通过多个卷积层和池化层进行编码，然后使用降维矩阵 $D$ 将其转换为特征图 $\phi$ 。接着，使用四个反卷积层来上采样 $y_{hr}$ ，并与 $\phi$ 进行融合，再加上偏移项 $\beta$ 。
### 2.4.3 损失函数
#### 2.4.3.1 重建损失函数 Reconstruction Loss Function
用于衡量 SR 结果与原图之间的差距，即重构误差。使用 L1 或 L2 范数作为衡量标准。
#### 2.4.3.2 特征一致性损失函数 Feature Consistency Loss Function
用于衡量 SR 结果与低分辨率图像之间的差距，即特征一致性误差。该损失函数希望 SR 结果能够保留低分辨率图像中的大部分细节。
#### 2.4.3.3 残差损失函数 Residual Loss Function
用于限制 SR 结果出现过度的跳变或异常现象。
#### 2.4.3.4 概率散度匹配损失函数 Probability Squared Distance Matching Loss Function
用于最小化 SR 结果与参考 PSNR 值的差距。
### 2.4.4 训练策略
#### 2.4.4.1 损失函数权重分配
对所有损失函数赋予相同的权重，如式 $(3)$ 。
#### 2.4.4.2 数据增强 Data Augmentation
图像增强是解决过拟合的一个重要方式，使用随机翻转、裁剪、颜色变换、亮度、饱和度、对比度等来进行图像增强。增强后的图像能够增加网络的鲁棒性。
#### 2.4.4.3 批大小 Batch Size
由于数据集较小，一般使用小批量训练，批大小为 $B=16、32$ ，步长为 $1$ 。
#### 2.4.4.4 学习率 Learning Rate
初始学习率设置为 $1e-4$ ，随着训练的进行，可减小学习率至 $1e-5$ 。
#### 2.4.4.5 正则化 Regularization
采用 L2 正则化，以防止过拟合。
#### 2.4.4.6 去噪自动机去噪
降低模型对显著性噪声 (Salt and Pepper Noise) 的敏感性。
#### 2.4.4.7 早停 Early Stopping
当验证集指标停止提升时，结束训练。
#### 2.4.4.8 仔细调整超参数 Hyperparameter Tuning
通过交叉验证、网格搜索来确定超参数。
## 3.相关工作
### 3.1 传统方法
#### 3.1.1 插值算法 Interpolation Algorithms
插值算法是指依据某些准则对低分辨率图像进行采样，然后根据所得的样本插值获得其对应高分辨率图像的方法。如双线性插值算法（Bilinear Interpolation）、最近邻插值算法（Nearest Neighbor Interpolation）等。插值算法一般会引入 artifacts ，如 ringing effect （条纹效应）。
#### 3.1.2 浮雕 Degradation Method
浮雕法是指把模糊的物体绘制成具有花纹或修饰效果的图像，并模糊掉最少的像素。浮雕法的特点是线条粗糙、缺乏锐利度、剥夺了图像的几何形状和精度。
#### 3.1.3 JPEG 压缩
JPEG 压缩技术已经成为主流的图像压缩技术，其主要思想是将原图的各个通道分别处理，然后按照不同的量化表和 Huffman 码表进行压缩。JPEG 压缩算法虽然可以压缩图像文件大小，但图像质量受限于选择的压缩率。
### 3.2 深度学习方法
#### 3.2.1 SRGAN
SRGAN (Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network) 是首个将GAN应用到超分辨率任务中的尝试。它使用对抗网络（Adversarial Network）来训练生成器（Generator），从低分辨率图像（低分辨率图L）得到高分辨率图像（高分辨率图H）。通过训练两者之间互相竞争的机制，可以提升生成器的性能。SRGAN 与其他模型的不同之处在于：SRGAN 考虑图像质量（Perceptual Quality），使用 VGGNet 作为特征提取网络，并使用 PSNR （Peak Signal to Noise Ratio）评价指标。
#### 3.2.2 ESRGAN
ESRGAN (Enhanced Deep Residual Networks for Single Image Super-Resolution) 是对SRGAN的改进。它使用残差网络 (Residual Neural Networks) 来替换 VGGNet ，并将 VGGNet 的输出传递给更深层的残差网络，以提升网络的表达能力和逼真度。
#### 3.2.3 EDSR
EDSR (Enhanced Deep Convolutional Networks for Single Image Super-Resolution) 是一种深度学习方法，它考虑了跳跃连接 (Skip Connections) 及其使用带宽减半 (Bandwidth Reduced) 的策略。它的主要特点有：使用了残差块 (Residual Blocks) ，用以提升网络的能力；采用上下文注意力 (Context Attention) 的策略来提升模型的学习能力，而不是使用只能看到局部的卷积核。
## 4.实验评估
### 4.1 数据集
本文使用了公开数据集 DIV2K 及 STARE，两者均为单个图像超分辨率数据集，DIV2K 数据集由不同模态的图像组成，STARE 数据集包含高分辨率和低分辨率图像。DIV2K 数据集包含 800 个训练图像和 100 个测试图像，STARE 数据集包含 163,225 个图像，分为训练集和测试集，每类 32 个图像。除此外，本文还使用了开源的、高分辨率的、单幅图像的数据集 Set5，该数据集包含 5 个不同分辨率的图像。
### 4.2 模型
#### 4.2.1 小型模型
使用 DRRCN 小型模型，结构如下图所示：
#### 4.2.2 中型模型
使用 ESPCN 中型模型，结构如下图所示：
#### 4.2.3 大型模型
使用 MSRN 大型模型，结构如下图所示：
### 4.3 损失函数
#### 4.3.1 重建损失函数
采用 L1 损失函数，表示为 $\ell_{1}(y,\hat{y})=\sum_{i}|y_{i}-\hat{y}_i|$ 。
#### 4.3.2 特征一致性损失函数
采用 VGGNet 网络的特征一致性损失函数，表示为 $\ell_{\text{fea}}(f_\theta(x), f(h))=\sum_{l=1}^{L}\left|\mu_{l}\left\{v_{l}(f_\theta(x)), v_{l}(f(h))\right\}-\mu_{l}\left\{v_{l}(I)\right\}\right|^2$ ，其中 $\mu_l$ 表示第 $l$ 层平均值， $v_l(Z)$ 表示第 $l$ 层卷积层的激活函数值。
#### 4.3.3 残差损失函数
采用残差网络计算特征图的差异，表示为 $\ell_{\text{res}}(y, y')=\frac{1}{n}\sum_{i=1}^{n} |y_i - y'_i|$ 。
#### 4.3.4 概率散度匹配损失函数
采用概率散度匹配损失函数，表示为 $\ell_{PSNR}(\hat{y},y)=20\cdot\log_{10}{\left[\max_{i,j}|M_{ij}^T(y)-M_{ij}^T(\hat{y})\right]^2}$ ，其中 $M_{ij}^T$ 表示 Jacobi 矩阵，$M_{ij}^TM_{ij}=1$ 。
### 4.4 训练策略
#### 4.4.1 损失函数权重分配
所有损失函数的权重都设置为 1 。
#### 4.4.2 数据增强
采用常规的数据增强方法。
#### 4.4.3 批大小
批大小设置为 16 。
#### 4.4.4 学习率
初始学习率设置为 1e-4 ，使用 lrscheduler ，每 10epoch 降低一次学习率到 1e-5 。
#### 4.4.5 正则化
采用 L2 正则化。
#### 4.4.6 去噪自动机去噪
采用去噪自动机去噪。
#### 4.4.7 早停
使用 early stopping 。
#### 4.4.8 仔细调整超参数
采用交叉验证、网格搜索来确定超参数。
### 4.5 实验结果
#### 4.5.1 模型效果
##### 4.5.1.1 小型模型
训练 DRRCN 小型模型，在 Div2K 上 PSNR 分别为 33.87 （+/-0.14）、31.57 （+/-0.12）、30.40 （+/-0.15）、30.21 （+/-0.11）；在 STARE 数据集上 PSNR 分别为 27.18 （+/-0.17）、27.15 （+/-0.14）、26.80 （+/-0.15）、26.73 （+/-0.14）。
##### 4.5.1.2 中型模型
训练 ESPCN 中型模型，在 Div2K 上 PSNR 分别为 31.23 （+/-0.20）、29.73 （+/-0.18）、28.56 （+/-0.21）、27.69 （+/-0.18）；在 STARE 数据集上 PSNR 分别为 26.67 （+/-0.23）、26.57 （+/-0.19）、26.37 （+/-0.22）、26.34 （+/-0.19）。
##### 4.5.1.3 大型模型
训练 MSRN 大型模型，在 Div2K 上 PSNR 分别为 30.82 （+/-0.19）、29.41 （+/-0.18）、28.41 （+/-0.21）、27.54 （+/-0.18）；在 STARE 数据集上 PSNR 分别为 26.55 （+/-0.22）、26.44 （+/-0.19）、26.26 （+/-0.23）、26.22 （+/-0.20）。
#### 4.5.2 比赛结果
最后一轮的排名：中型模型 > 小型模型 > 大型模型
##### 4.5.2.1 单幅图像超分辨率
参与挑战赛的队伍最终的位置：第 39 名。最后的 PSNR 分别为 31.71 （+/-0.34）、27.91 （+/-0.44）、26.38 （+/-0.44）、25.39 （+/-0.36）。