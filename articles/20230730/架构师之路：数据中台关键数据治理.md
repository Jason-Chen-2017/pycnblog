
作者：禅与计算机程序设计艺术                    

# 1.简介
         
 数据中台（Data Intelligence）作为2020年互联网企业必备技能之一，其重要性无需多言。随着越来越多的企业将数据视作至关重要的基础业务，传统的数据处理方法已无法满足时代要求，如何实现数据驱动、智能化，以及如何对关键数据进行有效治理，成为了各公司面临的共同难题。因此，我们必须秉持科学发展观，学习先进技术，切实提升数据中台的整体能力，培养出一支能够兼顾架构、开发、测试等方面的高级数据架构师。本文旨在通过对数据中台核心技术和原理的解析，结合实际案例，帮助读者了解数据中台的定义及其作用，并对数据中台的关键治理方式——数据质量建设和数据模型设计有全面的认识。
        # 2.知识背景
         ## 2.1 数据中台概念
         数据中台是一种基于云计算、大数据分析、机器学习、IoT技术、云平台等新兴技术的新型组织形态，它是一个将海量数据集成、清洗、分析、决策、呈现到用户终端的综合性平台。它将企业内多个系统中的各种数据集合起来，形成中心管理平台，实现了跨部门、跨系统、跨业务场景的数据共享和协同。它既是一套数据分析系统的集合，也是一组数据治理工具的集合。它解决的是海量数据的处理、分析、挖掘问题，极大地促进了企业的效率和竞争力。
         ### 2.1.1 数据中台发展历程
         数据中台从最早的数字孪生、智能数据采集、数据仓库的模式演变而来，逐步形成独立部署于各个数据中心的海量数据集市。随后，数据中台的角色发生了变化。作为数据治理和智能应用的“纽带”角色，数据中台的目标是把各种数据源汇聚到一起，形成统一的数据库，支持业务快速响应、有效决策。2017年，英国《卫报》报道，英国政府正通过数据中台来优化管理与服务政府部门的信息。数据中台也经历了从试点项目到规模化部署的过程。
         随着信息技术、商业模式、需求的不断刷新，数据中台也经历了相应的转型升级，目前国内的数据中台主要分为以下几个阶段：
          - 第一代数据中台（Numeric Data Tower）：直接集成了各类公司内部的数据源，按功能和用途划分多个库。缺点是各类数据源之间的异构性很强，需要做大量的ETL工作才能保证一致性。
          - 第二代数据中台（Digitalization Data Tower）：在第一代数据中台的基础上，引入数据虚拟化技术，摒弃异构性，所有数据都存储于数据湖之上，统一入口，并提供数据服务。优点是可以按需快速获取所需的数据，减少数据的重复采集，节省成本。
          - 第三代数据中台（Intelligent Data Tower）：在第二代数据中台的基础上，引入智能分析引擎，支持各种复杂查询，如推荐系统、预测模型等，实现数据驱动业务。
          - 第四代数据中台（Data Intelligence Tower）：在第三代数据中台的基础上，引入机器学习、大数据分析等技术，构建复杂的模型，解决数据分析、挖掘领域的复杂问题。此外，还需要对数据中台进行架构重构、运维支持、线上服务等一系列配套工作。
         ### 2.1.2 数据中台功能模块
         数据中台由以下几个功能模块组成：
          - 数据接入与集成：包括将各个数据源汇聚到数据中台的过程中，对各类数据进行清洗、转换、归一化等处理，使其具备一致性和可用性。同时，还需要对数据的结构化、格式化等进行标准化，确保数据可以被应用层识别、理解、处理。
          - 数据治理：数据中台的数据治理是指对数据的准确性、完整性、可信度进行检测、维护、控制，确保数据能够用于下游的各种应用，避免数据的泄露或误用。
          - 数据分析与挖掘：数据中台的数据分析与挖掘模块由计算机智能算法和统计模型实现，对数据进行分析、探索和预测，以发现更加有价值的数据和洞察机遇。
          - 数据展示与可视化：数据中台的数据展示与可视化模块负责将分析结果呈现给最终的用户，帮助业务决策和决策支持。
          - 服务与支持：数据中台的服务与支持模块用于解决数据中台运行过程中出现的问题、异常情况，提供运行状态、故障排查、定制服务等支持。
         ### 2.1.3 数据中台角色
         数据中台有几个重要角色：
          - 数据分析师：数据中台的数据分析师是数据中台的核心角色，他们有丰富的专业知识、经验和技能，能够熟练使用数据分析工具、处理海量数据，并通过分析提炼数据中的价值。
          - 数据工程师：数据工程师负责设计数据模型、搭建数据仓库、构建数据流水线、编写SQL脚本等。
          - 数据科学家/算法工程师：数据科学家/算法工程师能够根据业务需求进行算法设计和研发，设计并改进机器学习模型，同时进行数据挖掘、数据分析和数据预测工作。
          - 数据决策者：数据决策者主要负责数据中台的商业价值评估、产品方向规划、客户关系维护等工作。
         ### 2.1.4 数据中台架构
         数据中台架构是指数据中台在一个大的平台上的架构设计和功能模块组合。数据中台架构由三个主要子系统组成：
          - 数据采集与加工（Ingestion and Processing）：数据采集与加工子系统负责从各类数据源处收集数据，按照一定的规则进行数据清洗、转换、规范化等处理，并导入到数据湖中。
          - 数据服务（Data Services）：数据服务子系统负责提供数据服务接口，向上游业务提供可靠的数据。主要有元数据管理、数据分析、数据挖掘、数据驱动业务等功能模块。
          - 数据交互（Visualization & Interactivity）：数据交互子系统负责数据展示、可视化与交互，用户通过前端页面访问数据服务。
         ### 2.2 数据中台关键技术
         为了实现数据中台的核心任务——数据治理，我们首先要了解数据中台的一些核心技术。
         ### 2.2.1 数据模型设计
         数据模型设计是数据中台的关键技术之一，它用来描述、组织和逻辑上组织数据。数据模型是数据结构、数据间的联系、数据的约束条件和规则，是指在数据库中用来表征现实世界中客观存在的事物的、具体化的概念。数据模型通常根据企业信息的特性和数据结构设计，有助于提高数据正确性、精度和效率。数据模型设计可以划分为以下几个步骤：
          1. 业务场景梳理与需求分析：包括业务场景的定义、数据需求的分析、职责范围的确定、信息生命周期的划分、各个系统之间的依赖关系、数据共享的方式、权限控制策略等。
          2. 概念架构设计：包括对数据信息层次结构的设计、对实体-属性-联系模型的选择、对实体之间的关联关系的定义等。
          3. 模型优化：包括对数据模型的描述、标准化、数据一致性、数据权限控制、数据查询的优化、索引的选择、数据采集的规范化、日志记录的配置等。
          4. 数据字典和元数据管理：包括生成数据字典和元数据，利用元数据对数据进行描述、分类和检索。
         ### 2.2.2 数据质量建设
         数据质量建设是数据中台的核心技术之二，它与数据建模密切相关，是关于如何确保数据不断增长、准确、完整、可靠、可用的过程。数据质量建设主要涉及以下几个方面：
          - 数据完善性建设：包括数据采集规范化、数据输入校验、数据传输加密、数据源数据质量验证、数据输出错误级别控制等。
          - 数据完整性建设：包括数据采集和入库的实时性监控、数据源之间的数据一致性保证、数据反馈机制的引入等。
          - 数据一致性建设：包括数据视图的定义、数据流的同步、数据订阅的发布、数据质量保证的流程等。
          - 数据可用性建设：包括数据分区的设置、数据冷热存储、数据同步机制的选择、可用性监控的手段等。
          - 数据安全建设：包括数据安全隔离、数据恢复机制的设计、数据操作审计等。
         ### 2.2.3 数据分析与挖掘
         数据分析与挖掘（Data Analysis & Mining）是数据中台的核心技术之三，它包含数据挖掘、数据分析、数据挖掘、数据可视化等技术。数据分析与挖掘包含如下几项技术：
          - 数据挖掘：数据挖掘是一种基于数据特征进行分析、发现和挖掘的技术，以发现数据中隐藏的模式、关联、结构和规律。数据挖掘的方法包括分类法、关联规则、聚类分析、频繁项集挖掘、决策树分析、人工神经网络等。
          - 数据分析：数据分析是指将数据转换、存储、处理、分析等步骤结合起来，从中提取价值信息，并用图表、报表等形式展现出来。数据分析常用技术有关系模型设计、统计分析、多维分析、数据挖掘等。
          - 数据可视化：数据可视化是通过不同形式的图表、图形、图像等媒介，帮助数据分析师、研究人员、决策者等理解数据特征和规律。数据可视化常用技术有数据可视化语言、可视化库、可视化工具等。
         ### 2.2.4 流程自动化
         流程自动化是数据中台的核心技术之四，它是指采用自动化技术，将手动数据处理、决策制定、分析处理等环节，转变为计算机程序，实现高度自动化。流程自动化有助于提高数据处理速度、降低数据处理成本，减少数据错误、失真，并提高数据准确性、效率和质量。流程自动化常用技术有流程建模、可视化建模、事件驱动、业务规则引擎、规则推理、深度学习等。
         ### 2.2.5 可信数据源
         可信数据源是数据中台的核心技术之五，它是指企业数据中是否存在不可靠的数据源，或者存在数据冗余、数据污染等问题。可信数据源导致的数据质量问题，可能导致企业投资决策产生偏差、经营风险增加。可信数据源检查可以通过数据质量建设和数据源汇总等技术实现。
         # 3.核心算法原理及操作步骤
         本节将对数据中台的核心算法原理及操作步骤进行详细阐述。
         ## 3.1 数据接入与集成
         数据接入与集成（Data Ingestion and Integration），即是从各类数据源处收集数据、对数据进行清洗、转换、规范化等处理，导入到数据湖中。数据接入与集成的主要目的是对数据的格式、格式、结构、质量进行统一。数据接入与集成的方法有两种：
          - 直连数据源：是指将各个数据源连接到数据中台，利用各个数据源自己的接口对数据进行获取、清洗、转换、加载。这种方式数据集成效率较高，但接口耦合度较高，容易出现性能问题；
          - 数据集成平台：是指使用数据中台提供的通用数据集成平台，集成多个数据源，对数据进行统一。数据集成平台一般采用开源工具或商业工具，可大幅度简化数据集成流程。
         ## 3.2 数据模型设计
         数据模型设计（Data Model Design）是数据中台的关键技术之一，它用来描述、组织和逻辑上组织数据。数据模型是数据结构、数据间的联系、数据的约束条件和规则，是指在数据库中用来表征现实世界中客观存在的事物的、具体化的概念。数据模型通常根据企业信息的特性和数据结构设计，有助于提高数据正确性、精度和效率。数据模型设计可以划分为以下几个步骤：
          1. 业务场景梳理与需求分析：包括业务场景的定义、数据需求的分析、职责范围的确定、信息生命周期的划分、各个系统之间的依赖关系、数据共享的方式、权限控制策略等。
          2. 概念架构设计：包括对数据信息层次结构的设计、对实体-属性-联系模型的选择、对实体之间的关联关系的定义等。
          3. 模型优化：包括对数据模型的描述、标准化、数据一致性、数据权限控制、数据查询的优化、索引的选择、数据采集的规范化、日志记录的配置等。
          4. 数据字典和元数据管理：包括生成数据字典和元数据，利用元数据对数据进行描述、分类和检索。
         ## 3.3 数据质量建设
         数据质量建设（Data Quality Assurance）是数据中台的关键技术之二，它与数据建模密切相关，是关于如何确保数据不断增长、准确、完整、可靠、可用的过程。数据质量建设主要涉及以下几个方面：
          - 数据完善性建设：包括数据采集规范化、数据输入校验、数据传输加密、数据源数据质量验证、数据输出错误级别控制等。
          - 数据完整性建设：包括数据采集和入库的实时性监控、数据源之间的数据一致性保证、数据反馈机制的引入等。
          - 数据一致性建设：包括数据视图的定义、数据流的同步、数据订阅的发布、数据质量保证的流程等。
          - 数据可用性建设：包括数据分区的设置、数据冷热存储、数据同步机制的选择、可用性监控的手段等。
          - 数据安全建设：包括数据安全隔离、数据恢复机制的设计、数据操作审计等。
         ## 3.4 数据分析与挖掘
         数据分析与挖掘（Data Analysis & Mining）是数据中台的关键技术之三，它包含数据挖掘、数据分析、数据挖掘、数据可视化等技术。数据分析与挖掘包含如下几项技术：
          - 数据挖掘：数据挖掘是一种基于数据特征进行分析、发现和挖掘的技术，以发现数据中隐藏的模式、关联、结构和规律。数据挖掘的方法包括分类法、关联规则、聚类分析、频繁项集挖掘、决策树分析、人工神经网络等。
          - 数据分析：数据分析是指将数据转换、存储、处理、分析等步骤结合起来，从中提取价值信息，并用图表、报表等形式展现出来。数据分析常用技术有关系模型设计、统计分析、多维分析、数据挖掘等。
          - 数据可视化：数据可视化是通过不同形式的图表、图形、图像等媒介，帮助数据分析师、研究人员、决策者等理解数据特征和规律。数据可视化常用技术有数据可视化语言、可视化库、可视化工具等。
         ## 3.5 流程自动化
         流程自动化（Workflow Automation）是数据中台的关键技术之四，它是指采用自动化技术，将手动数据处理、决策制定、分析处理等环节，转变为计算机程序，实现高度自动化。流程自动化有助于提高数据处理速度、降低数据处理成本，减少数据错误、失真，并提高数据准确性、效率和质量。流程自动化常用技术有流程建模、可视化建模、事件驱动、业务规则引擎、规则推理、深度学习等。
         ## 3.6 可信数据源
         可信数据源（Reliable Sources of Data）是数据中台的关键技术之五，它是指企业数据中是否存在不可靠的数据源，或者存在数据冗余、数据污染等问题。可信数据源导致的数据质量问题，可能导致企业投资决策产生偏差、经营风险增加。可信数据源检查可以通过数据质量建设和数据源汇总等技术实现。
         # 4.具体实例解析
         本节将结合数据中台关键技术与实际案例，对数据中台关键技术进行具体实例解析。
         ## 4.1 数据接入与集成
         在实际操作中，数据中台一般都会有专门的团队负责数据接入与集成。数据接入与集成工作包括：
          - 数据采集：包括对不同数据源进行扫描、爬虫、API调用等方式，获取原始数据；
          - 数据清洗：对原始数据进行清洗、转换、规范化，去除脏数据、异常值、重复记录等；
          - 数据转换：包括对原始数据进行格式转换、重塑、拆分等，形成适合应用的形式；
          - 数据加载：将数据导入到数据湖中进行存储，包括离线存储、在线存储、异构存储等；
          - 数据分发：将数据分发给下游应用。
         以腾讯微信为例，数据中台会按照以下步骤来完成微信的用户信息的采集、清洗、转换、加载：
          - 数据采集：微信官方提供了手机号码、邮箱地址等敏感信息的采集权限。微信小程序、公众号SDK、网页端登录、后台扫码等方式获取公开数据。
          - 数据清洗：微信的用户数据通常会包含不可信任的外部数据，例如自媒体、黑客攻击等。微信会对这些数据进行清洗、过滤。
          - 数据转换：微信提供的API已经帮用户完成了数据的解析、转换工作，用户只需要填充必要的字段即可。
          - 数据加载：数据湖一般存储在HDFS（Hadoop Distributed File System，Hadoop的分布式文件系统）上。
          - 数据分发：数据分发给下游应用，例如微信提供分析和展示数据服务。
         以上步骤只是数据接入与集成的一种方式，还可以选择其他的方式，比如将数据接入到AWS（Amazon Web Service，亚马逊云计算）的Redshift数据库、MySQL数据库等。
         ## 4.2 数据模型设计
         在数据模型设计这一环节，数据中台将对用户行为数据进行建模，包括建立数据模型、概念架构设计、数据字典、元数据管理等。数据模型的核心任务就是将企业信息的概念模型和实体属性模型映射到关系模型，并用实体-属性-联系模型进行数据信息的组织和逻辑结构的设计。数据模型设计涵盖的内容非常广泛，包括实体定义、实体关系定义、实体属性定义、实体约束定义、实体分区定义、实体索引定义、实体模式定义等，其中实体分区定义、实体索引定义是数据分析与挖掘的关键环节。实体分区是对数据进行划分，可以按照时间、空间、热度等维度进行分区。实体索引是对数据按照某种特定的排序方式进行索引，便于快速检索和查询。
         举个例子，假设企业在业务场景中对商品交易数据进行建模，需要定义实体包括用户、商品、交易订单、支付订单等。则用户实体的属性包括用户名、密码、邮箱、手机号等。商品实体的属性包括商品名称、价格、颜色、尺寸、库存数量等。交易订单实体的属性包括交易订单ID、商品编号、交易金额、下单日期等。支付订单实体的属性包括支付订单ID、交易订单ID、支付金额、支付渠道等。然后，定义实体之间的关系，比如用户与商品之间的关系，用户与交易订单之间的关系，交易订单与支付订单之间的关系。
         数据字典和元数据管理是数据模型设计的最后一步。数据字典是对数据模型里定义的所有实体、属性、关系等的文档化，可以用于数据字典查询、数据模型的理解和使用。元数据管理是对数据模型的元数据进行管理，包括元数据版本控制、元数据审核、元数据授权等。
         另外，数据模型设计也需要考虑数据一致性问题。数据一致性是指不同数据源之间的同步、一致性、正确性。一致性的前提是对数据进行正确的定义、结构化、编码、规范化、注释、描述，并且确保数据采集和数据清洗的一致性。数据中台需要对数据一致性建设具有非常高的关注，确保数据源之间的数据共享和同步的一致性，防止数据因损坏、丢失等原因造成业务中断。
         ## 4.3 数据质量建设
         数据质量建设属于数据治理的范畴，对企业数据的质量进行保障、评估、维护、控制，确保数据准确、完整、一致、可靠、可用。数据质量建设的主要任务包括数据完善性建设、数据完整性建设、数据一致性建设、数据可用性建设、数据安全建设等。
         ### 4.3.1 数据完善性建设
         数据完善性建设是指对原始数据进行准确性、完整性、可靠性的核查，确保数据采集、传输的准确性、完整性、有效性。数据完善性建设的方法包括数据验证、数据覆盖、数据质量控制、数据匹配、数据标注、数据采集监控等。数据验证是指对原始数据进行逻辑检查、规则检查、枚举检查等，确保数据准确、正确。数据覆盖是指确保所有数据都被采集到了，包括采集用户、公众号等公开信息，还应当对内部员工、员工培训、员工异动等信息进行采集。数据质量控制是指通过数据采集、传输、存储过程中的各项环节对数据质量进行评估，包括数据收集频率、数据质量、数据唯一性、数据一致性等。数据匹配是指利用规则或模型匹配算法将各种原始数据相互关联，从而达到数据质量的最大化。数据标注是指标记原始数据，例如打标签、进行描述，对原始数据进行描述，并确认原始数据的真实来源和真实含义。数据采集监控是指对数据的采集过程、传输过程、存储过程等进行监控，包括数据采集时长、数据损坏率、数据传输延迟等。
         ### 4.3.2 数据完整性建设
         数据完整性建设是指确保企业数据完整、一致、正确，确保数据不会因采集、传输、存储、分析等环节遗漏、缺失、错误。数据完整性建设的方法包括数据准确性校验、数据最小化、数据校验、数据合并、数据反馈、数据沿革等。数据准确性校验是指对数据项进行数据类型、长度、格式等检查，确保数据准确。数据最小化是指确保数据采集和存储量最小化，包括减少不必要的数据、删除无用数据。数据校验是指对数据进行一致性检查，确保数据完整性。数据合并是指对不同数据源的数据进行整合，确保数据一致性。数据反馈是指将数据质量缺陷反馈给相关单位，允许数据源进行调整，确保数据准确性。数据沿革是指对历史数据进行监控、记录、追溯，通过对数据源的分析，判断数据的真实含义、真实来源，确保数据真实性。
         ### 4.3.3 数据一致性建设
         数据一致性建设是指不同数据源之间的同步、一致性、正确性。一致性的前提是对数据进行正确的定义、结构化、编码、规范化、注释、描述，并且确保数据采集和数据清洗的一致性。数据一致性建设的方法包括数据视图定义、数据订阅发布、数据分区设置、数据同步机制选择等。数据视图定义是指根据业务需求、用户场景、数据特征等，定义数据视图。数据订阅发布是指对数据进行一致性校验，确保数据一致性。数据分区设置是指对数据按照时间、空间、热度等维度进行分区，确保数据按需获取。数据同步机制选择是指选择合适的数据同步机制，确保数据一致性。
         ### 4.3.4 数据可用性建设
         数据可用性建设是指确保企业数据能够正常使用，确保数据源中的数据不会因为数据丢失、损坏、过期等原因影响应用系统。数据可用性建设的方法包括数据分区设置、数据冷热存储、数据同步机制选择、可用性监控手段等。数据分区设置是指对数据按照时间、空间、热度等维度进行分区，确保数据按需获取。数据冷热存储是指对于关键数据，选择冷热存储，确保数据安全。数据同步机制选择是指选择合适的数据同步机制，确保数据一致性。可用性监控手段是指对数据的可用性进行监控，包括数据容灾、数据可靠性、数据健康度、数据容量限制等。
         ### 4.3.5 数据安全建设
         数据安全建设是指确保数据安全，确保数据不会因窃取、篡改、泄露等安全事件影响个人隐私、企业利益。数据安全建设的方法包括数据安全隔离、数据恢复机制设计、数据操作审计等。数据安全隔离是指对数据进行隔离，确保数据安全。数据恢复机制设计是指设计恢复机制，确保数据不会因意外损坏、错误删除等问题影响可用性。数据操作审计是指记录数据管理员对数据的操作，确保数据安全。
         ## 4.4 数据分析与挖掘
         数据分析与挖掘（Data Analysis & Mining）是数据中台的关键技术之三，它包含数据挖掘、数据分析、数据挖掘、数据可视化等技术。数据分析与挖掘包含如下几项技术：
          - 数据挖掘：数据挖掘是一种基于数据特征进行分析、发现和挖掘的技术，以发现数据中隐藏的模式、关联、结构和规律。数据挖掘的方法包括分类法、关联规则、聚类分析、频繁项集挖掘、决策树分析、人工神经网络等。
          - 数据分析：数据分析是指将数据转换、存储、处理、分析等步骤结合起来，从中提取价值信息，并用图表、报表等形式展现出来。数据分析常用技术有关系模型设计、统计分析、多维分析、数据挖掘等。
          - 数据可视化：数据可视化是通过不同形式的图表、图形、图像等媒介，帮助数据分析师、研究人员、决策者等理解数据特征和规律。数据可视化常用技术有数据可视化语言、可视化库、可视化工具等。
         数据分析与挖掘技术是数据中台的核心技能，是提高数据分析、挖掘的能力的关键。通过使用数据分析与挖掘技术，可以对数据进行分类、关联、聚类等分析，从而得到有意义的见解。例如，在电商场景，通过数据分析与挖掘技术，可以对用户行为数据进行分类、聚类、关联等分析，得到购买习惯、喜好偏好、兴趣偏好、品牌偏好、区域分布等有价值的信息。
         ## 4.5 流程自动化
         流程自动化（Workflow Automation）是数据中台的关键技术之四，它是指采用自动化技术，将手动数据处理、决策制定、分析处理等环节，转变为计算机程序，实现高度自动化。流程自动化有助于提高数据处理速度、降低数据处理成本，减少数据错误、失真，并提高数据准确性、效率和质量。流程自动化常用技术有流程建模、可视化建模、事件驱动、业务规则引擎、规则推理、深度学习等。
         流程自动化是数据中台的重要功能，它将各个数据分析环节、决策制定过程、可视化呈现等环节，从人工手动执行的手动流程，转变为由计算机程序执行的自动流程。流程自动化可以提高数据处理效率、降低人为因素的干扰、保证数据准确性、可靠性、一致性、可用性。
         ## 4.6 可信数据源
         可信数据源（Reliable Sources of Data）是数据中台的关键技术之五，它是指企业数据中是否存在不可靠的数据源，或者存在数据冗余、数据污染等问题。可信数据源导致的数据质量问题，可能导致企业投资决策产生偏差、经营风险增加。可信数据源检查可以通过数据质量建设和数据源汇总等技术实现。
         可信数据源是数据中台的重要内容，是确保数据质量的关键，也是数据质量建设中需要注意的问题。数据质量问题的根源在于数据源的质量问题，如何保证数据源的准确性、一致性、可用性，是数据中台质量建设的关键。数据源准确性问题导致的数据质量问题包括数据不准确、错误、不完整等问题，数据一致性问题导致的数据质量问题包括数据不一致、缺失、异常等问题，数据可用性问题导致的数据质量问题包括数据丢失、损坏、过期等问题。通过数据源汇总、数据源质量检查、数据抽样分析、数据质量控制等方法，可以有效地保障数据源的准确性、一致性、可用性。

