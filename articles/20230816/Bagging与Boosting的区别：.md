
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Bagging(Bootstrap aggregating)和Boosting(提升方法)是集成学习中常用的两种方法。Bagging和Boosting都是在多个弱分类器(Weak Classifier)的基础上通过生成多棵树(Tree)或弱分类器(Classifier)来获得集成学习的结果。两者之间的主要区别在于：
- Boosting: 是一种迭代的方法，每次迭代都用上一次模型预测结果的残差来训练下一个模型；
- Bagging: 在每一轮迭代中选择不同的样本集进行训练，从而达到降低方差。

那么，什么时候需要采用Bagging？什么时候需要采用Boosting？ Bagging与Boosting的区别是什么呢？为什么有的算法可以用Bagging，有的算法只能用Boosting？这些问题都会在这篇文章里进行详细的阐述。
# 2.背景介绍
## 2.1 Bagging VS Boosting
Bagging、Boosting是集成学习中的两种主流方法。
### Bagging(bootstrap aggregating)
在机器学习领域，Bootstrapping是一种统计方法，它是在已知数据集的前提下，随机地抽取一定数量的数据子集，并利用该子集构建模型。Bagging就是将多次训练得到的基学习器进行集成，一般来说，其过程如下所示：

1. 采样：通过选取一定的方式（例如随机采样）从原始数据集中产生n个含量相同的子样本集。
2. 模型训练：对每个子样本集，用相应的学习算法建立一个模型。这里的学习算法通常称为“基学习器”或者“基分类器”。
3. 投票表决：对于测试数据点x，由所有学习器投票决定其属于哪一类。投票规则可以采用简单如多数表决，也可以采用更加复杂的规则，比如学习期权模型。

通过Bagging集成的学习器可以降低样本扰动带来的影响，从而取得比单独使用某一学习算法效果更好的性能。Bagging的另一个优点是减少了过拟合的风险。由于各个基学习器之间的数据依赖关系较弱，因此即使使用相互独立的基学习器也能够很好地抗衡噪声的影响。但是，如果使用同一个基学习器，则存在信息重复的问题。所以，Bagging的一个关键性缺陷在于它的容错能力弱。

### Boosting(提升方法)
Boosting也是一种集成学习方法。与Bagging不同的是，在每一轮迭代中，提升方法不会使用全部训练数据集进行训练，而是关注那些误分的数据点，并根据它们提供的“高质量”反馈调整学习过程。一般来说，Boosting的训练过程如下：

1. 初始化：首先，为每一个样本赋予一个初始权重，通常初始化为1/N，其中N为样本总数。
2. 训练：对每个样本，根据当前的权重，训练出一个基分类器。
3. 更新权值：根据基分类器的错误率，更新每个样本的权值。错误率越小，该样本的权值越大。
4. 测试：最终，组合多个基分类器的输出，得到最后的预测结果。

Boosting的优点是速度快，易于实现，并且在异常值处理上不易受干扰。Boosting的基本思想是通过在训练过程中，不断往正确分类的方向努力，从而获得一系列弱分类器的集合，然后将这些弱分类器集成为强分类器。

### Bagging VS Boosting比较
|                            |     Bagging        |       Boosting      |
|----------------------------|--------------------|---------------------|
|**样本自助采样**            |   每次采样得到不同子样本集 |                   不需要                |
|**学习算法类型**            |    任意一种         |                     需要                |
|**特征空间采样**           |    无               |                  有                    |
|**易受干扰的异常值处理**     |   无               |                 有                    |
|**降低噪声的作用**          |    较弱             |                    较强                   |
|**基学习器个数**            |     棘手             |                      容易                 |