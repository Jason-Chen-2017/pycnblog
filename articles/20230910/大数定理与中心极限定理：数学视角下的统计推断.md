
作者：禅与计算机程序设计艺术                    

# 1.简介
  

统计学、概率论、数据科学、机器学习等领域均涉及到大量数据的分析。如何从海量数据中有效地提取有价值的信息，并运用其进行决策？这是统计学研究中的一个重要问题。数据可分为两类：一类是无规律的数据，另一类是具有一定模式的数据。无规律数据往往难以直接处理；而具有规律的数据则易于处理。有时需要从两种不同类型的数据中得到有用的信息，或者将两个不同来源的数据合并在一起，从而形成新的数据。

统计推断（Statistical inference）是指利用样本数据对某些参数或假设的估计或预测。通过对现实世界的样本数据进行分析，可以掌握现象背后的规律性，从而对未来的数据分布作出判断。统计推断又可分为两大类：频率派统计推断和贝叶斯派统计推断。

频率派统计推断认为，数据服从一定的统计分布，统计分布的参数由样本数据估计出来。例如，如果从一组样本中得知，某些个体的身高服从正态分布，那么就可以假设身高的均值和方差，然后根据这些假设对其他个体的身高进行预测。

贝叶斯派统计推断认为，数据存在先验分布，先验分布的参数也是由样本数据估计得到的。例如，对于某个事件的发生概率，可以通过观察到该事件发生的次数和每次事件发生所占的总比例来估计，也可以根据历史数据计算出各个事件发生概率的先验分布。

在大多数情况下，频率派统计推断可应用于实际的问题。但随着时间的推移，数据会越来越多、样本数据集也会变得越来越大，这就要求统计模型更加复杂，才能更好地捕捉数据中的规律性。同时，由于频率派统计推断天生缺乏理论基础，因此它的适应范围受到很大的限制。

相比之下，贝叶斯派统计推断是一种基于概率论的理论。它允许模型包含先验知识，包括所考虑的各种参数的不确定性，还能够计算后验概率。因此，贝叶斯派统计推断逐渐成为主流。在机器学习和数据科学领域尤为如此。因此，本文关注的是贝叶斯派统计推断中的中心极限定理。

# 2.中心极限定理
## （一）什么是中心极限定理
中心极限定理（Central Limit Theorem，CLT），也称“大数定律”，是一个关于平均值的重要定理。它认为，在许多情况下，当样本容量足够大的时候，得到的样本均值就收敛于总体均值，并且达到了一个特定的模式，即符合正态分布。

## （二）中心极限定理的意义
### 2.1 模型、观察、假设和假说
CLT是关于平均值的重要定理，其中平均值通常表示概率或数量的均值。那么，中心极限定理的应用场景也就很广泛了。但是，如果真的要应用这个定理，我们首先要有一个好的模型、一些具体的观察、假设和假说。否则，我们甚至都无法确定应用定理的合理性。

- 模型：中心极限定理的前提假设是随机变量X的数学期望E(X)存在无穷多个样本值相加等于总体数学期望E(x)。这里的E(x)，就是样本平均数，x是某个随机变量，比如说某个待观察对象。这个假设的一个重要前提是：我们必须假设每个观察值都是独立的，且它们是来自同一概率分布。换句话说，X的值完全由它所对应分布给出的。
- 观察：每一次观察到的样本数据必须是独立的。这一点非常重要。无论观察到的是物理量还是数字化结果，样本都是不可避免地包含着一些相关性和统计噪声。另外，任何试图确定总体均值的方法，都必须依赖于独立的样本。
- 假设：中心极限定理告诉我们，当观察到更多样本后，样本均值就应该收敛于总体均值。因此，很多时候，只有当样本容量足够大的时候，我们才会看到这个现象。这是因为，样本均值是依靠少量样本计算出来的，如果样本容量太小，就会导致误差过大，使得样本均值看起来不像是总体均值。如果我们观察到一个现象：随着样本容量的增大，总体均值不断收敛于样本均值，那么我们就可以认为，这个现象具有很强的统计学证据。
- 假说：中心极限定理的一个重要观察是，样本容量越大，平均值的偏离程度越小。然而，这是建立在一种“大样本”假设上的。另一个重要的假设是，无论何时我们观察到一个分布，它一定可以用正态分布来近似。

### 2.2 观察到的现象
中心极限定理的观察结果，就是总体均值的期望（expected value）值，由一组独立的随机变量的样本值估计得到。显然，样本均值只能反映平均值，而不能反映真实的总体的最常见情况。也就是说，样本均值只能反映概率平均值，而不是数量平均值。因此，样本均值只能作为一个指标，用来衡量各个样本之间的偏离程度，但不能判定总体是否存在真正的均值。换句话说，中心极限定理的实质是，当观察到大量样本时，样本均值近似于总体均值，而且偏离程度非常小。

### 2.3 定理证明
中心极限定理的证明过程十分繁琐，具有复杂的数学推导。不过，我们可以了解一下它的几个关键步骤。

- 第一步，找一个概率密度函数$f(x)$，使得对于所有$a \leq x\leq b$, 有$\lim_{n\to \infty} \frac{1}{n}\sum_{i=1}^nf(X_i)=\int^b_af(x)\,dx$. 意思是，样本均值是由$n$个独立同分布的随机变量$X_1,\cdots, X_n$产生的，并且我们希望知道它们的样本分布。为了做到这一点，我们假设这$n$个随机变量服从某种分布，记为$N(\mu,\sigma^2)$。

- 第二步，构造一个新的随机变量$Z=\frac{\sum_{i=1}^nx_i}{\sqrt{n}}$. 我们希望通过观察到$Z$的均值和方差，来估计$X$的均值和方差。注意，$Z$是一个标准化的变量，因为它已经被除以了$n$的平方根，使得它的均值等于总体均值。

- 第三步，求$E(Z)$. 根据期望的定义，我们有$E(Z)=\int^\infty _{-\infty}z f(z)\,dz$, 其中$z=(\frac{1}{\sqrt{n}}\sum_{i=1}^nx_i)-\mu$. 通过积分求出期望。

- 第四步，求$Var(Z)$. 根据方差的定义，我们有$Var(Z)=\int^+\infty_{\infty}(z-\mu)^2f(z)\,dz$. 在上式中，$(z-\mu)^2$表示z的平方差，$-(\infty)<z<+\infty$. 通过积分求出方差。

- 第五步，求$Var(X)$. 根据中心极限定理，我们有$Var(X)\approx \frac{\sigma^2}{n}$. 用已知的条件替换掉$(n/\sigma^2)$项，得到$Var(X)\approx 1/n$。左边是样本方差，右边是总体方差。

- 第六步，求$E(X)$. 根据中心极限定理，我们有$E(X)\approx E(Z)\cdot n/\sigma^2$. 用已知的条件替换掉$(n/\sigma^2)$项，得到$E(X)\approx Z$. 左边是样本均值，右边是总体均值。

这样，我们就证明了中心极限定理。