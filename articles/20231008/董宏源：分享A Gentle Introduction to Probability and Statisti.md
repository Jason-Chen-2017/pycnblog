
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


概率论、统计学（特别是假设检验）是一个十分重要的计算机科学领域。许多计算机应用和实际工程中都需要用到这种数理统计方法。在机器学习、模式识别、图像处理、生物信息学等各个领域都会涉及到随机变量、概率分布、随机过程、抽样调查、统计推断、回归分析等多方面的数学分析和计算。所以，对于这门课，非常值得上好基调的提出来作为入门课。
课程主要讲述了如下几个主题的内容：
- 基本概念、性质和基本定理
- 概率分布、随机变量及其概率密度函数、期望、方差、连续型随机变量及其概率密度函数
- 离散型随机变量及其概率分布、概率质量函数、极限分布、条件概率、独立性、边缘概率、Markov链
- 参数估计、假设检验、p值与置信区间、极大似然估计法、贝叶斯估计、马尔科夫链蒙特卡罗方法、EM算法、Gibbs采样、遗传算法、蒙特卡洛树搜索算法、联合概率分布、独立同分布
- 抽样方法、Bootstrap方法、Jackknife方法、交叉验证、方差分析、无偏性与一致性检验、案例研究
- 模型选择、正则化、贝叶斯网、变量选择、缺失值补全、多元回归、判别分析、聚类分析、异常检测、时间序列分析、张量方法等
本文将首先对概率论、统计学的基本概念和基本定理进行阐述。然后介绍各种类型的随机变量及其分布。包括连续型随机变量、离散型随机变量、二项分布、泊松分布、均匀分布、指数分布、正态分布、χ²分布、F分布、t分布、高斯 Copula 分布、伯努利分布、负二项分布、多重伯努利分布、负二项模型。并介绍随机变量之间的关系，例如互相独立、条件独立、全概率公式等。最后介绍各种参数估计方法、假设检验的方法、统计量计算方法。其中包括矩估计、最大似然估计、最小二乘拟合、贝叶斯估计、频率派方法、共轭梯度下降算法、Gibbs采样、MCMC方法、遗传算法、蒙特卡洛树搜索算法、近邻居采样、Simulated Annealing算法、协同过滤算法。
# 2.核心概念与联系
## 随机事件与概率
定义：设A为一个非空集，称其中的元素为“事件”，若对每一个事件$e\in A$，都有一个实数$\Pr(e)$，称这个实数为事件A的概率。如果对于所有的事件$e_i$, $e_j$ ，都有$e_i \neq e_j$, 那么事件$E=e_i∩e_j$ 的发生必定与事件$e_i$ 或 $e_j$ 的发生互斥。如果事件B是事件A的子集，那么事件B的发生必定导致事件A的发生。
记号：
$$\mathcal{S}=\left\{a_{1}, a_{2}, \cdots, a_{n}\right\}$$ 是样本空间，其中$a_i$ 为样本点或称为样本。
如果$X$ 为随机变量，则$X$ 的样本空间为$(-\infty, +\infty)$ 。
如果$X$ 为离散型随机变量，$Y$ 为随机变量，那么$X$ 和$Y$ 有相同的样本空间，即$X$ 的取值为$x_1, x_2,..., x_k$ ，$Y$ 的取值为$y_1, y_2,..., y_m$ 。
如果$X$ 和$Y$ 是两个随机变量，且存在函数$f: \mathbb{R}^{d} \rightarrow \mathbb{R}$ ，使得$f(x) = Y|X$ ，即$Y$ 对$X$ 的条件分布等于$Y$ 的分布，则称$Y$ 关于$X$ 的函数依赖。

## 随机变量、概率分布、概率密度函数
### 随机变量
设$X$ 为一个试验，$x$ 为该试验的一个结果。定义随机变量$X$ 为：
$$X:\Omega \rightarrow \mathbb{R}$$
称函数$X$ 为随机变量。其中，$\Omega$ 为样本空间，即可能出现的结果集合。随机变量表示对试验中不同结果的一种度量或描述，也可说是随机变量是对实践的观察的测度。例如，抛硬币可能得到两种结果（正面和反面），记硬币为$H$ ，头记作$h$ ，尾记作$t$ ，则$H$ 为一个随机变量。
### 概率分布
设$X$ 为一个随机变量，如果能够找到一个映射：
$$\mu=(\mu _{x_1}, \mu _{x_2},..., \mu _{x_k})^T \quad (x_1, x_2,..., x_k)\in X^k,\quad x_1<x_2<...<x_k $$
使得：
$$P(X=x)=\mu (x),\quad x\in X$$
则称这个映射为随机变量$X$ 的概率分布。记号：
$$\pi(x)=P(X=x)$$
当$X$ 为离散型随机变量时，即$X$ 可以取值的离散集合时，就把上面定义的映射叫做概率分布。通常情况下，离散型随机变量的概率分布可以表示成概率质量函数，或简称为质量函数。
### 概率密度函数
设$X$ 为一个随机变量，$\xi$ 为某个概率区间$(a,b)$ 。若存在函数$f: \mathbb{R} \rightarrow [0,+\infty]$ 使得：
$$f(x)=P(\left[a, b\right] \cap X^{-}(x))$$
对于所有满足$a\leqslant x\leqslant b$ 的$x$ ，则称函数$f$ 为$X$ 在$(a,b)$ 上的概率密度函数。记号：
$$\text{density function of }X\text{ at }x\triangleq f(x)$$
## 期望与方差
### 期望
设$X$ 为一个随机变量，如果存在数学期望：
$$E[X]=\sum_{x\in X}xp(x)$$
则称它为随机变量$X$ 的期望，记作：
$$E(X)=\mu$$
其中，$\mu$ 为随机变量$X$ 的概率分布，即$E(X)=\pi(x)$ 。
### 方差
设$X$ 为一个随机变量，如果存在一个非负数学期望：
$$Var(X)=E[(X-\mu)^2]$$
则称它为随机变量$X$ 的方差，记作：
$$Var(X)=\sigma^{2}$$
其中，$\sigma$ 为随机变量$X$ 的标准差，即：
$$\sigma=\sqrt{\frac{1}{N}\sum_{i=1}^Nx_i^2}$$
其中，$N$ 是随机变量$X$ 的样本容量。