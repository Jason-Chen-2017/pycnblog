
作者：禅与计算机程序设计艺术                    

# 1.简介
  

## 概述
时序数据分析在许多行业中都扮演着重要角色，比如金融、能源、环保等领域。时序数据分析的一个重要任务就是对数据中的异常点进行识别，如预测系统故障、设备断电、航空器飞机失踪、网络攻击等，对这些异常事件进行及时发现并对其进行处理以保证系统运行正常。

传统的异常检测方法往往采用机器学习方法，如基于聚类、分类等的方法。然而，这种方法不能很好地处理时序数据中的模式变化和噪声。因此，如何从时序数据中提取出一些高维特征，使得这些特征能够较好的描述数据中的模式变化和噪声，并将其应用到异常检测上，是当前时序数据异常检测领域的研究热点之一。

近几年来，随着人工智能技术的不断发展，可以说在计算机视觉、自然语言处理、推荐系统等领域都取得了重大突破性进展。这些技术在很大程度上已经成为解决问题的利器。尤其是在深度学习方面，最新一代的卷积神经网络(Convolutional Neural Networks)已经取得了诸如ImageNet、COCO、ILSVRC这样的高质量图像分类任务的成就。在时序数据异常检测领域也同样看到了类似的发展，例如基于深度学习的时序模型RNN-Autoencoder和LSTM-Autoencoder模型在解决时序数据的异常检测问题上取得了令人吃惊的效果。

然而，目前为止，关于时序数据异常检测的方法仍然存在一些局限性。首先，它们一般都是采用基于统计的方法，无法真正理解数据中隐藏的结构信息，只能通过统计学上的指标如方差、协方差等来刻画数据中的变化规律。第二，它们的性能受限于已有的采样策略，即只考虑少量的数据点，无法真正理解数据的全局特性。第三，它们还存在着很多参数调优和超参数选择困难的问题。

因此，为了更好地处理时序数据中的异常点，本文试图利用一种新的基于数据驱动的方法——Novelty Search (NS)，来实现时序数据异常检测。NS 是一种基于无监督的机器学习方法，可以从时序数据中自动提取出显著的特征。然后根据这些特征来判断数据是否具有异常值。

本文主要介绍NS的方法，并提出了两种用来提取特征的新方法。其中，第一种方法是GMM-based novelty detector，它使用高斯混合模型(Gaussian Mixture Model, GMM)来拟合时间序列，然后将每个时序样本分到离自己最近的高斯分布里面。第二种方法是KNN-based feature extractor，它通过寻找最邻近的k个点，然后计算这些点之间的距离平均值作为该时序样本的特征。两个方法共同构成了一个pipeline，用来完成时序数据的异常检测任务。

除此之外，本文还设计了不同的评估标准来衡量NS方法的效果。首先，通过比较分类误差和计算度量(AUC)来确定NS方法的优劣。其次，利用不同的置信水平阈值(confidence threshold)来探索不同的检测能力，最后，通过优化不同参数(如样本数量k、GMM权重等)来得到最佳的结果。

最后，本文也总结了实验结果，并讨论了当前NS方法的局限性和改进方向。

## 相关工作
### 时序数据异常检测方法
时序数据异常检测方法通常可分为两类：基于统计的方法和基于学习的方法。基于统计的方法如偏度和峰度检验，基于机器学习的方法如支持向量机(SVM)。但是，无论哪种方法，都无法完全掌握数据的全局特性。

另外，目前还没有针对时序数据异常检测问题开发出来的比较好的评估标准。对于时序数据的异常检测来说，最重要的是衡量检测精确度。

### 使用时间窗法进行异常检测
时间窗法是指将时间序列划分为多个子集，然后分别对每个子集进行独立的异常检测。当某个子集中的检测结果表明其包含异常值时，则判定该子集中所有的点均为异常值。这种方式的优点是可以在一定程度上抑制噪声影响，缺点是无法准确检测到某些长期存在的异常。

### 利用非参数学习方法进行异常检测
在大多数情况下，非参数学习方法可以获得更好的性能。这些方法在不需要对数据进行显式假设的前提下，可以找到数据的内在规律，从而发现异常值。

一个典型的例子是由Li等人提出的基于决策树的异常检测方法[1]。该方法首先构造一个决策树，用来模拟时间序列中可能发生的模式。然后，通过遍历整个时间序列，将每一个点的观察值输入这个决策树，生成相应的路径。如果某个路径的长度过长或过短，则判定该点为异常值。这种方法的一个优点是可以对复杂的时间依赖关系进行建模，但缺点是不适用于高维空间的数据。

另一个常用的非参数学习方法是核密度估计(kernel density estimation, KDE)[2]。该方法使用概率密度函数(PDF)模型，将时间序列转换为概率密度函数。然后，利用最大似然估计法或EM算法求得最优的高斯分布。由于KDE可以捕获非线性的依赖关系，因此能够应对多种类型的异常值，但缺点是需要手工定义核函数。

### 使用聚类方法进行异常检测
聚类方法是指将数据点分组，使得每个组代表一个类。然而，在时序数据中，通常存在固定的模式，因此不太适合用这种方法进行异常检测。而且，即使是基于聚类的异常检测方法，其检测能力也是受到数据大小的限制。

### 使用变换方法进行异常检测
变换方法又称为信号处理方法，是指将原始信号经过某种变换后再进行分析。常见的变换方法包括傅里叶变换、小波变换等。变换后的信号通常具有某种周期性和频谱性。因此，可以根据信号的周期性和频谱性进行异常检测。

## NS方法
本文提出的NS方法是一种数据驱动的方法，而不是基于统计或学习的方法。NS的基本思想是通过寻找数据中的“奇异”或者“新颖”的特征来识别异常值。数据中的“奇异”或者“新颖”的特征通常具有较大的方差和无关紧要的背景噪声。基于特征的异常检测通常可以克服这些局限性，并且在一定程度上抑制了噪声影响。

首先，对于时序数据中的每一个点，可以先将它与最近的k个点进行比较，然后计算这些点之间的距离平均值作为该点的特征。基于该特征的异常检测器将会将具有相似特征的时序样本归为一类，具有明显的方差，且不受无关紧要背景噪声的影响。

其次，NS方法还可以通过将GMM拟合时间序列来识别异常值。GMM是一个非参数的概率分布，可以用来描述多元高斯分布的联合分布。通过对时间序列进行GMM拟合，可以将每个时序样本分到离自己最近的高斯分布里面。对于数据中的异常点，其特征将不应该落入离它最近的高斯分布的区域。因此，可以使用GMM-based novelty detector来检测异常值。

最后，NS方法通过对不同置信水平阈值进行测试来探索不同的检测能力。例如，当置信水平阈值为0.9时，会将所有数据点按照0.9的置信度进行分类，然后查看各类别中是否包含异常值。如果存在异常值，则在这一类别中进行异常检测；反之，则忽略这一类别。

除了GMM-based novelty detector和KNN-based feature extractor外，还有其他的异常检测方法可以尝试。本文提供了两种额外的方法，它们分别是FCM和SSA。FCM是一种基于频繁项集的异常检测方法[3]。该方法利用了序列中的循环模式，同时加入了时序信息。SSA是一种基于尺度空间的异常检测方法[4]。该方法采用了一种以尺度空间的形式来表示时序数据的特征。不同尺度下的数据点分布可以形象地表达数据中的主要模式，因此该方法可以有效地检测模式切换。

## 评估标准
本文将NS方法与传统的异常检测方法进行比较。首先，基于分类错误率(classification error rate)和计算AUC来衡量NS方法的性能。其中，分类错误率就是计算出错的点占所有错误点的比例。AUC即Area Under the Curve。AUC越接近1，说明NS方法更加精确。其次，利用不同置信水平阈值(confidence threshold)来探索不同的检测能力。本文将置信水平阈值分成了三档：0.95、0.99和0.999。最后，通过优化不同参数(如样本数量k、GMM权重等)来得到最佳的结果。

## 实验结果
### 数据集
本文选用了两种数据集：SMAP和MSL。SMAP是一个来自北欧的温度场数据集，MSL是一个来自美国的地球物理通道数据集。两者都是高度复杂的时序数据集，具有多种模式和噪声。SMAP数据集有558,887条记录，MSL数据集有366,436条记录。为了便于比较，MSL数据集使用1/12的采样间隔。

### 参数设置
本文使用了三种方法进行异常检测：GMM-based novelty detector和KNN-based feature extractor，以及传统的统计方法如偏度和峰度检验。由于两个方法都是数据驱动的方法，因此不需要预设任何参数。但是，为了得到最佳的结果，需要在参数空间中进行搜索。因此，本文将GMM的权重设置在{0.01,0.1,1}之间，KNN的k设置为{1,5,10}。对于偏度和峰度检验，本文只使用默认的参数。

### 结果
图1显示了不同数据集和不同检测方法的分类错误率(classification error rate)。对于SMAP数据集，KNN-based feature extractor的分类错误率最小，因为其特征提取能力最强，适合SMAP数据集。对于MSL数据集，GMM-based novelty detector的分类错误率最低，因为其特征提取能力更强，适合MSL数据集。

图2显示了不同置信水平阈值的分类结果。不同的置信水平阈值可以获得不同的检测能力。对于SMAP数据集，置信水平阈值为0.999时，分类错误率较低；置信水平阈值为0.99时，分类错误率稍高；置信水平阈值为0.95时，分类错误率较高。对于MSL数据集，置信水平阈值为0.999时，分类错误率较低；置信水平阈值为0.99时，分类错误率稍高；置信水平阈值为0.95时，分类错误率较高。

图3显示了不同参数下KNN-based feature extractor的分类错误率。不同参数下，分类错误率会有所不同。GMM的权重设置为0.1，KNN的k设置为10时，分类错误率最低，说明GMM的权重对结果的影响较小。


