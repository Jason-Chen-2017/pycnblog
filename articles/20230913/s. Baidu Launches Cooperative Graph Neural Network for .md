
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Baidu是中国最大的中文搜索引擎公司之一，其在线推荐系统一直以来都是基于用户的行为日志数据进行训练建模。随着互联网的飞速发展，用户数量呈现爆炸性增长，同时需求也越来越多样化，如何满足个性化的推荐需求成为当前热门的话题。而Baidu团队自然地想到了一种新的机器学习模型——协同图神经网络（Collaborative Graph Neural Networks）来解决这一难题。
协同图神经网络利用图数据结构对用户之间的关联关系进行建模，可以捕捉到用户间的共性特征并进行推荐。但是，传统的协同图神经网络所建模的关系是静态的，即只考虑历史行为数据，而用户的最新行为信息往往不可获取，因此需要考虑到新老用户间的互动动态，来进一步提升推荐效果。在本文中，我们将介绍Baidu近期推出的Cooperative Graph Neural Network，它是一种用于推荐系统的协作图神经网络模型。
# 2.相关工作介绍
一般来说，协同图神经网络是用于推荐系统的最新研究领域。早在2017年，阿里巴巴就已经提出过协同过滤方法，通过计算用户之间的相似度来推荐商品。到了2019年，谷歌团队发布了Social GANs(Social Generative Adversarial Networks)，通过生成器网络生成符合用户偏好的邻居节点，并且这些节点分布在整个图上。但是，这种方法仍然存在着明显的问题，比如说生成的邻居节点缺乏实体信息、以及生成的邻居之间可能没有任何相关性、以及缺乏用户侧的信息补充等。2020年，微软团队提出了邻居嵌入向量的相似度训练策略，通过对多个邻居节点的嵌入向量进行相似度计算，来优化推荐结果。同时，百度也提出过基于马尔科夫随机场的协同过滤推荐方法，通过边缘概率计算得到用户相似性。而Baidu在2020年提出的Cooperative Graph Neural Network（CGNN），就是基于GraphSAGE网络架构实现的，能够学习到用户之间的社交动态，提高推荐效果。
# 3.主要贡献与创新点
## （一）概览
Baidu最近推出的Cooperative Graph Neural Network是一个用于推荐系统的协作图神经网络模型。该模型通过编码用户的历史行为数据，建立图结构，然后用GRU等序列模型来捕获用户的序列信息。最后，通过Graph Attention层来融合不同邻居节点之间的全局上下文信息。整个模型的结构如下图所示:  
其中，$h_i^t$代表第$t$时刻节点$i$的表示向量，GRU单元负责对每个节点的表示向量进行更新；Attention层则负责通过聚合邻居节点的表示向量，得到该节点的全局表示向量。损失函数使用的是softmax交叉熵。另外，模型采用了多尺度的采样策略，能够学习到全局信息和局部信息。
## （二）特色与亮点
### （1）能力突破
首先，Cooperative Graph Neural Network在推荐系统中的能力突破是值得关注的。协同图神经网络在建模用户之间的关联关系方面具备独到的优势。它不仅能够捕捉到不同用户间的用户习惯差异，还能够捕捉到不同用户间的实时互动情况。而且，它能够捕捉到用户的用户画像，从而更好地为推荐提供个性化建议。此外，由于Cooperative Graph Neural Network本身的图结构，能够捕捉到用户间的复杂关系，因此它可以在学习到长尾效应的同时，保持高性能。另外，在稀疏数据的情况下，Cooperative Graph Neural Network能够很好地适配现代深度学习框架。
### （2）多尺度采样
其次，Cooperative Graph Neural Network采用了多尺度采样策略，能够学习到全局信息和局部信息。在每个时间步$t$，模型会采样出一个子图。对于全局子图，它由所有用户构成，包含了所有关系信息；对于局部子图，它由$k$个邻居用户构成，能够捕捉到用户的部分短期行为信息，增强模型的鲁棒性。另外，当用户的历史点击行为比较稀疏时，模型也能学习到全局信息，提升推荐效果。
### （3）混合精度训练
最后，为了缓解计算资源限制的问题，Cooperative Graph Neural Network采用了混合精度训练策略。它同时兼顾了浮点运算和低精度定点运算的效率，能够有效降低计算成本，缩短训练时间。目前，主流深度学习框架支持混合精度训练，如TensorFlow的XLA和PyTorch的Apex。据称，Cooperative Graph Neural Network的推理速度比传统的协同图神经网络快很多。
## （三）模型设计及关键参数解析
### （1）模型设计
Cooperative Graph Neural Network是一种基于GraphSAGE的推荐系统模型。在这个模型中，用户被抽象为节点，行为被抽象为边。在图的每一次迭代过程中，根据模型的输入，利用GCN层进行特征提取，利用Attention层融合邻居节点特征，然后利用GRU层更新每个节点的表示。最后，利用softmax分类器输出预测结果。模型的训练过程分为三个阶段，包括准备阶段、训练阶段、预测阶段。模型的架构如下图所示:  


### （2）输入
#### （a）用户特征
Cooperative Graph Neural Network的输入包括两个部分，分别是用户特征和行为特征。用户特征包括用户的ID、用户的类型、用户的兴趣偏好等，行为特征包括用户在不同时间点的行为记录。用户ID、用户类型、兴趣偏好都可以直接用数字编号或one-hot编码，而用户行为记录需要转化为标准的稀疏矩阵表示。用户行为记录的每一条记录对应了用户的某个操作，例如点击、收藏、浏览等等。记录的第一维代表了时间，第二维代表了该用户的不同操作，第三维代表了不同的物品，记录的值代表了用户对不同物品的操作频率。通常来说，用户行为的稀疏程度较高，因此可以使用Sparse Matrix存储，例如CSR或者CSC格式存储。

#### （b）邻居采样
Cooperative Graph Neural Network采用了邻居采样策略，对每个节点选择一定数量的邻居节点，从而能够捕捉到用户之间的社交关系。邻居节点的选择方式有两种，一种是根据节点的历史行为进行采样，另一种是根据节点的Embedding距离进行采样。Cooperative Graph Neural Network的采样率设置为0.1，即10%的节点为邻居节点。

### （3）图神经网络模块
#### （a）GraphSAGE
GraphSAGE是一个经典的图神经网络模块，它的基本思路是在每一次迭代过程中，将中心节点的邻居节点信息汇聚起来，然后在此基础上再进行特征提取，形成一个隐含的表示向量。GraphSAGE的主要原理是“聚合”邻居节点的信息。它提出了一个可学习的函数$H^{(l)}=f_{\theta}(AGG(\{\hat{h}_{v}^{l},\forall v \in N(u)\})W_{l}^{T}\Theta^{l})$，其中$\hat{h}_{v}^{l}$为中心节点$u$的第$l$层邻居节点$v$的特征向量，$N(u)$为中心节点$u$的邻居节点集合。$AGG(\cdot)$为聚合函数，可以选择均值函数或者LSTM函数。$\Theta^{l}$为模型参数，$W_{l}^{T}\Theta^{l}$为权重。

#### （b）Attention层
Attention层可以融合不同邻居节点的全局上下文信息。它使用一个权重矩阵来计算不同邻居节点的注意力系数，再通过softmax归一化得到不同邻居节点的权重系数。具体来说，Attention层的输出表示形式如下：  
$$
x_j=\sigma(\sum_{i \in N(j)}\alpha_{ij}h_i^{\prime}), h^{\prime}_i=\frac{\text { LSTM } (h_i, u ; W_{\text { att }})}{\sqrt{|N(i)|}}, \quad \forall j \in V,\quad i \in N(j),
\tag{1}
$$
其中，$\sigma(\cdot)$为sigmoid激活函数；$V$为图中的所有节点集合；$N(j)$为节点$j$的邻居节点集合；$h_i$为节点$i$的特征向量；$h^{\prime}_i$为节点$i$的注意力向量；$W_{\text { att }}$为Attention层的参数；$u$为表示用户的元信息。

#### （c）GRU层
GRU层是一种循环神经网络层，能够捕捉到用户的序列信息。它使用遗忘门、更新门来控制信息的丢弃与保存。具体来说，GRU单元的输出为：  
$$
\begin{array}{ll}
r_i & =\sigma(W_{ru}h_{i-1}+W_{rc}x_i+\epsilon_r)\\
z_i &= \sigma(W_{zu}h_{i-1}+W_{zc}x_i+\epsilon_z)\\
\widetilde{h}_i &= tanh(W_{cx}x_i + r_i \odot (W_{ch}h_{i-1}+b))\\
h_i &= z_i\odot h_{i-1}+(1-z_i)\odot \widetilde{h}_i, \quad i>1
\end{array}
\tag{2}
$$
其中，$\sigma(\cdot)$为sigmoid激活函数；$x_i$为时间步$i$的输入；$h_{i-1}$为时间步$i-1$的状态；$r_i$, $z_i$, $\widetilde{h}_i$, $h_i$ 分别表示遗忘门、更新门、候选状态和最终状态；$W_{ru}$, $W_{rc}$, $W_{ru}$, $W_{zu}$, $W_{zc}$, $W_{cu}$, $W_{cx}$, $W_{ch}$, $b$ 为GRU层的参数。

### （4）损失函数
Cooperative Graph Neural Network的损失函数为Softmax交叉熵。它衡量了预测的正确率。

### （5）多尺度采样
Cooperative Graph Neural Network采用了多尺度采样策略，首先对整个图进行采样，接着把采样得到的子图送入GNN模型进行训练。多尺度采样策略能够学习到全局信息和局部信息，并且在稀疏数据下也能取得不错的效果。

### （6）混合精度训练
为了缓解计算资源限制的问题，Cooperative Graph Neural Network采用了混合精度训练策略。它同时兼顾了浮点运算和低精度定点运算的效率，能够有效降低计算成本，缩短训练时间。目前，主流深度学习框架支持混合精度训练，如TensorFlow的XLA和PyTorch的Apex。

## （四）模型评价
Cooperative Graph Neural Network的评价指标主要有准确率、召回率、覆盖率、新颖度、新颖指数等。准确率和召回率度量了推荐结果的正确率，覆盖率和新颖度衡量了推荐结果的广度和深度，而新颖指数则更加全面地评估了推荐结果的新颖程度。