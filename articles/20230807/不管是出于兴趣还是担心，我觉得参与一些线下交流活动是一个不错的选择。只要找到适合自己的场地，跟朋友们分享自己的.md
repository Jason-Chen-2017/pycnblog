
作者：禅与计算机程序设计艺术                    

# 1.简介
         

         欢迎加入知识星球,专注于AI领域。通过“线上+线下”的方式促进AI的普及与应用。一起探索智慧的海洋，共同推动人类进步。
         “星球”旨在提供一个开放、自由的平台让更多人来分享、讨论AI相关话题，包括但不限于：
          - AI/ML算法模型
          - NLP/CV等技术领域的研究及应用
          - 产品落地方案
          - 工程落地经验
          - 技术创新方向
         ... 
         
         
         
         
         
         
         # 2.相关名词及概念介绍
         
         · AI:Artificial Intelligence(人工智能)
         
         · ML:Machine Learning(机器学习)
         
         · DL:Deep Learning(深度学习)
         
         · CNN:Convolutional Neural Network(卷积神经网络)
         
         · RNN:Recurrent Neural Network(循环神经网络)
         
         · GAN:Generative Adversarial Networks（生成对抗网络）
         
         · LSTM:Long Short-Term Memory(长短时记忆网络)
         
         · Transformer:Attention Is All You Need (Transformer) (注意力所有你所需要的)
         
         · CUDA:Compute Unified Device Architecture(统一计算设备架构)
         
         · GPU:Graphics Processing Unit(图形处理器单元)
         
         · TPU:Tensor Processing Unit(张量处理器单元)
         
         · BERT:Bidirectional Encoder Representations from Transformers (双向编码器表征)
         
         · Seq2seq:Sequence to Sequence(序列到序列模型)
         
         · Attention Mechanism:注意力机制，指的是将输入的不同元素映射到输出的不同元素上，使得输出中每一步都只能看到与当前输入相关的信息。如RNN中的隐藏层可以看做是一个由很多输入与输出相互映射的注意力矩阵，通过注意力矩阵，可以帮助RNN根据历史信息更准确地预测未来的输出。
         
         · Embedding:embedding 是一种自然语言处理技术，能够将文本转换成稠密向量，以便进行下游的NLP任务。它通过学习词语之间的语义关系，从而达到提取语义信息的目的。Embedding 的输入是单词或句子，输出是固定维度的向量表示。
         
         · Tokenization:分词，即将原始文本按照字、词、句子等单位切分成具有意义的多个词语或者短语的过程。中文文本常用分词工具有 jieba，Hanlp等。英文文本常用分词工具有 NLTK 或 spaCy。
         
         · Padding:填充，是对输入数据进行预处理的一环，目的是使其满足模型的要求，即每个样本的长度相同。由于不同的样本长度可能存在差异，因此一般会对数据进行padding操作，使其长度变为最大的样本长度。Padding 方式有两种：前后补齐；常数值补齐。
         
         · Difference between Classification and Regression tasks:分类任务是指给定样本的输入特征，模型应该输出目标变量的离散分类结果，如垃圾邮件识别、手写数字识别等；回归任务是指给定样本的输入特征，模型应该输出一个连续值，如股票价格预测等。
         
         · Overfitting:过拟合是指训练集的误差很小，但是测试集的误差较大，原因是模型过于复杂导致欠拟合。应采取以下措施缓解过拟合：1、增加样本数量；2、增强模型的复杂度；3、减少正则化项、参数规模和隐含层数目；4、早停法控制迭代次数；5、使用集成方法提高性能。
         
         · Dropout:Dropout 是深度学习的一个重要技术，用来防止过拟合。dropout 随机关闭一定比例的神经元，从而使神经网络的平均表现不受单个神经元的影响。 dropout 在训练过程中随机丢弃某些节点，而不是像 SGD 方法那样把它们设为 0。dropout 除了降低模型的复杂度外，还可以起到减少 overfitting 的作用。
         
         · Batch Normalization:Batch Normalization 是深度学习的一个层级标准化技术，主要用于加快模型收敛速度并提升模型精度。Batch Normalization 将每批数据标准化，使得网络收敛更顺利，同时使得不同尺寸的数据分布范围一致，降低了模型的方差。
         
         · Activation Function:激活函数是深度学习中的关键组件之一，主要用于解决梯度消失和爆炸问题。常用的激活函数有 sigmoid 函数、tanh 函数、ReLU 函数、Leaky ReLU 函数、ELU 函数。其中，sigmoid 函数和 tanh 函数比较常用，其他激活函数均有各自特点。
         
         · Optimizer:优化器是在深度学习中更新神经网络权重的算法，可以有效提升模型的训练效率和性能。常用的优化器有 Adam、SGD、Adagrad、RMSprop 等。其中，Adam 是最常用的优化器，速度也最快，而且在一定程度上解决了动量和梯度平滑的问题。
         
         · Softmax Function:Softmax 函数是一种对模型输出进行归一化的方法，用于将输出值转换成概率分布，使得模型输出更加可信。
         
         · Convolutional Neural Network(CNN):卷积神经网络是深度学习中应用最广泛的神经网络模型。CNN 的主要特点是卷积层和池化层。卷积层可以提取图像特征，并对局部区域进行特征检测；池化层则可以降低参数数量，并减少计算量。
         
         · Recurrent Neural Network(RNN):循环神经网络是深度学习中另一类重要模型，其特点是能够捕捉时间序列数据中的长期依赖关系。RNN 模型可以捕捉时间序列数据的动态变化，并产生一个序列的输出。
         
         · Generative Adversarial Networks(GANs):生成对抗网络是最近出现的深度学习模型，是一种基于生成模型的无监督学习方法。它由两个网络构成：生成器和判别器。生成器网络是专门生成虚假数据的网络，试图通过对真实数据进行操控，得到一个连续且逼真的样本。判别器网络则是一个二元分类器，用于区分输入数据是否是真实数据。GAN 网络的训练目标就是使生成器的输出越来越接近真实数据，这样才可以增加真实数据的多样性。
         
         · Long Short-Term Memory(LSTM):长短时记忆网络是另一种常见的 RNN 模型，它的特点是可以保留之前状态的信息，并且能够自动修正或更新这些信息。LSTM 可以记住过去的时间序列数据，并利用此信息来预测或描述下一个时间步的数据。
         
         · Attention Mechanism:注意力机制可以视作是对 LSTM 或 GRU 中的隐藏状态进行筛选，从而选择性地关注输入序列中的特定片段，并向前传播该片段的信息。注意力机制可以学习输入特征之间的联系，并将注意力放在与当前输入最相关的特征上。
         
         · Word embedding:Word embedding 是一种自然语言处理技术，能够将文本转换成稠密向量，以便进行下游的NLP任务。它通过学习词语之间的语义关系，从而达到提取语义信息的目的。Embedding 的输入是单词或句子，输出是固定维度的向量表示。常见的 Word embedding 有 GloVe、word2vec 和 fastText 等。
         
         · Tokenization:分词，即将原始文本按照字、词、句子等单位切分成具有意义的多个词语或者短语的过程。中文文本常用分词工具有 jieba，Hanlp等。英文文本常用分词工具有 NLTK 或 spaCy。
         
         · Padding:填充，是对输入数据进行预处理的一环，目的是使其满足模型的要求，即每个样本的长度相同。由于不同的样本长度可能存在差异，因此一般会对数据进行padding操作，使其长度变为最大的样本长度。Padding 方式有两种：前后补齐；常数值补齐。
         
         · Vocabulary size:词汇量是指在词袋模型中，词汇表的大小，通常超过5000个就容易发生词汇爆炸问题，为了避免这个问题，可以使用词频 threshold 来过滤掉低频词。