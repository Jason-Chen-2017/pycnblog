
作者：禅与计算机程序设计艺术                    

# 1.简介
  

矩阵的求逆(Inverse matrix)是数值计算中经常遇到的问题之一。矩阵求逆有很多种不同的方法，例如行列式法、高斯消元法、LU分解等，本文将介绍几种常用的矩阵求逆方法及其应用。

# 2.基本概念
## 2.1 定义
一个m行n列的矩阵$A=(a_{ij})$, $i=1,2,\cdots,m; j=1,2,\cdots,n$称为m×n维(m by n dimension)，记作$A\in \mathbb{R}^{m \times n}$。如果存在另一个矩阵$B=(b_{ij}), i=1,2,\cdots,m, j=1,2,\cdots,n$使得$AB=\mathrm{I}_n (单位阵), \quad BA=\mathrm{I}_m (\cdot)$,则称$A$可逆，或$A^{-1}$,并且记作$A^-$ 或 $\left(\frac{1}{det A} \right)^{1/n}A$.

## 2.2 行列式
对于一个n阶方阵$A=(a_{ij}), i=1,2,\cdots,n-1, j=1,2,\cdots,n-1$, 它的行列式（determinant）$\det A$是一个实数，满足以下两个条件:

1. 当$j=1,2,\cdots,n-1$时, 在代换下式:

   $$\det A=\sum_{\alpha=1}^n (-1)^{\alpha+i}(a_{\alpha 1})(a_{\alpha 2})\cdots (a_{\alpha n-1})(a_{\alpha n})$$

   中，$-1^{\alpha+i}=(-1)^i$为互换求和顺序的运算符号，即将所有$(-\alpha)!$相乘后的结果相加；$a_{\alpha n}\neq 0$。

2. 如果$A$的第$i$行$r_i$及第$i$列$c_i$任意两者元素不全为零，那么$\det A=-\det A$。

**证明:** 

根据对称性，我们只需考虑对角线上的元素。假设将$A$按下标为$k$的元素变换到$A$的左上角的位置($1\leqslant k\leqslant n$)，那么其行列式变化不会影响其它元素的值，而行列式的符号也不会改变，因此要么是0要么是不定号数，即可以用负数表示或者用不同号数表示。当$A$为奇异矩阵时，因为对任何$k>n$都有$a_{kk}=0$，故行列式恒等于0；当$A$可逆时，因为行列式存在且不为0，所以符号不一定为正或者负。

又因$A$为n阶方阵，所以有$\det A \neq 0$。如果$A$的某些元素值为0，则在它们所在行、列的元素中选取不为0的元素，并去掉这些元素所在的行、列，剩下的子矩阵为$A^\prime$。由第1条结论可知，$A^\prime$的行列式就是$|A|$。因此，$\det A$的符号为$|-1|=1$。 

依据乘法交换律和共轭律，从而推出了$\det A$的符号规律。

# 3.行列式法
## 3.1 方法概述
19世纪，帕雷托、马尔科姆·海瑟、约翰·克莱顿三人 independently 提出了计算矩阵逆的方法——“行列式法”，它通过分析行列式的值，得到其逆矩阵。行列式法的第一个主流方法基于Cramer's rule。

方法如下： 

1. 求出行列式的绝对值的模值：$d = | \det A |$ 
2. 求出各行元素的系数：$x_i = \frac{\det B_i}{\det A}, i=1,2,\cdots,m$ 
3. 求出各列元素的系数：$y_j = \frac{\det C_j}{\det A}, j=1,2,\cdots,n$ 
4. 用上述结果建立矩阵$X=(x_1, x_2, \cdots,x_m), Y=(y_1, y_2, \cdots,y_n)$ 
5. 构造矩阵$A^{-1}=Y\cdot X^{-1}$ 

其中，$B_i=(a_{\alpha j}), i=1,2,\cdots,m, j=1,2,\cdots,n$ 为去掉第i行之后的$A$；$C_j=(a_{i \beta }), i=1,2,\cdots,m, j=1,2,\cdots,n$ 为去掉第j列之后的$A$。

## 3.2 代码实现
```python
import numpy as np

def inverse(A):
    if len(np.shape(A))!= 2 or np.shape(A)[0]!= np.shape(A)[1]:
        raise ValueError("input is not a square matrix")

    d = abs(np.linalg.det(A)) # calculate the determinant of input matrix
    
    if d == 0:
        print("Matrix is singular.")
        return None

    else:
        inv_matrix = []
        
        for i in range(len(A)):
            temp = []
            for j in range(len(A[0])):
                adj_mat = [[A[(i+t)%len(A)][(j+s)%len(A)] for s in range(len(A))] for t in range(len(A))] # get an adjoint matrix with row and column index swapped
                sign =((-1)**((i+j)%2)) # use the parity to alternate signs
                cofactor = sign * det(adj_mat)//d # calculate the coefficient of each element
                temp.append(cofactor)
            
            inv_matrix.append(temp)

        inv_matrix = np.array(inv_matrix).astype('float')
        return inv_matrix / np.linalg.det(A)
    
def det(A):
    if len(np.shape(A)) == 1: 
        return reduce(lambda x, y: x*y, [A[-(i+1)][-(i+1)] for i in range(len(A))]) # recursive function to compute determinant
        
    elif len(np.shape(A)) == 2:
        rows, cols = np.shape(A)[:2]
        
        if rows > 2 and cols > 2:
            sum_diag = sum([A[i][i]*A[i][i] for i in range(rows)]) # calculate diagonal elements' values
            sum_rest = sum([det(np.delete(np.delete(A,i,axis=0),i,axis=1))*(((-1)**(i%2)))**(cols//2) for i in range(rows)]) # calculate nondiagonal elements' values
            
            return sum_diag - sum_rest
            
        else: # base case when matrix size is less than or equal to 2
            return A[0][0]*A[1][1]-A[0][1]*A[1][0]
```

## 3.3 算法性能分析
行列式法的时间复杂度是O(mn^3)，主要占用内存空间大小为O(mn)。对于对称矩阵而言，其行列式的值只有+1或-1，因此比较适合于此方法。但对于一般情况，行列式法并不能保证高精度的计算，除非输入数据非常小。另外，行列式法只能求出方阵的逆，对于更为一般的矩阵求逆问题，其他一些方法（如LU分解、Cholesky分解、QR分解等）更加有效。

# 4.高斯消元法
## 4.1 方法概述
高斯消元法（Gauss elimination method）是一种利用矩阵相减和行初等变换来化简矩阵的基本方法，其目的是使每一行右边只含有一个非零元素，从而使矩阵变成上三角矩阵（upper triangular matrix），然后再用回代法来求解另一侧的变量。

步骤如下：

1. 对每个非零元素找到对应的上三角矩阵的位置并将其减去相应倍数的另一行元素。直到每一行右边只含有一个非零元素。
2. 将最下面的一行元素移至右下角。
3. 用回代法解出所有未知数。

## 4.2 代码实现
```python
def gauss_elimination(A):
    m, n = len(A), len(A[0])
    U = [[0]*n for _ in range(m)] # create upper triangular matrix
    
    # copy original matrix into upper triangle matrix
    for i in range(min(m, n)):
        pivot_row = max(range(i, m), key=lambda r: abs(A[r][i])) # find maximum absolute value from unpivoted rows below current row
        
        if A[pivot_row][i]!= 0: # swap rows if needed
            A[i], A[pivot_row] = A[pivot_row], A[i]
            U[i], U[pivot_row] = U[pivot_row], U[i]
        
        for j in range(i+1, n):
            factor = A[i][j]/A[i][i] # calculate multiplier
            
            for k in range(i, n):
                A[i][k] -= factor*A[i][i] # subtract multiplied row from all other rows
                U[i][k] -= factor*U[i][i]
    
    # back substitution algorithm
    b = [0]*m # allocate space for solutions
    
    for i in reversed(range(n)):
        coef = U[i][i]
        assert coef!= 0 # singular matrix error
        
        b[i] = (A[i][n] - sum(U[i][:i]*[coef]*b[:i])/coef)/U[i][i] # solve system using divided differences formula
        
    return [tuple(b)] # convert solution list to tuple of tuples
    
# example usage:
A = [[2,-3],[1,1]]
print(gauss_elimination(A)) #[(1.0, -0.33333333333333337)]
```

## 4.3 算法性能分析
高斯消元法有很好的稳定性和准确性，但其计算量较大，时间复杂度为O(n^3)。对于对称矩阵，其计算速度一般很快。但对于一般情况，该方法需要进行多次分块处理，降低了效率。除此之外，在高斯消元法的迭代过程中，需要进行重复的消元过程，导致算法不易收敛。

# 5.LU分解
## 5.1 方法概述
LU分解（LU decomposition）是一种重要的矩阵分解技术，它把一个矩阵分解为两个矩阵的乘积，并同时保持矩阵的秩不变。LU分解通常用于求解线性方程组及其高效求解。

LU分解步骤如下：

1. 分别对主对角线以及上三角矩阵进行初等化，使其变成一个上三角矩阵。
2. 按照顺序扫描上三角矩阵中的元素，计算非主对角线元素。
3. 对每一个非主对角线元素进行初等化，并更新矩阵。

## 5.2 代码实现
```python
from functools import lru_cache
@lru_cache()
def LU(A):
    L = [[0]*len(A) for _ in range(len(A))] # create lower triangular matrix
    U = [[0]*len(A) for _ in range(len(A))] # create upper triangular matrix
    
    # forward step for P, L, and U matrices calculation
    for j in range(len(A)):
        L[j][j] = 1
        for i in range(j, len(A)):
            dot_product = sum(L[j][:j]*U[i][:j])
            U[j][i] = A[j][i] - dot_product
            
        for i in range(j, len(A)):
            dot_product = sum(L[j][:j]*U[i][:j])
            L[j][i] = (A[j][i] - dot_product)/(U[j][j] if U[j][j]!=0 else float('nan'))
            
    return L, U
    
# example usage:
A = [[2.,-3.],[-1.,1.]]
P, L, U = LU(A)
print(P) #[[1.0, 0.0], [-1.0, 1.0]]
print(L) #[[1.0, 0.0], [2.0, 1.0]]
print(U) #[[2.0, -3.0], [0.0, 1.0]]
```

## 5.3 算法性能分析
LU分解的计算量较小，时间复杂度为O(n^3)，但是存储空间为O(n^2)。对于对称矩阵，LU分解效果不错。然而，对于一般情况下，LU分解并没有什么优越性。除此之外，LU分解要求输入矩阵必须是方阵，如果输入矩阵不是方阵，则需要先进行变形处理才能进行LU分解。