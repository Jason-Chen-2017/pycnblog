
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


## ID3算法(Iterative Dichotomiser 3)简介
ID3（Iterative Dichotomiser 3）算法是一种用于决策树学习的经典算法。它由罗纳德·李剑、弗朗西斯科·索尔、洪姆试图三人合著在1986年提出。它的主要特点是能够生成一棵高度平衡的决策树，即预测能力接近甚至超过随机猜测的平均值。

相比于其他决策树算法，如CART(Classification and Regression Tree)，使用信息增益作为划分标准。信息增益用来度量数据集的不确定性。熵则用来度量数据集的混乱程度。

假设有如下二分类数据集：

| 年龄 | 性别 | 收入 | 是否违约 |
| ---- | ---- | ---- | -------- |
| 青年 | 男   | 高   | 否       |
| 中年 | 女   | 普通 | 是       |
| 老年 | 男   | 低   | 否       |
|...  |...  |...  |...      |

使用基于信息增益的ID3算法，可以生成如下决策树：



如上图所示，年龄和性别两个特征被选中用来分割数据集。年龄特征被选中的原因是它具有最大的信息增益值(4.5)。

这种方法生成的决策树具有较高的准确率，但对于某些数据集来说，决策树可能过于复杂，并且难以处理高维的数据。此外，ID3算法没有考虑变量之间的关联性，因此对多变量数据集往往效果不佳。

为了克服这些缺陷，提出了C4.5算法。

## C4.5算法概述
C4.5算法是ID3算法的改进版本。其基本思想是在ID3算法基础上，引入了属性间的互信息来选择最优分支。由于互信息能够更好地反映属性之间的相关性，所以它能够使决策树更加有效地处理多变量数据集。同时，它还采用了经验熵代替了信息熵作为划分标准，从而可以更好地处理类不平衡的问题。

C4.5算法与ID3算法有以下不同之处:

1. 在计算分支节点的条件熵时，C4.5算法采用了经验熵，而不是信息熵；
2. C4.5算法中增加了互信息作为特征选择指标，并且可以通过预先计算的方式加速算法运行；
3. C4.5算法支持连续型变量，在寻找最优分割点时，不会将它们视为离散型变量。

## 算法流程

### 数据预处理
首先，需要对原始数据进行预处理，去除缺失值，标准化等。

### 属性选择
然后，选择最优特征。最优特征即为信息增益最大或者最好的属性，具体定义如下：

1. 对每个属性，根据目标变量的取值计算其经验熵；
2. 根据上面计算得到的各个属性的熵，计算属性的经验信息增益；
3. 如果存在多个最优属性，选择信息增益最大的那一个作为最优属性；
4. 当多个最优属性拥有相同的信息增益时，优先选择离散型变量作为最优属性；

### 递归构造树
基于已有的最优属性，递归地构建决策树。

1. 若所有样本属于同一类Ck，则置为叶子结点并将Ck作为该结点的类标记。
2. 否则，遍历该属性的所有可能取值a1,a2,...,an，依次为左子树，右子树。
    * 将D中所有AttributeValue=ai的样本分到左子树，将D中所有AttributeValue≠ai的样本分到右子树。
    * 递归地构造左子树和右子树，直到所有样本都属于单一类。
3. 返回根结点。

最后，得到的决策树即为C4.5算法生成的决策树。

### 注意事项
* 如果训练样本只有一种类别，那么决策树生成的结果就是单结点决策树，即根结点只有一个类标记。
* 如果某个特征对分类完全无用，比如说它只对类别有影响但是没能区分，则该特征就不应该出现在决策树中。

## 代码实现
这里使用Python语言，实现C4.5算法的代码。

```python
import math
class Node:
    def __init__(self, attribute_name):
        self.attribute_name = attribute_name # 分割属性名称
        self.children = {} # 分支字典

def get_entropy(labels):
    """计算给定数据集的经验熵"""
    if len(set(labels)) == 1:
        return 0
    freq = [float(labels.count(x))/len(labels) for x in set(labels)]
    entropy = sum([-p*math.log(p,2) for p in freq])
    return entropy

def get_info_gain(data, feature, target):
    """计算给定数据集的经验信息增益"""
    attr_values = list(set([row[feature] for row in data]))
    gain = []
    for value in attr_values:
        sub_data = [(row[:], row[-1]) for row in data if row[feature]!= value] # 生成划分后的数据子集
        sub_target = [row[-1] for row in sub_data]
        prob = float(sub_data.__len__()) / data.__len__()
        info = get_entropy(sub_target)*prob
        gain.append((value, info))
    max_gain = max([v[1] for v in gain])
    split_val = [v[0] for v in gain if v[1] == max_gain][0]
    return (max_gain, split_val)
    
def get_conditional_entropy(data, parent_ent, feature, value):
    """计算给定数据集的条件熵"""
    rows = [[row[:] for i in range(len(row))] for row in data if row[feature] == value]
    labels = [row[-1] for row in rows]
    ent = sum([get_entropy(labels), parent_ent])/parent_ent
    return ent

def build_tree(data, features, target):
    """递归构造决策树"""
    if not any(features): # 数据集为空或所有特征均已处理完
        count = collections.Counter(row[-1] for row in data).__dict__['items']
        max_label = sorted(count)[-1]
        node = Node('')
        node.label = 'Label=%s'%max_label[0]+',Count=%d'%max_label[1]
        return node
    
    # 获取信息增益最大的特征及其切分值
    gains = [(f, get_info_gain(data, f, target)[0]) for f in features]
    best_feat, best_gain = max(gains, key=lambda x: x[1])
    
    root = Node(best_feat)

    # 获取所有值列表和对应的信息增益
    values = sorted(list(set([row[best_feat] for row in data])))
    gains = {value: get_info_gain(data, best_feat, target)[0]-get_conditional_entropy(data, get_entropy(target), best_feat, value) for value in values}

    # 按信息增益排序后的分裂值列表
    split_vals = sorted(gains, key=gains.get, reverse=True)
    for val in split_vals[:-1]:
        child = Node(best_feat+'='+str(val))
        root.children[child.attribute_name] = child
        
    left_data = [(row[:], row[-1]) for row in data if row[best_feat]<split_vals[-1]]
    right_data = [(row[:], row[-1]) for row in data if row[best_feat]==split_vals[-1]]
    del right_data[-1]
    
    feat_left = copy.deepcopy(features)
    del feat_left[best_feat]
    for row in left_data:
        cur_node = root
        while True:
            cur_attr = cur_node.attribute_name
            if cur_attr == '':
                break
            elif '=' in cur_attr:
                attr_name, attr_val = cur_attr.rsplit('=', 1)
                if row[attr_name] <= int(attr_val):
                    next_node = cur_node.children[cur_attr]
                    break
                else:
                    cur_node = None
            else:
                next_node = cur_node.children[cur_attr]
                cur_node = None
                
        if not cur_node or isinstance(next_node, str):
            continue
        
        label = ''.join([x+':'+str(y)+','for x, y in zip(sorted(data[0])[:-1], row[:-1])] + ['Label='+str(row[-1])+',']).rstrip(',')
        if isinstance(next_node, str):
            next_node = Node('')
            
        if next_node.attribute_name in feat_left:
            create_nodes(next_node, feat_left, label, left_data)
        else:
            add_to_leaf(next_node, label)
            
    feat_right = copy.deepcopy(features)
    del feat_right[best_feat]
    create_nodes(root, feat_right, '', right_data)
    return root
        
def create_nodes(node, feat, prev_label='', data=[]):
    """创建决策树节点"""
    if not feat:
        counts = collections.Counter(row[-1] for row in data).__dict__['items']
        max_label = sorted(counts)[-1]
        node.label = '%s%s'%(prev_label,'Label=%s'%max_label[0]+',Count=%d'%max_label[1])
        return
    
    # 获取信息增益最大的特征及其切分值
    gains = [(f, get_info_gain(data, f, [-1])[0]) for f in feat]
    best_feat, best_gain = max(gains, key=lambda x: x[1])
    
    root = node
    if not hasattr(root, 'children'):
        root.children = {}
    children = getattr(root, 'children')
    child = Node(best_feat)
    children[child.attribute_name] = child
    
    nodes = sorted([(k, getattr(v, 'label')) for k, v in children.items()], key=lambda x: x[1])
    if prev_label and nodes and ('=' in nodes[-1][0]):
        _, last_label = nodes[-1]
        new_last_label = ','.join([''.join([x+':'+str(y)+',' for x, y in zip(sorted(data[0])[:-1], row[:-1])] + ['Label='+str(row[-1])+',']).rstrip(',') for row in data if int(x)<int(nodes[-1][0].rsplit('=', 1)[1])])
        setattr(getattr(root, nodes[-1][0]), 'label', last_label+',\n'+new_last_label)
        nodes = nodes[:-1]
    
    for i, n in enumerate(nodes):
        feats = copy.deepcopy(feat)
        feats.remove(n[0])
        label = n[1]
        index = n[0].find('=')
        if index >= 0:
            node_val = n[0][:index+1]
        else:
            node_val = ''
        if i < len(nodes)-1 and n[0] == nodes[i+1][0]:
            continue
        next_node = children[n[0]]
        create_nodes(next_node, feats, label, [row for row in data if row[best_feat]<=node_val or (isinstance(node_val, str) and int(node_val)<int(rows[0][best_feat]))])
            
def add_to_leaf(node, label):
    """添加到叶节点"""
    leaf = node
    while True:
        if isinstance(leaf, str):
            leaf = Node('')
        if hasattr(leaf, 'label'):
            break
        leaf = getattr(leaf, 'children')['']
    if leaf.label is None:
        leaf.label = label
    else:
        leaf.label += '\n' + label
```