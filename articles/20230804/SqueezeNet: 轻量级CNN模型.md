
作者：禅与计算机程序设计艺术                    

# 1.简介
         
 SqueezeNet，中文名叫压缩感知网（Convolutional Neural Network for Visual Recognition），由斯坦福大学DeepGrid团队在2016年提出，是一款轻量级的CNN模型。该网络结构中采用了高效的分离卷积(squeeze)操作，将空间信息和通道信息相互结合后得到有效的特征表示，从而达到降低计算复杂度、减少参数数量及降低内存占用等目的。SqueezeNet能在不损失精度的情况下获得比AlexNet更小、快的推理速度。它的最大特点是轻量化，在相同大小的模型中参数数量仅有AlexNet的一半，却可以取得与AlexNet相媲美甚至更好的性能。
          # 2.基本概念及术语说明
          ## 概念
          ### 模型架构
          SqueezeNet主要由两部分组成，第一部分为卷积层，第二部分为全连接层。卷积层利用分离卷积操作提取特征，全连接层通过全局池化和softmax层输出分类结果。如下图所示： 

          在上述网络结构中，卷积层由多个$3    imes3$卷积核堆叠构成，可以看作是多个滤波器对图像进行卷积操作，每个滤波器具有自己专属的卷积核参数。如图中的蓝色块就是一个滤波器。卷积层的输出被称为特征图，记作$f_l$，其中$l$代表第$l$个卷积层，其高度、宽度和通道数与输入图像相同。特征图经过不同尺寸的池化操作之后，提取到的都是局部特征，因此需要下采样再上采样才能获得全局特征。

          全连接层包括$1     imes 1$卷积核和全局池化层，用于对特征进行降维、升维和归一化处理。$1 \mrmqsize$卷积核通过缩小每个元素的维度，降低通道数，而全局池化层则通过对特征进行均值池化或最大池化，从而获得固定维度的向量作为神经元的输入。最后一个全连接层输出的是分类结果。
          
          ### 分离卷积
          分离卷积(squeeze operation)，是指在卷积操作时先将每个通道上的权重进行约束，并舍弃冗余的权重，从而减少参数数量和降低计算量。SqueezeNet中的卷积操作实现了分离卷积，它首先应用逐通道的$1     imes 1$卷积核，将每个通道的卷积核矩阵分解为两个子矩阵。第一个子矩阵对应于低秩矩阵，第二个子矩阵对应于高秩矩阵。然后，再对低秩矩阵和高秩矩阵分别进行卷积操作，得到两个子矩阵的卷积结果。最终，把两个子矩阵的卷积结果按照特定顺序组合起来，得到整个卷积操作的输出。
          ### 压缩率
          论文中也提到了压缩率的概念，即网络参数占总参数的比例。表明其与模型大小成正比。一般来说，压缩率越高，代表着模型的参数越少，因此模型越小。参数数量越少，意味着模型的运算速度越快。
          ### 网络规模
          SqueezeNet的网络规模指的是网络每一层的通道数量，例如SqueezeNet-1.0、SqueezeNet-1.1等等。网络规模越小，表示参数数量越少，网络的计算速度越快；网络规模越大，表示参数数量越多，网络的计算速度越慢。
          ### 计算量
          计算量是指网络对于给定输入大小的计算量。由于卷积层由多个$3     imes 3$滤波器组成，因此计算量随着滤波器个数的增加而增加，相应地，全连接层的参数数量也会随之增加，因此计算量也是依次增大的。但是，由于分离卷积的存在，参数数量远远小于原本的卷积层，因此总体的计算量依然保持很低。
          ## 术语
          - $M_    ext{block}$：单个卷积块的个数
          - $N_    ext{stack}$：网络中堆叠卷积块的个数
          - $    heta_{i}$：第$i$个分支的权重矩阵，$i$表示第几个分支（第几层的卷积层）。$W^i_{    ext{k}j}$表示权重矩阵的第$k$行第$j$列元素。
          - $\alpha_{ij}^{l}$：在$l$层卷积块中的第$i$个分支在第$j$个位置的步长。$\alpha_i^{l}$表示第$l$层卷积块的第$i$个分支的步长。
          - $\beta_{i}^{l}$：在$l$层卷积块中的第$i$个分支的感受野大小。
          - $\rho_{1},\rho_{2}$：权重共享率。
          - $\rho$-net：稀疏层。
          ## 操作步骤及数学公式
          下面将详细阐述SqueezeNet的具体操作步骤以及数学公式。
          1. 基础设置
            - 设置卷积核大小为$K=\{3\}$，激活函数为ReLU。
            - 对输入数据做标准化，使得每一层的输入数据的均值为0，方差为1。
          2. 前馈网络
            - 每层卷积层使用逐通道的$3    imes 3$卷积核进行卷积，但不是使用普通的三维卷积，而是先将通道数目进行分离卷积，即先将每个通道的卷积核矩阵分解为两个子矩阵。第$l$层的卷积核矩阵可以分解为两个$M_l    imes N_l$矩阵$A_l$和$B_l$，满足：
              $$A_l = W^l_{1\cdot }$$
              $$\quad B_l = W^l_{2\cdot }$$
              其中，$A_l$的每个元素为卷积核参数矩阵的一个条目，$B_l$的每个元素为0。
              将卷积核分解为两个矩阵还有一个好处，可以让SqueezeNet节省大量的参数。
            - 使用逐点卷积进行训练，即在每一次迭代过程中，都用输入数据乘以卷积核矩阵，然后加上偏置项。
            - 每层卷积层之后都会有激活函数ReLU，从而引入非线性变换，缓解模型的过拟合现象。
            - 池化层：
              - 当需要降低高度和宽度时，选择平均池化层。
              - 当需要提取全局信息时，选择最大池化层。
              - 可以尝试其他池化方式，比如带 stride 的最大池化层。
          （待续）