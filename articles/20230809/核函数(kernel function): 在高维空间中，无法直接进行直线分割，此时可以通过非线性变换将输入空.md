
作者：禅与计算机程序设计艺术                    

# 1.简介
         
　　假设我们要对复杂的二维数据进行分类或回归任务。比如图像处理、机器学习中的回归问题、文本分类等。对于这些复杂的数据来说，一般都不是直接可视化的，需要通过一些方法对其进行降维或可视化才能看清楚。其中一种方法就是采用核方法(Kernel method)，也就是用某种核函数(kernel function)将原始特征映射到一个低维空间中，再在低维空间里进行分析或学习。核方法可以解决很多分类或回归问题。例如：
         
         - 在图像处理中，我们可以使用基于像素邻域的方法将图像数据压缩成少量的特征向量；或者采用核神经网络，先训练出卷积核(convolutional kernel)，然后通过卷积计算得到新的特征图。
         - 在文本分类或推荐系统中，我们可以使用主题模型或词袋模型获得词频统计信息作为特征向量，再使用核方法映射到一个低维空间进行分析或分类。
       
       # 2.概念术语说明
       ## 2.1 原空间(input space)与子空间(feature space)
       在高维空间中，如果输入空间过于复杂而难以直接进行可视化或分析，通常会选择某种非线性变换将输入空间映射到一个低维空间中，从而方便对数据进行分析或可视化。这种变换就叫做特征提取(feature extraction)。


       上图展示了输入空间与特征空间的关系。我们希望用某种变换将输入空间映射到特征空间中，但是当输入空间太大而不能直接进行可视化时，就需要采用核方法。所以，实际上所说的特征提取是将输入空间映射到特征空间，并且特征空间往往是一个更小的子空间。而后续的分析或学习则是在特征空间中进行的。

       ## 2.2 内积(inner product)
       特征空间中的两个向量之间的相似度度量可以用内积(inner product)表示。给定输入空间X，定义内积如下：

        $$
        \langle x_i, x_j\rangle = <x_i, x_j> = \sum_{k=1}^K x_i^k x_j^k
        $$ 

       这里$<\cdot,\cdot>$代表内积运算符。它是一个在输入空间X上的二范数(symmetric positive definite matrix)，且满足自反性、对称性和正定性。因此，它既可以衡量两个向量之间的差异大小，又可以衡量它们之间的相关程度。当然，对于输入空间X内的每个元素x，都有一个对应的特征向量$\phi(x)$，两者的内积就可以表示它们在特征空间中的相似度。
       ## 2.3 核函数(kernel function)
       核函数(kernel function)是指用来将输入空间映射到特征空间中的非线性函数。核函数由两个输入向量及其核矩阵进行评估。首先，输入向量$x_i$和$x_j$在核函数内积的定义式中隐含了一个二范数乘积。为了能够实现二阶导数的微分，核函数需要满足对称性和正定性，即定义为

        $$
        k(x_i, x_j) = \left\langle\phi(x_i), \phi(x_j)\right\rangle 
        $$ 

       其中，$\phi(\cdot)$是一个将输入空间映射到特征空间的非线性函数。$\phi(x)$也被称作核函数，核函数的输出是一个标量值。我们可以把核函数看作是一个将输入向量映射到特征空间的非线性变换。