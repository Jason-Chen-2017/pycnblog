
作者：禅与计算机程序设计艺术                    

# 1.简介
         
## 一、介绍
在现实世界中，许多事物都可以用向量来表示。例如：位置、速度、颜色、力、长度等。而对于数字化建模来说，计算机图形学、机器学习、深度学习、图像处理都是可以用向量进行运算的领域。因此，理解向量及其运算很重要。本文将系统地介绍向量的基本概念和运算规则。
## 二、基本概念
### 2.1 向量的定义
在一个向量空间（vector space）V中，一个n维向量是一个元素为实数的序列$\vec{x}=(x_1,\cdots,x_n)$，其中$x_i\in R$。这些元素的集合记作$\mathbb{R}^n$或$V=\mathbb{R}^{n}$，是向量空间的基，也可以说是n维欧氏空间（Euclidean space）。一个向量的加法和数乘运算分别由如下两个定义：
$$a(\vec{u}+\vec{v})=(a+b)u_1+(a+b)u_2+\cdots+(a+b)u_n $$
$$c(ax)=cx_1\cdot a+cx_2\cdot a+\cdots+cx_n \cdot a$$
其中，a，b，c是任意实数。
### 2.2 向量的加法
向量的加法也称之为矢量加法或点加。给定两个同维的向量$\vec{u},\vec{v}$，他们的加法运算满足以下分配律：$(\vec{u}+\vec{v})+\vec{w}= \vec{u}+\vec{v+w}$。即加法是可交换的。

类似的，对于一个向量$\vec{v}$,如果存在某个实数a，使得a与$\vec{v}$都是向量空间V的单位元，那么a与$\vec{v}$的相乘为零矢量：$0\vec{v}$.

另一方面，给定一个非零向量$\vec{v}$，如果a不是向量空间V的单位元，则存在某个实数c，使得c与$\vec{v}$的连乘为零：$ac\vec{v}=0$.

### 2.3 向量的数量积
向量的数量积也称之为点积或标量积，给定两个同维的向量$\vec{u},\vec{v}$，他们的数量积或者dot product可以表示为: $\vec{u}\cdot\vec{v}=u_1v_1+u_2v_2+\cdots + u_nv_n =\sum_{i=1}^{n}{u_iv_i}$。其中$u_i$, $v_i$ 分别是$\vec{u}$第i个分量，$\vec{v}$第i个分量。

这个运算得到的结果是一个实数，叫做向量的内积或点积，记作$\vec{u}\cdot\vec{v}$。它等于各分量的乘积之和。所以，对于实数$\alpha$和任意向量$\vec{v}$，有：
$$\alpha\vec{v}\cdot v_i=|\alpha|^2 v_i=\left|\begin{array}{ccc} 0&-\alpha&\cdots\\ -\alpha & 0&\cdots \\ &&\ddots \end{array}\right|v_i=\left|\frac{\alpha}{\sqrt{|v|}}\right|^2v_i$$
其中$\left|\frac{\alpha}{\sqrt{|v|}}\right|$是$\alpha$关于$\vec{v}$的一个规范化因子。若要求$\vec{u}\cdot\vec{v}$总是大于等于零，只需考虑正交向量：$\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_{k-1}$，且$\vec{u}\cdot\vec{v}_j=0$ (j=1,...,k-1)。因为如果$\vec{v}_j$是单位向量的话，那么$\left|\vec{u}\cdot\vec{v}_j\right|=0$，也就是$\vec{u}\cdot\vec{v}_j=0$ 。换句话说，任何一个不受其他单位向量影响的向量$\vec{v}_j$都不能和$\vec{u}$产生正交关系。由于$\vec{u}$和$\vec{v}_1,\vec{v}_2,\ldots,\vec{v}_{k-1}$都已经不可能互相正交，所以$\vec{u}\cdot\vec{v}_j=0$。

另外，设有一个矩阵A，它的每一行都是一个向量，那么对于任意向量$\vec{u}$，都有：
$$A\vec{u}=[a_1,a_2,\ldots,a_m]=[a_{\pi_1},a_{\pi_2},\ldots,a_{\pi_r}]\cdot[e_{\pi_1},e_{\pi_2},\ldots,e_{\pi_r}]=a_{\pi_1}e_{\pi_1}+a_{\pi_2}e_{\pi_2}+\ldots+a_{\pi_r}e_{\pi_r}$$
其中$[e_{\pi_1},e_{\pi_2},\ldots,e_{\pi_r}]$是以$\pi_1,\pi_2,\ldots,\pi_r$为循环节序号的基底。则对于任意向量$\vec{v}$，有：
$$A^{-1}A\vec{v}=I_n\vec{v}=AA^    op\vec{v}$$
其中$A^    op$表示矩阵$A$的转置。

同样的，对于三个或更多维度上的向量空间，如果存在一个单位化的向量u，使得u的数量积等于零，就说该向量和它所在的坐标系平面垂直。而且，从上面的定义可以知道，这一条件成立的充要条件就是该向量是这些单位向量的线性组合，即$u=\sum_{i=1}^{n}{a_ie_i}$，其中$a_i$是任意实数。因此，在三维空间里，单位向量$e_1=(1,0,0)$，$e_2=(0,1,0)$,$e_3=(0,0,1)$ 是平行于坐标轴的，但并不正交，它们的数量积等于零。而四维空间里的单位向量$e_1=(1,0,0,0)$，$e_2=(0,1,0,0)$,$e_3=(0,0,1,0)$,$e_4=(0,0,0,1)$ 都是平行于坐标轴的，而且正交。

### 2.4 向量的叉积
向量的叉积也叫向量积，又称向量內積。设$\vec{u}=(x,y,z)$和$\vec{v}=(x',y',z')$，则$\vec{u}    imes\vec{v}=-\hat{n}(x,y,z)    imes\hat{n}(x',y',z')$，其中$\hat{n}$为单位法向量，计算方法是：
$$\hat{n}(\vec{v})=\frac{\vec{v}}{|v|}$$
得到单位法向量后，计算向量积为：
$$\vec{u}    imes\vec{v}=\left\{ \begin{array}{ccc} y&z&-y'-z'\\ -z'&x&y-x'\\ x'&-y'&z-z'\end{array}\right\}$$
其中右边第三列的结果即是向量积。特别的，如果$\vec{u}$和$\vec{v}$都是单位向量，则：
$$\vec{u}    imes\vec{v}=\vec{N}(3)$$
其中$\vec{N}(3)$代表单位复数第三次纯量。

### 2.5 向量空间
设V为一个向量空间，有很多种定义方法。这里以线性空间为例，设$f:\mathbb{R}^{n}\rightarrow\mathbb{R}$ 为线性函数，则$V$中的所有$f(\vec{x})
eq f(\vec{y})$ 的向量对有且仅有两个，即$\forall\vec{x},\vec{y}\in V,(f(\vec{x}-\vec{y}))
eq 0$，即$V$是$L^{2}(\mathbb{R}^n)$的子空间。又由引理：$\forall\vec{x},\vec{y},\vec{z}\in V,\forall t\in \mathbb{R},\forall p(1-tp)(f((t\vec{x}+(1-t)\vec{y})+(1-t)p\vec{z}))=tf(x)+(1-t)f(y)+(1-t)fp(z)$，可知$V$是Hilbert空间的子空间。此处$n$是维度，$L^{2}(\mathbb{R}^n)$和$Hilbert空间$都是向量空间。

### 2.6 基和坐标系
如果$V=\mathbb{R}^{n}$是一个向量空间，$\vec{e}_1, \vec{e}_2, \ldots, \vec{e}_n$是$V$的一组基。对于基$\vec{e}_1, \vec{e}_2, \ldots, \vec{e}_n$的每一个基向量$\vec{e}_i$，设其对应的复数形式为$\delta_{\vec{e}_i}:=\exp(\mathrm{i}     heta_i), i=1,2,\ldots, n$，那么基$\{\vec{e}_1, \vec{e}_2, \ldots, \vec{e}_n\}$在坐标系$\left(\{\delta_{\vec{e}_i}\}\right)_i$下的坐标为$\left(    heta_1,    heta_2,\ldots,    heta_n\right)$。这样，就可以通过坐标$    heta_i$来确定基向量$\vec{e}_i$的值。在坐标系$\left(\{\delta_{\vec{e}_i}\}\right)_i$下，$V$的任一向量$\vec{v}=(v_1,v_2,\ldots,v_n)$可以表示为：
$$\vec{v}=\sum_{i=1}^{n}{v_i\delta_{\vec{e}_i}}$$
称$\left(\{\delta_{\vec{e}_i}\}\right)_i$为$\vec{v}$在坐标系$\left(\{\delta_{\vec{e}_i}\}\right)_i$下的坐标系。当我们说一个向量$\vec{v}$在坐标系$\left(\{\delta_{\vec{e}_i}\}\right)_i$下具有某些坐标值时，通常指的是它的基底对应的值。如：$\vec{v}=(3,-2,7)$ 在坐标系$\left(\{\delta_{\vec{e}_1},\delta_{\vec{e}_2},\delta_{\vec{e}_3}\}\right)_i$ 下具有坐标 $(    heta_1,    heta_2,    heta_3)$，即：$\vec{v}=3\delta_{\vec{e}_1}-2\delta_{\vec{e}_2}+7\delta_{\vec{e}_3}$ 。如果$\{\vec{e}_1,\vec{e}_2,\vec{e}_3\}$属于$V$的某个基，则$\vec{v}$在基$\{\vec{e}_1,\vec{e}_2,\vec{e}_3\}$下具有相应的坐标值。

一般地，$V$的基由某个向量空间生成，设$\{v_1,v_2,\ldots,v_n\}$是$V$的一个基，则$V=\span\{v_1,v_2,\ldots,v_n\}$是一个向量空间。设$\{\vec{e}_1,\vec{e}_2,\ldots,\vec{e}_m\}$是$V$的一组基，则$\{\vec{e}_1,\vec{e}_2,\ldots,\vec{e}_m\}$也是$V$的一组基。

定理：设$V$是$F$中的向量空间，$\{\vec{e}_1,\vec{e}_2,\ldots,\vec{e}_m\}$是$V$的一组基，则存在唯一的坐标系$\left(\{\delta_{\vec{e}_i}\}\right)_i$，使得：
$$V=\span\{\langle\vec{e}_i,v\rangle\delta_{\vec{e}_i}|v\in V\}$$
$V$的向量可以在$V$的任何基下表示，也就是说：$\forall\vec{v}\in V,\forall\{\vec{e}_i\}\subseteq V,\exists! c_i\in F,\vec{v}=c_1\vec{e}_1+c_2\vec{e}_2+\ldots+c_m\vec{e}_m$。

定理：设$V$是$F$中的向量空间，$\{\vec{e}_1,\vec{e}_2,\ldots,\vec{e}_m\}$是$V$的一组基，则$\forall\vec{v}\in V,\forall\{\vec{e}_i\}\subseteq V,\exists!\mu$是$F$中的单位标量，使得：
$$\vec{v}=\mu_1\vec{e}_1+\mu_2\vec{e}_2+\ldots+\mu_m\vec{e}_m$$
$V$的任意一组基$\{\vec{e}_1,\vec{e}_2,\ldots,\vec{e}_m\}$都是$V$的一组基，且$\mu$是一个单位标量。

定理：设$V$是$F$中的向量空间，$\{\vec{e}_1,\vec{e}_2,\ldots,\vec{e}_m\}$是$V$的一组基，则$\forall\vec{v}\in V,\forall\{\vec{e}_i\}\subseteq V,\forall\lambda_i\in F,\exists! c_i\in F,\vec{v}=c_1\vec{e}_1+\cdots+c_m\vec{e}_m$。

证明过程：首先，假设$W\subseteq V$，且$W=\span\{\vec{w}_i\}$,其中$\vec{w}_1,\vec{w}_2,\ldots,\vec{w}_n$构成$W$的基。那么，有：
$$\forall\vec{v}\in W,\forall\lambda_i\in F,\exists! c_i\in F,\vec{v}=c_1\vec{w}_1+\cdots+c_n\vec{w}_n$$
于是：
$$\forall\vec{v}\in W,\forall\lambda_i\in F,\exists! c_i\in F,\vec{v}=c_1\vec{w}_1+\cdots+c_n\vec{w}_n=\lambda_1\vec{w}_1+\lambda_2\vec{w}_2+\cdots+\lambda_n\vec{w}_n$$
那么：
$$\lambda_1\vec{w}_1+\lambda_2\vec{w}_2+\cdots+\lambda_n\vec{w}_n=\lambda_1\langle\vec{w}_1,\vec{v}\rangle\vec{w}_1+\lambda_2\langle\vec{w}_2,\vec{v}\rangle\vec{w}_2+\cdots+\lambda_n\langle\vec{w}_n,\vec{v}\rangle\vec{w}_n$$
$    herefore$ 有：
$$\lambda_1=\frac{\langle\vec{w}_1,\vec{v}\rangle}{\langle\vec{w}_1,\vec{w}_1\rangle},\quad \lambda_2=\frac{\langle\vec{w}_2,\vec{v}\rangle}{\langle\vec{w}_2,\vec{w}_2\rangle},\quad \cdots,\quad \lambda_n=\frac{\langle\vec{w}_n,\vec{v}\rangle}{\langle\vec{w}_n,\vec{w}_n\rangle}$$
于是：
$$\vec{v}=c_1\vec{w}_1+\cdots+c_n\vec{w}_n=\frac{\langle\vec{w}_1,\vec{v}\rangle}{\langle\vec{w}_1,\vec{w}_1\rangle}\vec{w}_1+\frac{\langle\vec{w}_2,\vec{v}\rangle}{\langle\vec{w}_2,\vec{w}_2\rangle}\vec{w}_2+\cdots+\frac{\langle\vec{w}_n,\vec{v}\rangle}{\langle\vec{w}_n,\vec{w}_n\rangle}\vec{w}_n$$
$    herefore$ 命题得证。

