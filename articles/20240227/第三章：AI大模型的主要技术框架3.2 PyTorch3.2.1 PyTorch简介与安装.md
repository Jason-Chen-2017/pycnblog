                 

## 3.2 PyTorch-3.2.1 PyTorchç®€ä»‹ä¸å®‰è£…

PyTorch æ˜¯ä¸€ä¸ªåŸºäº Torch åº“çš„å¼€æº machine learning æ¡†æ¶ï¼Œç”± Facebook çš„ AI Research lab ï¼ˆFAIRï¼‰ å›¢é˜Ÿå¼€å‘ï¼Œå·²ç»è¢«å¹¿æ³›åº”ç”¨äºæ·±åº¦å­¦ä¹ é¢†åŸŸã€‚PyTorch ç›¸æ¯” TensorFlow ç­‰å…¶ä»–æ¡†æ¶çš„ä¼˜ç‚¹ä¹‹ä¸€æ˜¯å®ƒå…è®¸ researchers and developers to build and train neural networks in a dynamic computational graph that is more flexible and easier to debug than TensorFlow's static computational graph.

### 3.2.1 PyTorch ç®€ä»‹

PyTorch æä¾›äº†ä¸¤ä¸ªä¸»è¦çš„ APIï¼š

- **Torch**: è¿™ä¸ª API æä¾› low-level çš„ tensor computation with strong GPU acceleration, which allows you to build complex multi-GPU models. It can be used for linear algebra operations, image processing, deep learning, etc.
- **TorchNet**: This is a high-level library built on top of Torch that provides pre-built modules and layers for building neural networks. It also includes common training utilities like data loaders, loss functions, and optimizers.

PyTorch çš„ä¸»è¦ç‰¹ç‚¹åŒ…æ‹¬ï¼š

- **Dynamic Computational Graph**: Unlike TensorFlow, PyTorch uses a dynamic computational graph. This means that the graph is constructed on the fly as your code runs, allowing for greater flexibility and ease of debugging.
- **Strong GPU Acceleration**: PyTorch has strong support for GPU acceleration, which makes it well suited for large-scale deep learning tasks.
- **Simplicity and Ease of Use**: PyTorch's syntax is simple and easy to understand, making it a great choice for beginners who are just starting out with deep learning.
- **Extensibility**: PyTorch is highly extensible, allowing you to define your own custom layers and modules.

### 3.2.2 PyTorch å®‰è£…

åœ¨å®‰è£… PyTorch ä¹‹å‰ï¼Œé¦–å…ˆéœ€è¦ç¡®ä¿å®‰è£…äº† CUDA Toolkit å’Œ cuDNNã€‚CUDA Toolkit æ˜¯ NVIDIA æä¾›çš„ GPU ç¼–ç¨‹å·¥å…·é›†ï¼Œè€Œ cuDNN æ˜¯ç”¨äºæ·±åº¦å­¦ä¹ çš„ GPU åŠ é€Ÿåº“ã€‚æ ¹æ®æ‚¨çš„ GPU ç±»å‹å’Œ CUDA ç‰ˆæœ¬é€‰æ‹©ç›¸åº”çš„ CUDA Toolkit å’Œ cuDNN ç‰ˆæœ¬ã€‚

åœ¨å®‰è£… CUDA Toolkit å’Œ cuDNN åï¼Œå¯ä»¥é€šè¿‡ pip å‘½ä»¤å®‰è£… PyTorchï¼š
```bash
pip install torch torchvision -f https://download.pytorch.org/whl/cu100/torch_stable.html
```
æ³¨æ„ï¼Œåœ¨ä¸Šè¿°å‘½ä»¤ä¸­ï¼Œ`-f` æ ‡å¿—æŒ‡å®šäº†é¢å¤–çš„åŒ…ç´¢å¼• URLï¼Œç”¨äºæ”¯æŒåŸºäº CUDA 9.2ã€10.0ã€10.1 å’Œ 10.2 çš„ PyTorch ç‰ˆæœ¬ã€‚è¯·æ ¹æ®æ‚¨çš„ç³»ç»Ÿé…ç½®é€‰æ‹©ç›¸åº”çš„ URLã€‚

å¦å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ Anaconda ç¯å¢ƒå®‰è£… PyTorchï¼š
```python
conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch
```
åœ¨ä¸Šè¿°å‘½ä»¤ä¸­ï¼Œ`cudatoolkit=10.2` è¡¨ç¤ºå®‰è£…æ”¯æŒ CUDA 10.2 çš„ PyTorch ç‰ˆæœ¬ï¼Œè¯·æ ¹æ®æ‚¨çš„ç³»ç»Ÿé…ç½®é€‰æ‹©ç›¸åº”çš„ç‰ˆæœ¬å·ã€‚

### 3.2.3 PyTorch å…¥é—¨å®ä¾‹

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ PyTorch å®ç°ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’ä»»åŠ¡ã€‚é¦–å…ˆï¼Œå¯¼å…¥ PyTorch åº“ï¼š
```python
import torch
import torch.nn as nn
import torch.optim as optim
```
æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹ï¼š
```python
class LinearRegressionModel(nn.Module):
   def __init__(self, input_dim, output_dim):
       super(LinearRegressionModel, self).__init__()
       self.linear = nn.Linear(input_dim, output_dim) 
   
   def forward(self, x):
       out = self.linear(x)
       return out
```
æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªè®­ç»ƒå‡½æ•°ï¼š
```python
def train(model, criterion, optimizer, x, y):
   model.zero_grad()
   y_pred = model(x)
   loss = criterion(y_pred, y)
   loss.backward()
   optimizer.step()
   return loss.item()
```
æ¥ä¸‹æ¥ï¼Œåˆ›å»ºä¸€ä¸ªæ•°æ®åŠ è½½å‡½æ•°ï¼š
```python
def load_data():
   x = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)
   y = torch.tensor([2, 4, 6, 8], dtype=torch.float32)
   return x, y
```
æœ€åï¼Œåˆ›å»ºä¸€ä¸ªæµ‹è¯•å‡½æ•°ï¼š
```python
def test(model, x, y):
   y_pred = model(x)
   correct = (y_pred.round() == y).sum().item()
   accuracy = correct / len(y) * 100
   print(f"Accuracy: {accuracy}%")
```
ç°åœ¨ï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼š
```python
# Load data
x, y = load_data()

# Initialize model, criterion, and optimizer
model = LinearRegressionModel(1, 1)
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Train model
for epoch in range(100):
   loss = train(model, criterion, optimizer, x, y)

# Test model
test(model, x, y)
```
è¿™ä¸ªç®€å•çš„ä¾‹å­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ PyTorch åˆ›å»ºä¸€ä¸ªçº¿æ€§æ¨¡å‹ï¼Œå¹¶åœ¨è®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹ä¸­ä½¿ç”¨ loss function å’Œ optimizerã€‚

## å°ç»“

åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬ç®€è¦ä»‹ç»äº† PyTorch æ¡†æ¶åŠå…¶ä¼˜ç‚¹ï¼Œå¹¶æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ PyTorch è¿›è¡ŒåŠ¨æ€è®¡ç®—å›¾çš„æ„å»ºå’Œ GPU åŠ é€Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªç®€å•çš„ PyTorch å…¥é—¨å®ä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ PyTorch åˆ›å»ºå’Œè®­ç»ƒä¸€ä¸ªç®€å•çš„çº¿æ€§æ¨¡å‹ã€‚åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶ PyTorch çš„æ ¸å¿ƒæ¦‚å¿µå’Œç®—æ³•åŸç†ï¼Œå¹¶è¯¦ç»†è®²è§£ PyTorch ä¸­çš„ç¥ç»ç½‘ç»œæ¶æ„ã€‚

---

å¦‚æœä½ è§‰å¾—æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ç‚¹ä¸€æ³¢æ˜Ÿ likingï¼Œæ„Ÿæ¿€ä¸å°½ï¼ğŸ’«

æ¬¢è¿å…³æ³¨æˆ‘çš„å¾®ä¿¡å…¬ä¼—å·ã€Œç¦…ä¸è®¡ç®—æœºç¨‹åºè®¾è®¡è‰ºæœ¯ã€ï¼Œè·å–æ›´å¤šç²¾å½©å†…å®¹ï¼
