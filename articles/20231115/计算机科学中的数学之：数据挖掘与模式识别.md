                 

# 1.背景介绍


## 数据挖掘与模式识别简介
数据挖掘(Data Mining)是利用大量的原始数据集从中提取有价值的信息并应用到生产环境、决策分析或其他更广泛的领域。数据挖掘技术通常分为三种类型：结构挖掘、关联规则挖掘、分类算法。结构挖掘算法将数据视作网络图、树形结构或其他形式的图形，通过对图形的分析找出其结构特征，如节点的连接关系及重要性，从而发现数据的内在规律。关联规则挖掘算法根据用户购买行为和其它相关信息，找到相互关联的物品集合。分类算法则通过归纳、演绎或特定的统计方法对数据进行自动分组，将具有共同特性的数据划分到同一类。不同的数据挖掘任务往往都需要不同的算法及技巧。数据挖掘可以分为以下几个层次：
- 有监督学习（Supervised Learning）：已知数据之间的依赖关系，要求模型预测新数据对应的输出结果；
- 无监督学习（Unsupervised Learning）：不知道数据之间的依赖关系，仅依据数据内部的结构和模式进行聚类或分类；
- 半监督学习（Semi-supervised Learning）：部分数据已有标签，部分没有；
-  reinforcement learning：通过反馈机制进行迭代训练，使机器根据历史数据对当前状态做出动作的推荐。
结构挖掘算法：社交网络分析、网络推荐算法、PageRank算法、随机游走算法等。
关联规则挖掘算法：Apriori算法、FP-growth算法、Eclat算法等。
分类算法：K近邻法、朴素贝叶斯法、隐马尔可夫模型、决策树、支持向量机等。
本文将讨论两种典型的数据挖掘问题：聚类与分类。两者都是机器学习领域的基础课题。先对两个问题进行介绍。
## 聚类与分类
### 聚类
聚类是将相同类别的样本点集按一定规则归类为一类，因此，它是一种无监督的学习方法。假设有n个训练样本{x1, x2,..., xn}，其中每个样本xi∈X为一个高维的向量。聚类问题就是寻找合适的聚类方案，使得簇内的距离尽可能小，但各簇之间应当尽可能的大。常用的聚类算法包括K-Means、DBSCAN、EM算法、谱聚类、混合高斯模型聚类等。下面给出K-Means聚类的基本思想。
1. K-Means算法：K-Means是一个基本且简单易懂的聚类算法。该算法每次迭代时，都会重新计算n个中心点，并将所有样本分配到最近的中心点所属的簇。具体地，初始化n个随机质心作为初始聚类中心，然后重复下列过程直至收敛：
   - 1. 分配样本到最近的中心点所属的簇。
   - 2. 更新聚类中心。
   - 3. 对所有样本重新分配到新的簇。
   - 4. 判断是否收敛，若不收敛，则回到第2步继续迭代。
   - 5. 最后，得到经过K-Means聚类后的结果。
   - K-Means算法优点：
       - （1）简单易懂。
       - （2）计算量小。
       - （3）容易理解。
   - K-Means算法缺点：
       - （1）容易陷入局部最优。
       - （2）初始选择的初始质心对结果影响较大。
       - （3）K值比较困难确定。
2. DBSCAN算法：DBSCAN(Density-Based Spatial Clustering of Applications with Noise)是一种基于密度的空间聚类算法。该算法将样本点按照密度来进行划分。首先，算法会从任一点开始扫描，发现所有的邻域点并标记为core点。然后，从core点开始扩张，直到密度满足某一阈值，或者达到最大扫描次数限制。标记为边界点，并将非核心点标记为噪声点。最终，得到一个由噪声点、边界点、核心点构成的样本点集合。一般来说，DBSCAN算法的鲁棒性比较好，能够很好的处理不同形状的分布、尺度、噪声等方面。除此之外，DBSCAN还提供了详细的输出，包括每个簇的样本点、簇中心位置、簇半径等。但是，DBSCAN算法不能给出确切的结果数目，只能估计出一个相对准确的数目。
   - DBSCAN算法优点：
       - （1）简单。
       - （2）不受初始质心影响。
       - （3）自动确定簇数量。
       - （4）具有鲁棒性。
   - DBSCAN算法缺点：
       - （1）易受噪音点的影响。
       - （2）计算量大。
       - （3）不适用于含有孤立点的复杂分布。