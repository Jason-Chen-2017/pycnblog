
作者：禅与计算机程序设计艺术                    

# 1.简介
         

支持向量机（Support Vector Machine，SVM）是一种常用的机器学习分类模型，由李航博士提出。它是一个优化的二类分类器，属于监督学习、回归分析、核方法三者的集大成者。SVM能够处理高维数据、异常值、不平衡的数据集等问题。目前国内外很多公司都在用SVM进行业务预测、垃圾邮件过滤、图像识别、文本分类等领域的应用。而本文就是要介绍SVM，希望能够给读者提供一个通俗易懂的了解。
首先，让我们来看一下SVM的一些重要特征。

① SVM是一种分类模型。

② SVM支持线性、非线性分类、多类别分类。

③ SVM解决了空间中的线性不可分割的问题。

④ SVM可以有效地处理高维数据。

⑤ SVM对于异常值的鲁棒性较好。

⑥ SVM可以实现核函数的映射。

⑦ SVM还可以实现分类回归。

以上就是SVM的一些重要特征。接下来，我会带领大家一起进入SVM的世界，从线性可分样本开始，逐步探索非线性不可分样本。# 2.线性可分样本
假设有一个训练集T={(x1,y1),(x2,y2),...,(xn,yn)}，其中xi∈Rd表示样本点的输入向量，yi∈R+表示样本点的输出标签（类别）。由于样本点是线性可分的，即存在着一个超平面将两类点完全隔开，所以这个问题就可以被直接解决。但是现实中往往存在许多复杂的情况，如同云雾一样，样本点不容易呈现明显的类别间界限。如下图所示，在线性可分样本情况下，SVM通过求解优化问题寻找最佳的分离超平面。
# 3.非线性可分样本
一般来说，如果存在着某些样本点不能很好地划分到不同的类别上，那么就称该样本点是非线性可分的。但其实在实际应用中，这种样本点却难以得到很好的处理，因为它们之间往往存在复杂的结构。如下图所示，在非线性可分样本情况下，SVM需要借助核技巧才能求得最优分离超平面。
为了能够处理非线性可分样本，SVM引入了核函数。核函数是在低维空间进行线性分类的手段。当原始数据空间中的数据无法用直线进行分类时，可以使用核函数进行转换后，使其可以在任意的低维空间进行线性划分。SVM的目标就是找到合适的核函数，使得支持向量尽可能远离其他样本点。一般来说，核函数可以分为三种：
1.线性核函数：k(x,z)=x^Tz
2.多项式核函数：k(x,z)=(gamma*x)^r*(gamma*z)^r
3.径向基函数（radial basis function）：k(x,z)=exp(-gamma||x-z||^2)
其中γ为参数，r为指数。常用的是径向基函数核函数。