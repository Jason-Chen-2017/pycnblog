
作者：禅与计算机程序设计艺术                    

# 1.简介
         

2020年是人工智能的元年。随着技术的不断进步，智能助手正在取代我们日常生活中的大量重复工作。比如帮助我们完成信息搜集、信息整理、知识学习等任务，或者实现一些自动化的办公流程。与此同时，对人工智能系统进行安全防护也越来越成为重中之重。

为了保障人工智能系统的运行安全、数据安全以及隐私权的尊重，国家也在积极探索相应的行政法规。其中最重要的就是公安部门的人工智能监管制度。

如何合理规范人工智能系统的运作，并且严格遵守公安机关对于AI相关人员的管理要求，一直是研究人员和政策制定者们所追求的目标。而基于目前公安部对于人工智能监管的研究成果及政策制定，我们可以预见，在2021年会出现很多挑战。

本文将从公安部对于AI相关人员管理与社会责任的方面进行论述。首先，我们将讨论AI系统由“功能”向“产品”转变的背景。这一转变带来了哪些新的管理需求？公安部在这个过程中又如何应对？

然后，我们将探讨人工智能模型相关管理问题，包括AI模型的存储、开发、部署、应用、监控、评估、认证等方面。我们将详细阐述公安部对于AI模型的管理要求，并分析不同监管层级下对于AI模型的权限划分。

最后，我们将讨论智能客服机器人的日益崛起以及其引发的管理挑战。公安部如何进行应对以及提升人力资源效率呢？如何通过有效的法律途径解决智能客服机器人滥用问题？

# 2.背景介绍
## AI系统由功能向产品转变的背景
截止到目前，公安部对于人工智能的监管主要围绕着五个方面：基础设施、算法、模型、工具以及应用。但随着公安部对于人工智能的高度关注，这些方面的监管也会越来越复杂。

在过去几年里，随着人工智能领域的不断发展，涌现出了许多颇具创新性的AI产品。如自动驾驶汽车、虚拟现实眼镜、图像识别技术等等。这些产品形成了一个完整的生态系统，甚至某种程度上已经超越了传统监管的范畴。公安部对于人工智能的监管也会与时俱进，跟上这个趋势。

2019年9月，公安部发表了一份报告，提出了“全面深化人工智能治理，构建生态共同体”。报告认为，“要从源头上抓好人工智能治理，确立公安部在人工智能领域的地位，坚持党对人工智能领域的领导，围绕共同利益和共同责任，推动科技创新、战略引领、平台协同、政府引导、国际合作，加强技术支撑、人才培养、法治建设、评价指标体系建设……”。

“全面深化人工智能治理，构建生态共同体”，这份五年计划着重于制订行政法规和立法法规。其中最重要的一项，就是建立健全人工智能监管框架。

近年来，随着公安部的人工智能监管框架的逐步完善，主要有以下几个方面的改革：

1. AI模型的存储、开发、部署、应用、监控、评估、认证等方面，公安部将统一要求按照AI监管职能分工制定监管要求。即各类人工智能模型都需要经过模型专家审核，得到AI业务管理部门的批准才能上线使用；

2. 将AI的训练、测试、服务过程纳入AI监管范围，明确要求对AI系统性能进行评估，发现和预防风险，为系统运行提供依据；

3. 推进AI能力成熟度模型的建设，建立评价标准体系。公安部将设立AI能力成熟度管理中心（ACMIC），对公安机关和公民个人发布的关于AI系统能力的评价，做出真正客观的评估并反馈给ACMIC，以便确定AI系统的适用性和潜在风险；

4. 引入AI人才培训制度，构建AI工程师队伍。公安部将鼓励公安机关不断扩大人工智能工程师队伍建设。同时，公安部还将推动建立AI招聘网络，通过对优质AI公司的选聘、培训、升迁、晋升等，增强AI人才培养机制，提供更好的就业环境；

5. 加强跨部门合作。公安部将积极推动与相关部门合作，包括法律、医疗卫生、国土、环保、能源、金融、教育、检察院等机构，共同探索AI监管合作的路径和方式。

## AI系统的主要角色
基于公安部人工智能监管的最新研究成果，我们知道AI监管的核心是三个角色——模型的开发者、模型的使用者和AI产品的服务提供商。

模型开发者：模型开发者是指能够开发并训练用于AI模型的算法，包括人工设计和自动训练。这些模型将用来辅助公安部门的各种工作，例如信息收集、分类、搜索、威胁情报分析、法律判决等等。因此，模型开发者的AI模型往往包含高度敏感的数据，需要加强数据保护措施。

模型使用者：模型使用者是指能够使用AI模型进行各种工作的公安部门工作人员。例如，根据犯罪嫌疑人的行为习惯，可以为他们提供精准的警务辅助；根据反恐、反贪等攻击的目标，可以对受害者进行威胁情报分析；通过人脸识别技术，可以识别路人并进行辅警监控；通过火灾检测技术，可以检测异常火灾隐患。模型使用者使用的AI模型往往来自外部组织或合作伙伴，这些模型可能存在侵犯公民个人隐私、违背公序良俗和道德规范的问题，需要合理的监管。

AI产品的服务提供商：AI产品的服务提供商是指能够为公安部门提供AI服务的企业。例如，公安部门可能会购买车牌识别、图像审核、智能驾驶、自然语言理解等AI服务，这些服务将基于公安部门内部或外部的AI模型进行处理，对公安部门的工作流程进行辅助，提升效率和效果。AI产品的服务提供商的AI产品可能包括商业模式、技术架构和安全保障等方面。

因此，公安部对于AI系统的监管，主要是围绕模型开发者、模型使用者、AI产品的服务提供商这三大角色进行。

# 3.核心概念术语说明
## 什么是AI？
人工智能（Artificial Intelligence，AI）是一种赋予计算机智能的能力，它模仿人类的非物理能力（如学习、推理、创造）。20世纪70年代，美国人工智能研究所布什尔·皮特等人提出了“人工智能”的概念，1956年，英国的卡内基梅隆大学教授艾伦.图灵发明了“图灵机”算法，使得电脑具有与人一样的智能。

2010年以来，随着人工智能技术的迅速发展，基于机器学习算法的深度学习、强化学习、集成学习等技术都逐渐成为人工智能的主流技术方向。这些技术的应用可以进行智能决策、图像识别、自然语言处理、智能翻译、虚拟人、音频识别、推荐系统等。

## 为什么要制定AI监管框架？

制定AI监管框架的目的是为了落实公安部的对于人工智能监管的决心、任务和责任，弘扬人工智能和法治精神，推动公安机关构建公开透明、科学合理、依法行政的公共秩序。

目前，公安部针对人工智能系统的监管力度已经很大，但仍存在一定的欠缺。多方面原因导致了当前AI监管框架存在诸多短板：

1. AI监管的专业水平低：目前人工智能监管所采用的方法、工具、方法论等专业技术较低。不少部门甚至没有专门的人员进行专业培训，导致监管的专业水平低，监管工作无法达到行业先进水平。

2. 监管措施普遍薄弱：虽然有一些地方已经出台了一些政策，但是这些政策的执行力度不够，仍存在很大的薄弱。例如，对于隐私数据的保护不到位、对模型训练数据集的管理不力，致使模型性能无法达到要求，导致监管工作无法取得有效的效果。

3. 监管措施的制定未考虑到“边界”问题：对于模型使用者、服务提供商等不同的角色，监管方针、措施既不能太宽泛，又不能太苛刻，需要考虑到各自角色之间的不同要求和限制。

4. 监管措施与经济利益不相匹配：虽然目前AI监管的内容非常广泛，但每一个细节却都需要付出相当的政治代价。例如，对于某个模型在特定领域的应用非常成功，需要单独加以授权，但如果在其他领域效果差，则不予保护。这样的监管制度既不公平，也不切合实际。

因此，制定AI监管框架有以下几个目的：

1. 提高公安机关的专业水平，确保AI监管的科学性、准确性和及时性。

2. 优化AI监管制度，使其能够满足不同部门、角色、领域、场景下的监管需求。

3. 治理、规范AI产业的发展，推动公安机关充分发挥自身的监管作用。

## AI模型的定义及其管理分级
我们通常说的AI模型是一个黑箱子，但事实上AI模型只是大脑的一个小部分。在深度学习的背景下，模型不仅包括神经网络结构，而且还包括算法逻辑、训练样本、训练策略、超参数等众多组件。因此，AI模型本质上还是一段程序代码，只是大脑的程序而已。

公安部的AI监管框架主要采用两种模型，一种是结构化模型，另一种是非结构化模型。

### 结构化模型
结构化模型是指有一定结构和逻辑的机器学习模型，例如决策树模型、随机森林模型、支持向量机模型等。它们的输入和输出都是特征变量、标签变量，模型的训练数据也是由特征和标签组成的。结构化模型的特点是预测精度高、训练速度快、易于理解、可解释性强。

公安部对于结构化模型的管理分级如下：

1. 核心模型：所谓核心模型，是指该模型对于公安机关的重要性和处理能力要求极高。

2. 关键模型：关键模型是指该模型对公安机关的安全性、处理效率、准确性、鲁棒性等各方面都有重要影响。

3. 有限分枝模型：有限分枝模型是指该模型对公安机关的处理能力要求相对较低，但是在一定条件下它的预测准确度可以超过核心模型。

4. 模型备份：模型备份一般用于应急处置，模型发生故障时可快速替换。

### 非结构化模型
非结构化模型指那些不能被严格分类的机器学习模型，例如聚类模型、GAN模型、GAN-based生成模型、深度熵模型等。这些模型的输入和输出不是具体的值，而是概率分布、密度函数或概率密度函数。

公安部对于非结构化模型的管理分级如下：

1. 生成模型：生成模型可以用于预测、分类、聚类、生成新的数据样本等。

2. 深度熵模型：深度熵模型主要用于对模型的训练过程进行评估和分析，找出其是否存在安全风险。

3. GAN-based生成模型：GAN-based生成模型在模型训练过程中生成伪造数据，通过对生成结果的分析发现其生成质量。

4. 混合模型：混合模型综合了结构化模型和非结构化模型的优点，对公安机关的处理能力有更高的要求。