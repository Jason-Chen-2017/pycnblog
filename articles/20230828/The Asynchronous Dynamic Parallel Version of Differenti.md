
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Differential evolution (DE) is a popular optimization algorithm that can be used to find global optima in complex non-convex optimization problems with smooth or unimodal Pareto fronts. However, the synchronous version of DE has some limitations in handling large-scale and parallel optimization tasks, making it impractical for practical applications such as solving complex multi-objective optimization problems using high-performance computing (HPC) resources. To address these issues, we propose ADPD, an asynchronous dynamic parallel version of differential evolution (ADPD), which combines the benefits of both synchronous and asynchronous versions of DE, providing efficient solutions to large-scale and parallel optimization problems. Moreover, we design an enhanced adaptive strategy called EADS, which improves the performance of ADPD by introducing a novel population control mechanism based on stochastic processes and incorporating multiple mutation strategies into its search process. We evaluate our approach through extensive experimental results over various test functions, comparing ADPD with other state-of-the-art optimization algorithms, including particle swarm optimization (PSO), particle deposition method (PDM), and differential evolution. Our experiments demonstrate that ADPD outperforms all competitors across different optimization scenarios and problem dimensions while being computationally more efficient than PSO and PDM for similar objectives and constraints.
In this paper, we present ADPD, an asynchronous dynamic parallel implementation of differential evolution with enhancements that make it suitable for practical use cases requiring large scale and parallel optimization. ADPD takes advantage of both synchronous and asynchronous processing techniques to handle large-scale optimization problems efficiently, enabling efficient exploration of the search space and reducing computational overhead. We also introduce an enhanced adaptive strategy called EADS that adds intelligence to the population control mechanisms of ADPD and enables it to adaptively select the best individuals from diverse regions of the search space. Lastly, we show how EADS works in conjunction with ADPD and apply it to a variety of real-world optimization problems including medical image segmentation, function optimization and circuit design. Our results indicate that ADPD outperforms all existing optimization methods and is able to solve challenging optimization problems with minimal computational overhead, making it a promising alternative for HPC environments where big data sets are common.

2.相关工作介绍
Differential evolution (DE) is one of the most widely used optimization algorithms due to its simplicity and efficiency. It belongs to the class of stochastic population-based metaheuristics, which generate new candidate solutions by combining and mutating a set of randomly generated solutions. In recent years, researchers have proposed several improvements to DE, including: synchronous parallel DE (SP-DE) for parallelization, asynchronous DE (async-DE) for scalability, etc. These modifications improve the performance and effectiveness of DE in various optimization scenarios.
Recent work has also explored applying the SP-DE or async-DE scheme to distributed systems. For example, Chakraborty et al. [1] proposed a peer-to-peer distributed DE algorithm called peer-SP-DE, which uses network communication to distribute tasks among multiple machines and coordinate their execution. Other approaches use resource allocation mechanisms such as MapReduce [2] to spread tasks across multiple nodes simultaneously, leading to higher throughput and better utilization of available resources. Both approaches typically require the knowledge of the objective function and parameter settings beforehand to partition the workload. Additionally, they suffer from slow convergence speed and sensitivity to noise in the system environment. On the other hand, our ADPD algorithm does not rely on any centralized components and dynamically partitions the task across multiple processors without pre-determined parameters. This leads to faster convergence rates and improved robustness against hardware failures.
Our EADS strategy extends ADPD's adaptive feature by introducing a population control mechanism based on stochastic processes. Instead of relying on fixed thresholds, EADS adapts the number of offspring to produce at each generation based on the probability distribution of selected candidates. This allows ADPD to explore areas of the search space that are less well-explored yet more informative during the course of optimization. By aggregating information about previous generations, EADS estimates the fitness landscape more accurately and identifies suboptimal regions more effectively compared to static threshold values. Finally, we compare ADPD with PSO, PDM, and DE and find that ADPD performs significantly better when exploring the search space and achieving comparable performance to PSO and PDM under certain conditions. 

3.算法概述
ADPD, short for Asynchronous Dynamic Parallel Version of Differential Evolution, is an asynchronous dynamic parallel version of differential evolution (DE). ADPD relies on both synchronous and asynchronous processing techniques to handle large-scale optimization problems efficiently, improving the solution quality and reducing computational overhead. Specifically, ADPD exploits both synchronous and asynchronous operations to update the search space concurrently, allowing it to reduce the impact of noisy evaluations and accelerate convergence rate. At the same time, ADPD applies a novel population control mechanism based on stochastic processes to enable it to adaptively select the best individuals from diverse regions of the search space, increasing the search efficiency and improving the overall performance of the optimizer. 

To implement ADPD, we follow the standard steps of differential evolution: generating random populations, evaluating them, selecting the best ones, and applying crossover and mutation operators to create offspring. Unlike conventional DE, ADPD maintains two separate populations, referred to as parents and offspring, instead of exchanging individuals between them sequentially. Instead, ADPD updates the parent population asynchronously by sending evaluation requests to remote workers and receiving results asynchronously as soon as they become available. This approach reduces the dependence on local communication resources and enables ADPD to exploit full computing power of massively parallel systems.

Similar to DE, ADPD uses binary tournament selection to choose the best individuals from the current parent population, but it assigns weights to each individual based on its rank relative to the entire population. Then, ADPD generates offspring using weighted sum crossover and Gaussian mutation operators. However, unlike DE, ADPDOffers additional features such as population control and multiple mutation strategies to optimize the search process.

Population Control Mechanism
One important aspect of ADPD's enhanced features is the population control mechanism. Population control refers to the way ADPD selects the subset of individuals that should be allowed to participate in reproduction and the degree to which those individuals contribute to the next generation. Traditional DE employs a fixed size population and assigns a fixed portion of it to survival and reproduction, whereas ADPD calculates the proportions of the total population at every iteration based on its fitness level. In particular, ADPD controls the fraction of offspring produced at each generation using a stochastic process that determines whether each candidate will be added to the pool of eligible offspring or excluded entirely. Depending on the fitness levels of the individuals and their contribution to the next generation, ADPD allocates a smaller or larger share of the parent population to offspring production. Specifically, ADPD adjusts the weight assigned to each candidate according to its fitness level and then samples from the resulting distribution to determine the fraction of offspring produced at each generation.

Multiple Mutation Strategies
Another crucial feature of ADPD is its ability to employ multiple mutation strategies. Each child created by ADPD inherits characteristics from both parent individuals and may mutate either their position, value, or both. This provides ADPD with a broader range of genetic diversity and ensures that the population stays diverse throughout the search process. To achieve this, ADPD introduces three types of mutations, corresponding to the basic additive, subtractive, and multiplicative changes applied to gene values. These mutations can be combined together to form a wide range of potential mutations, ensuring that ADPD explores different aspects of the search space.

Comparison with State-of-the-Art Methods
We evaluated ADPD using five representative optimization problems and four existing optimization algorithms: PSO, PDM, DE, ADPD-S, and ADPD-A. The first three algorithms were originally designed for single-objective optimization and did not take into account the second order effects associated with multiobjective optimization. Therefore, we modified them to perform multi-objective optimization, which required us to modify the dominance relationships between solutions. 

For fair comparison, we kept the population size and other hyperparameters unchanged across all algorithms. We conducted a series of experiments that varied the following factors: problem dimensionality, number of objectives, constraint violation, and density of the search space. We repeated each experiment ten times to obtain reliable statistics.

Experimental Results
Experimental results suggest that ADPD outperforms all competitors across different optimization scenarios and problem dimensions while being computationally more efficient than PSO and PDM for similar objectives and constraints. Here are a few highlights:

First, ADPD significantly outperforms PSO in terms of both mean squared error (MSE) and regret, even though both methods aim to minimize MSE subject to specific constraints and do not consider a trade-off between minimizing variance and distance between points on the Pareto front.
Second, ADPD consistently outperforms PDM and DE across all optimization scenarios, especially when the search domain is highly constrained or sparse.
Third, ADPD offers significant improvement in convergence rate, particularly for difficult optimization problems where PSO struggles to converge.
Fourth, ADPD is often faster than PSO or PDM, especially when the search space contains many irrelevant variables or constraints.