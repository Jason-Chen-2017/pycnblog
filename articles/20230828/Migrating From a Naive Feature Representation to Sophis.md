
作者：禅与计算机程序设计艺术                    

# 1.简介
  

随着深度学习技术的不断进步，基于神经网络（CNN）的特征提取已经成为许多计算机视觉任务的标准化处理方式。CNN可以从图像或视频中自动提取不同尺寸、纹理、光照等视觉特征并对其进行建模。然而，对于某些特定任务，比如图像分割、图像检索，这些传统的图像特征往往不能有效地提取出感兴趣的目标信息，因而需要设计新的特征表示方法。在本文中，作者探讨了一种迁移学习的策略，将深度学习模型从一种简单、粗糙的特征提取转变为高级特征，通过改善模型的鲁棒性和泛化能力来解决视觉识别领域的复杂问题。本文主要通过在两个不同的视觉识别数据集上应用该策略，证明了所提出的基于对抗攻击的迁移学习方案在迁移过程中能够较好地保留源模型的关键特性并提升模型的性能。


# 2.相关工作及启发
## 2.1 Transfer Learning
Transfer learning，即迁移学习，是机器学习的一个重要研究方向。它利用已训练好的模型参数去解决新任务的问题。典型的迁移学习包括基于特征相似度的迁移、基于结构的迁移、基于标签的迁移等。深度学习在这个领域的主要代表是基于特征的迁移，也称作feature transfer。

如图1所示，传统的图像分类方法通常由特征学习器（如线性SVM或最大熵模型）、分类器、距离度量、损失函数组成。而迁移学习则允许直接从源模型学习到新的特征表示形式，从而不需要重新训练分类器和距离度量。例如，使用迁移学习可以在类似但小于原始数据大小的数据上微调预训练的深度神经网络模型，从而获得更高的准确率。如图2所示，传统的迁移学习方法包括匹配或正则化现有特征；在新任务中，直接微调全部层的参数；或者使用少量训练样本微调卷积层的权重。







## 2.2 特征迁移策略
目前，深度学习在视觉识别领域取得了很大的进步，不同于以前的基于特征的手工设计，CNN已经被广泛用于特征抽取。但是，对于某些特定的任务，比如图像分割、图像检索，传统的特征提取方式可能就无法产生高效的结果。因此，需要考虑如何利用CNN在低层次上提取的特征向量生成新的高层次的、具有意义的信息。

常用的特征迁移策略有两种，第一种是直接使用原始模型的输出作为新模型的输入；第二种是在原始模型和新模型之间添加一个中间层，使得新模型得到更多关于图像的有用信息。下面详细介绍两种特征迁移策略。
### 2.2.1 直接使用原始模型输出作为新模型输入
这种方法的特点是，只要原始模型可以较好的完成相应的任务，那么基于原始模型的输出就可直接作为新模型的输入。比如在图像分割任务中，可以直接把原始模型的输出直接当做特征输入到新的模型中。这也是迁移学习的一种最直接的应用，比如可以在目标域上微调ResNet模型，而不需要自己设计特征提取网络。然而，这种方法虽然简单易行，但是由于没有充分利用原始模型的特征信息，所以可能导致过拟合。

### 2.2.2 在原始模型和新模型之间增加一个中间层
另一种方法是，在原始模型的输出上加上一个额外的中间层，然后再把这个中间层的输出送入到新的模型中。这种方法的特点是，通过在原始模型和新模型之间引入一个适配层，可以让新模型学习到更多有关图像的有用信息。如图3(a)所示，假设有两个模型A和B，其中模型A的输出表示为$\hat{y}=A(\mathcal{I})$，$\mathcal{I}$为图像输入，而模型B的输入表示为$\theta_B\hat{y}+\phi_{\psi}(z)$，其中$\theta_B$和$\phi_{\psi}(z)$分别是模型B的权重和偏置，且$\phi_{\psi}(z)$是模型A的输出。换句话说，模型B可以学习到一种从模型A的输出到新模型输出的映射，并根据这个映射来改善模型的性能。




图3左边为直接把原始模型的输出作为新模型的输入的迁移策略，右边为在原始模型和新模型之间增加一个适配层的迁移策略。显然，在右侧的策略下，原始模型的输出更充分地激活了新的模型，因而可以更好地学习到高层次的、有用信息。

然而，如何设计适配层是一个复杂的课题。作者提出了一个叫做Adversarial adaptation的迁移学习方案，其基本思路是通过生成对抗样本来促进模型之间的特征学习互补。具体来说，首先，设置一个判别器D，它负责判断给定输入是否是合法的特征，并将其与原始模型的输出和中间层输出一起作为判别器的输入。然后，生成器G根据判别器判定的特征生成图像，并希望其与真实图像尽可能相似，同时尽量欺骗判别器。最后，基于判别器的损失训练生成器，使用真实样本和生成样本进行联合训练。

这种方法能够提升模型的泛化能力，并提供一个更容易优化的目标函数。但是，为了解决生成对抗样本的稳定性问题，作者还建议采用梯度惩罚的方法。另外，作者发现，新模型并不一定总能从源模型学习到有用的特征信息，因为它可能会面临欠拟合问题。因此，作者还提出了一种采用自监督的迁移学习方法，即仅仅将源模型的输出送入到新模型中。通过限制新模型的参数数量，可以减少模型之间的互补关系。