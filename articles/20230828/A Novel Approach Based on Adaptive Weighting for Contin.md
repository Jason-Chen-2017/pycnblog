
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Assessing the performance of a system is critical in several application domains such as healthcare, manufacturing, transportation, etc. Therefore, continuous performance feedback (CPF) based on endurance tests has been proposed to assess the performance over time. CPF relies on analyzing the results of repeated testing cycles that cover different loads or conditions. However, evaluating performance from negative and positive test outcomes can be challenging due to interference factors caused by external influences, hardware failures, software errors, etc. In this paper, we present an adaptive weighting approach to address these challenges. The key idea behind our approach is to adaptively assign weights to each successful outcome based on its frequency of occurrence while ignoring those with low frequencies. We propose an algorithm that first performs individual load tests with respect to their predefined thresholds and then assigns weights to all the outcomes based on their frequency of occurrence across multiple cycles. Finally, it combines the weighted scores using a weighted geometric mean to obtain the overall score. To evaluate the effectiveness of the proposed approach, we conducted experiments using real-world systems and datasets with different types of workload variations and input patterns. Our experimental findings show that the adaptive weighting strategy significantly outperforms state-of-the-art methods in terms of accuracy, precision, recall, F1-score, and MAE metrics, when applied to continuous performance feedback based on endurance tests.
本文提出了一个基于自适应权重的新型连续性能反馈系统。主要贡献如下：
* 提出了一种新的连续性能反馈系统——基于持续耐力测试的自适应权重方法
* 首先针对不同载荷或条件执行单个载荷测试，然后根据多次循环中每个结果出现频率对所有结果进行赋权
* 通过加权几何平均（weighted geometric mean）将加权得分合并以产生整体得分
* 在实验中证明了所提出的自适应权重策略在准确性、精度、召回率、F1-score、MAE等指标上均优于目前已有的算法
# 2.背景介绍
Continuous performance feedback (CPF), also known as real-time monitoring and evaluation, refers to the process of monitoring and evaluating the performance of a system over time without intervention. It involves continuous monitoring and analysis of various operational parameters, including system response times, throughput rates, error rates, resource utilization, user satisfaction levels, availability, and so forth, during operation. CPF provides valuable insights into the system's behavior under varying conditions and enables early detection of any deviations from desired levels. Several approaches have been proposed to implement CPF based on either single-run tests or endurance tests performed over time. 

However, assessing the performance of a system based only on negative and positive test outcomes may not provide sufficient information about how well the system performs in real life scenarios. This may result in false positives, wherein the system fails to perform optimally despite achieving high performance criteria. On the other hand, false negatives, which occur when the system does not meet certain performance criteria but still passes the test, can lead to significant waste of resources and could potentially cause long-term issues if ignored. Thus, there is a need for more accurate assessment techniques that take into account both positive and negative test outcomes, making use of prior knowledge, experience, and learning to improve the performance prediction quality over time. 

In this work, we focus on addressing two challenges: (i) handling interference factors caused by external influences, hardware failures, software errors, etc., and (ii) accurately identifying which outcomes are more likely to indicate failure rather than success. We propose an adaptive weighting approach that takes into account the frequency of occurrence of each outcome during the testing cycle while assigning appropriate weights to them. Specifically, we train a classifier model using historical data to identify the most important features affecting the outcomes and establish the mapping between feature values and probabilities of failure/success. Then, we perform multi-cycle tests on the same system using different input conditions and assign weights to the outcomes based on their frequency of occurrence across multiple cycles. Finally, we combine the weighted scores using a weighted geometric mean to obtain the overall score. We demonstrate the efficacy of our method through extensive experimentation on real-world systems and datasets with diverse workload variations and input patterns.