
作者：禅与计算机程序设计艺术                    

# 1.简介
         
　　决策树（decision tree）是一种常用的机器学习方法，它在分类、回归以及序列预测等多个领域都有广泛的应用。当数据集较大或者特征很多时，决策树可以用来做出预测，并在训练和测试时达到较好的效果。但决策树也存在局部模式与全局模式的问题，这使得决策树模型很难解释和理解。本文将探索决策树中局部模式与全局模式产生的原因及其影响因素，并提出相应的解释框架，对决策树的局部模式和全局模式进行分析。
         　　决策树模型是一个二叉树结构，不同节点表示特征值或属性值划分，而每条路径代表一个判定规则，从根结点到叶子结点构成一条从左到右的判断过程，最终判断是否属于某个类别或数值。
         　　局部模式与全局模式是在处理缺失值的场景下形成的，两者都是由于缺失值的存在导致决策树生成出现偏差。
         　　
         ## 2.基本概念术语说明

         ### （1）决策树

         　　决策树（decision tree）是一种常用的机器学习方法，它在分类、回归以及序列预测等多个领域都有广泛的应用。当数据集较大或者特征很多时，决策树可以用来做出预测，并在训练和测试时达到较好的效果。但决策Tree 模型也存在局部模式与全局模式的问题。
         - 局部模式：局部模式是指在训练集中的样本点在某一区域内拥有相似的取值，对于决策树来说，这种局部模式往往表现为离群值。在训练集中的离群值会造成决策树模型的不稳定，在预测时往往会受到这些离群值的影响而产生错误的结果。
         - 全局模式：全局模式是指样本点所处的总体分布情况，包括数据的整体范围、方差以及数据之间的相关性等。而全局模式又往往依赖于样本点的统计量分布，而非特定数据的取值。

         　　决策树中局部模式和全局模式的产生都与数据处理过程中存在的缺失值有关。若训练集中含有缺失值，则不能直接使用决策树进行建模；缺失值一般通过一些技术手段（如均值/众数插补法、最小均方差估计、最大似然估计等）来进行填充，填充后的样本集称作经补全的样本集。

         ### （2）信息增益

         　　信息增益（information gain）是用于计算属性的信息量，用于评价选择某一特征进行分割的好坏。信息增益描述了熵的减少或增加，用以度量划分数据集前后熵的变化，所以信息增益反映了数据集的纯度。信息增益准则认为，在分类任务中，信息增益大的特征具有更强的分类能力。

         　　信息增益的计算公式如下：

         $$IG(D,A)=H(D)-H(D|A)$$

         $H(D)$：数据集D的经验熵

         $H(D|A)$：数据集D在特征A下的经验条件熵

         　　其中，$D$ 表示数据集，$A$ 表示特征，$=$ 表示期望，$\vert\vert \mid$ $\mid$表示集合的运算符号，$H(\cdot)$ 表示熵函数。

         　　信息增益的特点是能够衡量互信息（mutual information）的大小，从而选取最优的特征进行分割。具体来说，信息增益大的特征往往具有更强的分类能力。


         ### （3）信息增益比

         　　信息增益比（gain ratio）是信息增益和特征的可分割程度的综合评价指标。信息增益比定义为特征的预测信息量与单个特征的信息量之比，越接近1，表明该特征对分类任务的预测力越强。信息增益比是基于信息增益的一种更加有效的指标。

         　　信息增益比的计算公式如下：

         $$\frac{IG(D, A)}{IV(A)}=\frac{H(D)-H(D|A)}{H_A(D)}$$

         IV(A)表示特征A的信息量

         H_A(D)表示数据集D关于特征A的经验条件熵

         使用信息增益比作为划分特征的标准，比起单纯的使用信息增益来选择特征划分要更加科学。信息增益比能够更好的处理包含许多特征的复杂问题。