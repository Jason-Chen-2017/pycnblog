
作者：禅与计算机程序设计艺术                    
                
                
概率论是统计学的一个分支，它研究随机事件及其发生的概率。概率论是一个基础学科，应用十分广泛。在机器学习、模式识别、信息论、统计学等领域都有着重要的地位。由于概率模型和技术的广泛应用，概率论的理论基础与实际应用息息相关。
随机过程（Random Process）是概率论的一个重要主题，它可以用于描述各种随机现象，如骨牌摆放、股市涨跌、气候变化、灾害爆发等等，是概率论的一种非常重要的工具。从本质上来说，随机过程就是具有确定性的随机变量序列。因此，随机过程也被称为指数分布族或正态分布族。
概率论与随机过程的关系类似于统计学与数理统计的关系。概率论主要研究事件出现的可能性，而随机过程则是研究随机事件发生的规律。概率论利用已知的事件发生的信息，预测未来事件的结果；而随机过程则是利用随机性及其关联的机制，预测随机事件随时间的演进。
概率论的关键词之一“独立同分布”（independent and identically distributed，简称i.i.d）。此词表示随机变量之间的关系是一致且独立的，并且每个随机变量都是符合某个概率分布的独立的。因此，如果两个随机变量X和Y相互独立，则它们的联合分布也是独立的。正态分布也是最常用的i.i.d的分布。
本文将讨论一些概率论、随机过程的基本概念及其应用。希望能够帮助读者更好地理解概率论与随机过程的联系，并对后续学习、工作、生活有所帮助。
# 2.基本概念术语说明
## 2.1 样本空间与事件
设X为一个定义在非负实数集合上的随机变量，其取值范围为[0,1]，记作$X\sim U(0,1)$。如果X的概率密度函数为f(x)，那么说$X$服从伯努利分布。由于$U(0,1)$是连续型随机变量，所以随机变量的概率只能用概率密度函数来估计。

另一方面，定义事件A={X=a}，其中a∈[0,1]，事件A表示所有取值为a的X落入该事件的概率为1/2。例如，当a=0时，事件A表示X落入A的概率为1/2。如果事件A的概率等于0或1，则称该事件为必然事件。如果$P(A)>0$，则称事件A为客观事件。

对于随机变量X，若存在子集S={(x,y)|x∈X,y∈[0,1]}满足：

1. $S$的元素为元组，第一个元素为随机变量X的随机取值，第二个元素为X的概率。
2. $(x,y)$的概率等于X=x对应的概率乘以$f_Y(y|x)$，即样本点$(x,y)$处$Y$的条件概率分布的值。其中，$f_Y(y|x)$表示$Y$的条件概率密度函数，即$P(Y=y|X=x)$。

则称S为$X$的样本空间。例如，$X\sim Bernoulli(    heta)$，其中$    heta\in [0,1]$，则$Bernoulli(    heta)$的样本空间为{((0,\frac{    heta}{2}), \frac{    heta}{2}), ((1,\frac{1-    heta}{    heta}), \frac{1-    heta}{    heta})}。

## 2.2 随机过程
随机过程是由一系列随机变量组成的序列，这些随机变量之间具备一定的相关性，而且每个随机变量都与其他随机变量有着紧密联系。通常情况下，随机过程由一个起始状态、一个过渡分布和一个终止状态组成。随机过程也可以认为是指数分布族中的随机变量序列。

随机过程往往用来描述复杂系统中随机变化的过程。例如，社会经济活动中的需求、供给、消费等随机变量就可以形成一个需求-供给曲线，通过这一曲线就可以了解社会经济活动中资源的分配以及分配效率。人口增长、物价水平的变化、产业结构的变迁等可以看做是复杂系统中随机变化的过程。

一般来说，随机过程可分为以下两种类型：

1. 确定性随机过程：指随机变量的值完全确定的随机过程。比如，抛掷一次硬币的过程，每次投掷结果都固定不变，但是每次投掷过程中，出现的期望值和方差都不一样。

2. 随机游走：一种概率无限小的随机过程。比如，根据以往的行为选择新的行为的过程。在随机游走过程中，新旧行为之间的联系是随机的，因此无法用已有的观察数据直接计算出转移概率。

## 2.3 随机变量的分布函数
假设X是一个定义在非负整数集合上的随机变量。定义分布函数$F_X(x)$如下：

$$
F_X(x)=P\{X\leq x\}= \sum_{k=0}^{\infty} P\{X=k\}\cdot \left\{\begin{array}{} {k=0} & :& x=0 \\ {k=x} & :& 0<x\leq 1 \\ {0} & :& else \end{array}\right.
$$

分布函数$F_X(x)$反映了X小于等于x的概率，即X落在区间[0,x]内的概率。分布函数的求法比较简单，只需要根据样本空间中的事件的发生频率或概率计算即可。

## 2.4 独立同分布
独立同分布（independent and identically distributed，简称i.i.d）意味着每个随机变量都是符合某个概率分布的独立的。换句话说，就是每个随机变量都服从相同的分布。通常，如果两个随机变量X和Y相互独立，则它们的联合分布也是独立的。独立同分布假设使得对联合分布进行建模变得十分容易，因为每个随机变量都是相互独立的。在很多情况下，独立同分布是很自然的，比如抛掷一次硬币和抛掷两次硬币是两个相互独立的事件。

如果两个随机变量X和Y相互独立，则它们的联合分布可以表示为：

$$
f_{XY}(x,y)=f_X(x)f_Y(y)
$$

其中$f_X(x), f_Y(y)$分别表示X和Y的概率密度函数。联合分布也可以表示为矩陣形式：

$$
\mathbf{f}_{XY}=\mathbf{f}_X\otimes \mathbf{f}_Y
$$

其中$\otimes$表示Kronecker积运算符。

## 2.5 概率分布的期望与方差
设$X$是一个随机变量，其概率分布密度函数为$f(x)$。对于任意实数$\epsilon>0$，有：

$$
E[X]=\int_{-\infty}^{\infty} xf(x)\mathrm{d}x+    ext{const},~~Var[X]=E[(X-\mu)^2]=\int_{-\infty}^{\infty}[x-\mu]^2f(x)\mathrm{d}x+\sigma^2+    ext{const}.
$$

这里，$\mu$表示$X$的均值，$\sigma^2$表示$X$的方差。

根据期望、方差的定义，分布函数$F_X(x)$有如下几条性质：

1. $\lim_{x    o -\infty}F_X(x)=0$, $\lim_{x    o +\infty}F_X(x)=1$.
2. 如果$c\geq E[X]$，则$\forall x\geq c, F_X(x)\geq e^{-cx}$.
3. 如果$c\leq E[X]$，则$\forall x\leq c, F_X(x)\leq 1-e^{-cx}$.
4. 当$c
eq E[X]$时，有$F_X(-c)=1-F_X(c)$。

第四条性质说明，关于分布函数$F_X(x)$的一切事情都可以通过改变x的符号来得到。

## 2.6 连续型随机变量的数字特征
### 2.6.1 中间断点
设$X$是一个连续型随机变量，其概率密度函数为$f(x)$。如果存在数$c$，使得$f(x)<c$ whenever $x\in [\alpha, \beta], ~\alpha < \beta$，则称$(\alpha, \beta)$是$X$的中间断点。如果存在$n$个不同的中间断点，则称$X$是连续型随机变量。

举例：

(1). $U(0,1)$有一个中间断点$(0,1/2)$，因为概率密度函数在$(0,1/2)$处的绝对值小于1/2。

(2). 一般的正态分布，比如$N(0,\sigma^2)$，其概率密度函数在任意一点的斜率都是恒定不变的。

(3). $X$是一个离散型随机变量，则不存在中间断点。

### 2.6.2 模型选择问题
给定两个连续型随机变量$X, Y$，如何选择合适的模型？一个直观的方法是考虑两个变量之间的关系。如果$X$和$Y$是强相关的，即$Cov(X,Y)
eq 0$，则$X$和$Y$可能共同驱动某种规律，这种关系被称为因果关系。如果两个变量都是弱相关的，即$Cov(X,Y)=0$，则不能排除两个变量之间没有显著的联系。通常情况下，变量之间的相关性可以由统计量来衡量。

另外，还可以考虑根据变量的特点来选择模型。例如，如果变量$X$是一个均值为$\mu$、方差为$\sigma^2$的正态分布，则可以选择一个弱相关的模型，例如高斯过程。而如果变量$X$是一个二项分布，则可以选择一个强相关的模型，例如泊松回归。

