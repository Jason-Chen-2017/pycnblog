
作者：禅与计算机程序设计艺术                    

# 1.简介
  

深度学习（Deep Learning）是近几年非常火热的研究方向，它主要解决了机器学习中的一些痛点，比如样本不足、计算资源限制、海量数据处理等难题，通过构建具有多个隐层的神经网络模型来对大规模的数据进行分析学习。

深度学习的基本想法是由许多简单神经元组成一个多层结构，通过反向传播算法对输出结果进行修正，使其逼近正确的目标值。传统机器学习方法在很长的一段时间内都是基于线性模型，无法有效地处理非线性关系和复杂模式。而深度学习则可以从更高的角度来看待机器学习问题，并寻找合适的解决方案。

深度学习技术的发展历史可以分为两个阶段，即基于规则的机器学习（Rule-based Machine Learning，RBM）和基于神经网络的深度学习（Deep Neural Network，DNN）。

## 1.1 RBM（Restricted Boltzmann Machines）
### 1.1.1 概念
受限玻尔兹曼机（Restricted Boltzmann Machine, RBM）是一种无监督的概率生成模型，由两层节点构成。第一层称作可见层（visible layer），第二层称作隐藏层（hidden layer）。任意时刻，输入单元（input unit）的取值决定于前一时刻的输出值；而输出单元（output unit）的值由上一时刻的输出值决定。每个节点之间都存在着关联权重（weight）。

### 1.1.2 发展史
RBM 最早由 Hinton 提出，Hinton 本人是 RBM 的主要创造者之一。RBM 在 86 年由科学文献发表，当时被认为是 “发明” 了具有代表性的深度学习模型。但是直到 97 年后期才得到广泛应用。

Hinton 的学生 <NAME> 在他的博士论文中提出了两种不同的方式来训练 RBM 模型，一种方式是用无监督学习的方法，另一种方式是用监督学习的方式，后来被称为反向传播算法。

此外，还有其他很多模型也试图模仿 RBM 模型，包括 Boltzmann 机、深层置信网络 (DBN) 和堆叠式自编码器（Stacked Autoencoders，SAE）。这些模型在某些方面也有所改进。

## 1.2 DNN（Deep Neural Networks）
### 1.2.1 概念
深度神经网络（Deep Neural Networks, DNN）是指具有至少一个隐藏层的神经网络。一般来说，隐藏层的数目比输入层和输出层的数目更多，而且可以包含更多的隐藏单元。

### 1.2.2 发展史
深度学习由 Hinton 等人在上世纪 90 年代提出的，当时首次出现的深度神经网络由感知机（Perceptron）引起了兴趣，但由于简单和易于实现，因此很快就被应用到了其它领域。后来，深度学习已经成为深度学习社区里研究的主要热点，主要原因有以下几个方面。

1. 大数据量
深度学习需要大量的数据用于训练。

2. 多样化任务
深度学习模型可以适应不同的任务。

3. 可解释性
深度学习模型可以在不知道输入数据的情况下进行预测。

4. 并行计算能力
目前深度学习模型的训练速度和内存占用都越来越好。

5. 更好的优化算法
深度学习的优化算法要优于传统的梯度下降法。

当前深度学习有很多种类型，包括卷积神经网络 CNN、循环神经网络 RNN、变体自动编码器 VAE、生成对抗网络 GAN 等等。