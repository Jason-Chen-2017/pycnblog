
作者：禅与计算机程序设计艺术                    

# 1.简介
  

基于图卷积神经网络(GCN)的应用已经成为图学习领域中热门的研究方向之一。GCN被广泛地用于处理节点分类、链接预测、推荐系统等任务。然而，传统的GCN只能解决静态图结构中的节点特征提取问题，难以捕捉到动态变化的信息。为了处理动态图结构，近些年来越来越多的研究工作开始关注如何将GCN扩展到非静态图上，从而在不同时间步长或不同空间尺寸下更好地提取动态信息。

2.研究背景
在传统的GCN中，每一个节点只能用到其邻居的一个局部信息，并不考虑全局信息，这就限制了GCN对动态图结构的适应性。如何将全局信息融入到每一步计算中，并有效地利用图中的动态变化是GCN研究的关键问题。目前比较流行的方法有两种：直接通过学习全局化的表示方式来捕获整体信息；或者通过自注意力机制来引入局部依赖信息，进而能够在不同空间尺寸下提取出全局信息。但是，都没有完全解决动态图的问题。

3.目标
本文希望通过分析现有的GCN模型，将它们扩展到动态图结构，并设计新的模型，以解决现有方法不能很好地解决的问题。我们的目标如下：
1）系统性地了解当前GCN模型在处理动态图上的不足。
2）对这些不足进行改进。
3）设计新的模型，并对比其效果与传统方法之间的差异。
4）给出实际应用中可能存在的挑战和未来的发展方向。

4.方法论
我们可以将GCN分成两类：无监督模型和有监督模型。无监督模型学习节点之间的相似性，并从相似性中推断出网络的结构。有监督模型同时学习节点的特征和结构，能够实现更高级的分类任务。

基于无监督模型的GCN主要包括对称型和非对称型的模型。对称型的GCN用两个相同的图卷积层对输入数据做卷积，结果送到一个MLP中进行分类；非对称型的GCN由两个不同的图卷积层组成，其中第二个层学习第一个层所学到的结构信息，然后用它来提取节点的特征，并送到MLP进行分类。

对于有监督模型的GCN，如图卷积神经网络(GCN)，首先用图卷积层学习到图中节点间的相似性，然后用MLP学习到节点标签与相似性的关系。其次，还有一些使用消息传递的模型，如图注意力网络(Graph Attention Networks, GAT)和图卷积神经网络的拓扑结构编码器(Topological Convolutional Neural Network Encoder)。

对于现有的GCN模型来说，主要的问题是局限于静态图结构。前面的方法尝试使用全局化的方式来学习整体的信息，或者使用自注意力机制来学习局部依赖信息。然而，这两种方法都没有完全解决动态图的问题。

另一方面，作者们发现，虽然GCN模型已经能够捕捉到不同时间步长下的动态变化，但仍然无法完整地理解时间序列中的全局依赖关系。因此，他们还需要开发新的模型来有效地学习到全局依赖关系。具体的想法如下：

**1.引入局部时间顺序信息**
GCN的模型假设每个节点之间都是独立生成的。但是，在现实世界中，节点通常是在时间上的相关联的，比如在一段视频中某个物体的位置发生了移动，那么这一系列动作就是在时间上相关联的。因此，我们可以通过引入时间信息来获得更多的信息。

通过引入时间信息，每一个节点除了会用到其邻居的局部信息外，还会用到之前的节点状态信息，这样就可以捕捉到之前发生过的事件。具体的方法是，在每一层的输出中加入时间信息，使得节点只看见自己的邻居和之前的时间节点，而不是所有历史上的节点。

**2.引入全局空间信息**
在现实世界中，图结构通常是由全局分布的实体构成的。比如，在社交网络中，用户之间的联系往往具有空间上的相关性，所以，可以尝试通过全局空间信息来提升模型的能力。

具体地，可以在特征提取过程中加入全局空间信息，使得不同位置的节点有机会进行交流。例如，可以先对整个图做一次全局建模，然后再把局部空间特征映射到全局空间中。这样就可以在不同空间尺寸下利用全局信息来提升模型性能。

**3.引入全局时间信息**
在实际场景中，时间信息也同样重要。比如，电子商务网站的用户行为记录非常复杂，用户的购买行为常常发生在多个时间点上。因此，可以考虑引入全局时间信息。具体地，可以构造一种新的GCN模型，这种模型可以在训练时刻学习到全局的时间信息，并引入到每一步的计算中。

此外，还可以采用时间卷积网络来捕获动态信息。时间卷积网络（T-CNNs）是对卷积神经网络的一种改进，旨在捕获时间序列内的依赖关系。T-CNNs的特点是对序列数据进行动态卷积，以捕获局部和全局的动态特征。