## 1.èƒŒæ™¯ä»‹ç»

åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå¼€æºå·¥å…·å’Œæ¡†æ¶çš„é‡è¦æ€§ä¸è¨€è€Œå–»ã€‚å®ƒä»¬ä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›äº†ä¾¿åˆ©çš„å¹³å°ï¼Œä½¿å¾—å¤æ‚çš„ç®—æ³•å’Œæ¨¡å‹èƒ½å¤Ÿæ›´å®¹æ˜“åœ°å®ç°å’Œéƒ¨ç½²ã€‚åœ¨è¿™ç¯‡æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬å°†é‡ç‚¹ä»‹ç»ä¸‰ä¸ªå¹¿å—æ¬¢è¿çš„å¼€æºå·¥å…·å’Œæ¡†æ¶ï¼šTensorFlowã€PyTorchå’ŒHuggingFaceã€‚

TensorFlowæ˜¯ç”±Google Brainå›¢é˜Ÿå¼€å‘çš„ä¸€ä¸ªå¼€æºåº“ï¼Œç”¨äºè¿›è¡Œé«˜æ€§èƒ½çš„æ•°å€¼è®¡ç®—ã€‚å®ƒçš„çµæ´»æ€§å’Œå¯æ‰©å±•æ€§ä½¿å¾—ç ”ç©¶äººå‘˜å’Œå¼€å‘è€…å¯ä»¥è½»æ¾åœ°æ„å»ºå’Œéƒ¨ç½²å„ç§å¤æ‚çš„æœºå™¨å­¦ä¹ æ¨¡å‹ã€‚

PyTorchåˆ™æ˜¯ç”±Facebookçš„äººå·¥æ™ºèƒ½ç ”ç©¶å›¢é˜Ÿå¼€å‘çš„ä¸€ä¸ªPythonåº“ï¼Œå®ƒæä¾›äº†ä¸¤ä¸ªé«˜çº§åŠŸèƒ½ï¼šå¼ºå¤§çš„GPUåŠ é€Ÿçš„å¼ é‡è®¡ç®—ï¼ˆç±»ä¼¼äºnumpyï¼‰ä»¥åŠå»ºç«‹å’Œè®­ç»ƒç¥ç»ç½‘ç»œçš„æ·±åº¦å­¦ä¹ å¹³å°ã€‚

HuggingFaceåˆ™æ˜¯ä¸€ä¸ªä¸“æ³¨äºè‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„å¼€æºåº“ï¼Œå®ƒæä¾›äº†å¤§é‡é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°æ„å»ºå’Œè®­ç»ƒå„ç§NLPä»»åŠ¡ã€‚

## 2.æ ¸å¿ƒæ¦‚å¿µä¸è”ç³»

### 2.1 TensorFlow

TensorFlowçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯å¼ é‡ï¼ˆTensorï¼‰å’Œè®¡ç®—å›¾ï¼ˆGraphï¼‰ã€‚å¼ é‡æ˜¯ä¸€ä¸ªå¤šç»´æ•°ç»„ï¼Œæ˜¯TensorFlowä¸­æ•°æ®çš„åŸºæœ¬å•ä½ã€‚è®¡ç®—å›¾åˆ™æ˜¯ä¸€ç§æè¿°è®¡ç®—è¿‡ç¨‹çš„æ•°æ®ç»“æ„ï¼Œå®ƒç”±ä¸€ç³»åˆ—çš„TensorFlowæ“ä½œï¼ˆOpï¼‰ç»„æˆã€‚

### 2.2 PyTorch

PyTorchçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯å¼ é‡ï¼ˆTensorï¼‰å’Œè‡ªåŠ¨å¾®åˆ†ï¼ˆAutogradï¼‰ã€‚å¼ é‡åœ¨PyTorchä¸­ä¹Ÿæ˜¯æ•°æ®çš„åŸºæœ¬å•ä½ï¼Œè€Œè‡ªåŠ¨å¾®åˆ†åˆ™æ˜¯PyTorchå®ç°ç¥ç»ç½‘ç»œçš„å…³é”®æŠ€æœ¯ï¼Œå®ƒå¯ä»¥è‡ªåŠ¨è®¡ç®—å‡ºä»»ä½•è®¡ç®—å›¾çš„æ¢¯åº¦ã€‚

### 2.3 HuggingFace

HuggingFaceçš„æ ¸å¿ƒæ¦‚å¿µæ˜¯Transformeræ¨¡å‹å’Œé¢„è®­ç»ƒæ¨¡å‹ã€‚Transformeræ¨¡å‹æ˜¯ä¸€ç§åŸºäºè‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰çš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå®ƒåœ¨NLPé¢†åŸŸå–å¾—äº†æ˜¾è‘—çš„æˆæœã€‚é¢„è®­ç»ƒæ¨¡å‹åˆ™æ˜¯ä¸€ç§åˆ©ç”¨å¤§é‡æ— æ ‡ç­¾æ•°æ®è¿›è¡Œé¢„è®­ç»ƒï¼Œç„¶ååœ¨ç‰¹å®šä»»åŠ¡ä¸Šè¿›è¡Œå¾®è°ƒçš„æ¨¡å‹ï¼Œå®ƒå¯ä»¥æ˜¾è‘—æé«˜æ¨¡å‹çš„æ€§èƒ½ã€‚

## 3.æ ¸å¿ƒç®—æ³•åŸç†å’Œå…·ä½“æ“ä½œæ­¥éª¤ä»¥åŠæ•°å­¦æ¨¡å‹å…¬å¼è¯¦ç»†è®²è§£

### 3.1 TensorFlow

TensorFlowçš„æ ¸å¿ƒç®—æ³•åŸç†æ˜¯æ•°æ®æµå›¾ï¼ˆData Flow Graphï¼‰ã€‚åœ¨æ•°æ®æµå›¾ä¸­ï¼ŒèŠ‚ç‚¹ä»£è¡¨è®¡ç®—æ“ä½œï¼Œè¾¹ä»£è¡¨æ•°æ®çš„æµåŠ¨ã€‚æ•°æ®æµå›¾å¯ä»¥å¹¶è¡Œè®¡ç®—ï¼Œå› æ­¤TensorFlowå¯ä»¥åˆ©ç”¨GPUè¿›è¡Œé«˜æ€§èƒ½çš„æ•°å€¼è®¡ç®—ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨TensorFlowæ¥å®ç°ä¸€ä¸ªç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰æ¨¡å‹çš„å‚æ•°å’Œè¾“å…¥è¾“å‡ºï¼š

```python
import tensorflow as tf

# Model parameters
W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)

# Model input and output
x = tf.placeholder(tf.float32)
linear_model = W * x + b
y = tf.placeholder(tf.float32)
```

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼š

```python
# loss
loss = tf.reduce_sum(tf.square(linear_model - y)) # sum of the squares

# optimizer
optimizer = tf.train.GradientDescentOptimizer(0.01)
train = optimizer.minimize(loss)
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥åˆå§‹åŒ–å˜é‡å¹¶å¼€å§‹è®­ç»ƒï¼š

```python
# training data
x_train = [1, 2, 3, 4]
y_train = [0, -1, -2, -3]

# training loop
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init) # reset values to wrong
for i in range(1000):
  sess.run(train, {x:x_train, y:y_train})

# evaluate training accuracy
curr_W, curr_b, curr_loss = sess.run([W, b, loss], {x:x_train, y:y_train})
print("W: %s b: %s loss: %s"%(curr_W, curr_b, curr_loss))
```

### 3.2 PyTorch

PyTorchçš„æ ¸å¿ƒç®—æ³•åŸç†æ˜¯åŠ¨æ€è®¡ç®—å›¾ï¼ˆDynamic Computational Graphï¼‰ã€‚ä¸TensorFlowçš„é™æ€è®¡ç®—å›¾ä¸åŒï¼ŒPyTorchçš„è®¡ç®—å›¾åœ¨æ¯æ¬¡å‰å‘ä¼ æ’­æ—¶éƒ½ä¼šé‡æ–°æ„å»ºã€‚è¿™ä½¿å¾—PyTorchæ›´åŠ çµæ´»ï¼Œå¯ä»¥æ”¯æŒåŠ¨æ€ç½‘ç»œç»“æ„å’Œæ§åˆ¶æµã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨PyTorchæ¥å®ç°ä¸€ä¸ªç®€å•çš„å¤šå±‚æ„ŸçŸ¥å™¨ï¼ˆMLPï¼‰æ¨¡å‹ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰æ¨¡å‹çš„ç»“æ„ï¼š

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class MLP(nn.Module):
    def __init__(self):
        super(MLP, self).__init__()
        self.fc1 = nn.Linear(784, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x
```

ç„¶åï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ï¼š

```python
# loss and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å¼€å§‹è®­ç»ƒï¼š

```python
# training loop
for epoch in range(10):  # loop over the dataset multiple times
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')
```

### 3.3 HuggingFace

HuggingFaceçš„æ ¸å¿ƒç®—æ³•åŸç†æ˜¯Transformeræ¨¡å‹å’Œé¢„è®­ç»ƒæ¨¡å‹ã€‚Transformeræ¨¡å‹çš„å…³é”®æŠ€æœ¯æ˜¯è‡ªæ³¨æ„åŠ›æœºåˆ¶ï¼ˆSelf-Attentionï¼‰ï¼Œå®ƒå¯ä»¥æ•æ‰åºåˆ—ä¸­çš„é•¿è·ç¦»ä¾èµ–å…³ç³»ã€‚é¢„è®­ç»ƒæ¨¡å‹çš„å…³é”®æŠ€æœ¯æ˜¯Masked Language Modelï¼ˆMLMï¼‰å’ŒNext Sentence Predictionï¼ˆNSPï¼‰ï¼Œå®ƒä»¬å¯ä»¥åˆ©ç”¨å¤§é‡æ— æ ‡ç­¾æ•°æ®è¿›è¡Œé¢„è®­ç»ƒã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨HuggingFaceæ¥å®ç°ä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨ï¼š

```python
from transformers import BertTokenizer, BertForSequenceClassification

tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased')
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œå¹¶é€šè¿‡æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼š

```python
inputs = tokenizer("Hello, my dog is cute", return_tensors="pt")
labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1
outputs = model(**inputs, labels=labels)
loss = outputs.loss
logits = outputs.logits
```

## 4.å…·ä½“æœ€ä½³å®è·µï¼šä»£ç å®ä¾‹å’Œè¯¦ç»†è§£é‡Šè¯´æ˜

### 4.1 TensorFlow

åœ¨TensorFlowä¸­ï¼Œæœ€ä½³å®è·µæ˜¯ä½¿ç”¨tf.data APIæ¥æ„å»ºè¾“å…¥ç®¡é“ã€‚tf.data APIå¯ä»¥å¤„ç†å¤§é‡æ•°æ®ï¼Œæ”¯æŒå¤šçº¿ç¨‹å’Œé¢„å–ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ•°æ®åŠ è½½çš„æ•ˆç‡ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨tf.data APIæ¥æ„å»ºä¸€ä¸ªå›¾ç‰‡æ•°æ®çš„è¾“å…¥ç®¡é“ï¼š

```python
import tensorflow as tf

# list of file names

# create a dataset from file names
dataset = tf.data.Dataset.from_tensor_slices(filenames)

# load and preprocess images
def load_and_preprocess_image(filename):
    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.resize(image, [224, 224])
    image /= 255.0  # normalize to [0,1] range
    return image

# apply the function to each item in the dataset
dataset = dataset.map(load_and_preprocess_image)

# batch and prefetch
dataset = dataset.batch(32).prefetch(1)
```

### 4.2 PyTorch

åœ¨PyTorchä¸­ï¼Œæœ€ä½³å®è·µæ˜¯ä½¿ç”¨torch.utils.data.DataLoaderæ¥æ„å»ºè¾“å…¥ç®¡é“ã€‚DataLoaderå¯ä»¥å¤„ç†å¤§é‡æ•°æ®ï¼Œæ”¯æŒå¤šçº¿ç¨‹å’Œé¢„å–ï¼Œå¯ä»¥æ˜¾è‘—æé«˜æ•°æ®åŠ è½½çš„æ•ˆç‡ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨DataLoaderæ¥æ„å»ºä¸€ä¸ªå›¾ç‰‡æ•°æ®çš„è¾“å…¥ç®¡é“ï¼š

```python
import torch
from torchvision import datasets, transforms

# data transformation
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# load data
train_data = datasets.ImageFolder('path/to/train', transform=transform)
test_data = datasets.ImageFolder('path/to/test', transform=transform)

# create data loader
train_loader = torch.utils.data.DataLoader(train_data, batch_size=32, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=False)
```

### 4.3 HuggingFace

åœ¨HuggingFaceä¸­ï¼Œæœ€ä½³å®è·µæ˜¯ä½¿ç”¨Trainer APIæ¥è¿›è¡Œæ¨¡å‹çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚Trainer APIæä¾›äº†è®¸å¤šæ–¹ä¾¿çš„åŠŸèƒ½ï¼Œå¦‚æ¨¡å‹ä¿å­˜å’ŒåŠ è½½ã€å­¦ä¹ ç‡è°ƒåº¦ã€æ¨¡å‹å¹¶è¡Œç­‰ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨Trainer APIæ¥è¿›è¡Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡çš„è®­ç»ƒå’Œè¯„ä¼°ï¼š

```python
from transformers import BertForSequenceClassification, Trainer, TrainingArguments

# load model
model = BertForSequenceClassification.from_pretrained("bert-base-uncased")

# define training arguments
training_args = TrainingArguments(
    output_dir='./results',          # output directory
    num_train_epochs=3,              # total number of training epochs
    per_device_train_batch_size=16,  # batch size per device during training
    per_device_eval_batch_size=64,   # batch size for evaluation
    warmup_steps=500,                # number of warmup steps for learning rate scheduler
    weight_decay=0.01,               # strength of weight decay
    logging_dir='./logs',            # directory for storing logs
)

# define trainer
trainer = Trainer(
    model=model,                         # the instantiated ğŸ¤— Transformers model to be trained
    args=training_args,                  # training arguments, defined above
    train_dataset=train_dataset,         # training dataset
    eval_dataset=test_dataset            # evaluation dataset
)

# train and evaluate
trainer.train()
trainer.evaluate()
```

## 5.å®é™…åº”ç”¨åœºæ™¯

### 5.1 TensorFlow

TensorFlowè¢«å¹¿æ³›åº”ç”¨äºå„ç§é¢†åŸŸï¼Œå¦‚è¯­éŸ³è¯†åˆ«ã€å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€ç”Ÿç‰©ä¿¡æ¯å­¦ç­‰ã€‚ä¾‹å¦‚ï¼ŒGoogleçš„è¯­éŸ³æœç´¢å’Œç…§ç‰‡åº”ç”¨éƒ½ä½¿ç”¨äº†TensorFlowè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒå’Œéƒ¨ç½²ã€‚

### 5.2 PyTorch

PyTorchè¢«å¹¿æ³›åº”ç”¨äºç ”ç©¶å’Œå¼€å‘ã€‚ç”±äºå…¶çµæ´»æ€§å’Œæ˜“ç”¨æ€§ï¼Œè®¸å¤šç ”ç©¶äººå‘˜é€‰æ‹©PyTorchä½œä¸ºå®ç°æ–°çš„ç®—æ³•å’Œæ¨¡å‹çš„å·¥å…·ã€‚æ­¤å¤–ï¼ŒPyTorchä¹Ÿè¢«ç”¨äºå¼€å‘å„ç§åº”ç”¨ï¼Œå¦‚è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—å›¾åƒåˆ†æç­‰ã€‚

### 5.3 HuggingFace

HuggingFaceä¸»è¦åº”ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚å®ƒæä¾›äº†å¤§é‡é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†ï¼Œä½¿å¾—å¼€å‘è€…å¯ä»¥è½»æ¾åœ°æ„å»ºå’Œè®­ç»ƒå„ç§NLPä»»åŠ¡ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€å‘½åå®ä½“è¯†åˆ«ã€æƒ…æ„Ÿåˆ†æç­‰ã€‚

## 6.å·¥å…·å’Œèµ„æºæ¨è

### 6.1 TensorFlow

- TensorFlowå®˜æ–¹ç½‘ç«™ï¼šhttps://www.tensorflow.org/
- TensorFlow GitHubï¼šhttps://github.com/tensorflow/tensorflow
- TensorFlow Tutorialsï¼šhttps://www.tensorflow.org/tutorials

### 6.2 PyTorch

- PyTorchå®˜æ–¹ç½‘ç«™ï¼šhttps://pytorch.org/
- PyTorch GitHubï¼šhttps://github.com/pytorch/pytorch
- PyTorch Tutorialsï¼šhttps://pytorch.org/tutorials/

### 6.3 HuggingFace

- HuggingFaceå®˜æ–¹ç½‘ç«™ï¼šhttps://huggingface.co/
- HuggingFace GitHubï¼šhttps://github.com/huggingface/transformers
- HuggingFace Model Hubï¼šhttps://huggingface.co/models

## 7.æ€»ç»“ï¼šæœªæ¥å‘å±•è¶‹åŠ¿ä¸æŒ‘æˆ˜

éšç€æ·±åº¦å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„å‘å±•ï¼Œå¼€æºå·¥å…·å’Œæ¡†æ¶çš„é‡è¦æ€§å°†è¶Šæ¥è¶Šå¤§ã€‚TensorFlowã€PyTorchå’ŒHuggingFaceç­‰å·¥å…·å’Œæ¡†æ¶å°†ç»§ç»­å‘å±•å’Œå®Œå–„ï¼Œä¸ºç ”ç©¶äººå‘˜å’Œå¼€å‘è€…æä¾›æ›´å¤šçš„ä¾¿åˆ©ã€‚

ç„¶è€Œï¼Œéšç€æ¨¡å‹å’Œç®—æ³•çš„å¤æ‚æ€§å¢åŠ ï¼Œå¦‚ä½•æé«˜è®¡ç®—æ•ˆç‡ã€é™ä½å†…å­˜æ¶ˆè€—ã€ç®€åŒ–æ¨¡å‹éƒ¨ç½²ç­‰é—®é¢˜å°†æˆä¸ºæœªæ¥çš„æŒ‘æˆ˜ã€‚æ­¤å¤–ï¼Œå¦‚ä½•æé«˜å·¥å…·å’Œæ¡†æ¶çš„æ˜“ç”¨æ€§å’Œå¯æ‰©å±•æ€§ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”å„ç§å¤æ‚çš„åº”ç”¨åœºæ™¯ï¼Œä¹Ÿæ˜¯æœªæ¥éœ€è¦è§£å†³çš„é—®é¢˜ã€‚

## 8.é™„å½•ï¼šå¸¸è§é—®é¢˜ä¸è§£ç­”

### 8.1 TensorFlow vs PyTorch

é—®é¢˜ï¼šæˆ‘åº”è¯¥é€‰æ‹©TensorFlowè¿˜æ˜¯PyTorchï¼Ÿ

ç­”æ¡ˆï¼šè¿™å–å†³äºä½ çš„å…·ä½“éœ€æ±‚ã€‚TensorFlowæä¾›äº†æ›´å…¨é¢çš„ç”Ÿæ€ç³»ç»Ÿï¼ŒåŒ…æ‹¬TensorBoardã€TensorFlow Servingç­‰å·¥å…·ï¼Œé€‚åˆäºå¤§è§„æ¨¡çš„ç”Ÿäº§ç¯å¢ƒã€‚è€ŒPyTorchåˆ™æ›´åŠ çµæ´»å’Œæ˜“ç”¨ï¼Œé€‚åˆäºç ”ç©¶å’ŒåŸå‹è®¾è®¡ã€‚

### 8.2 HuggingFaceçš„é¢„è®­ç»ƒæ¨¡å‹

é—®é¢˜ï¼šHuggingFaceçš„é¢„è®­ç»ƒæ¨¡å‹æ˜¯å¦‚ä½•è®­ç»ƒçš„ï¼Ÿ

ç­”æ¡ˆï¼šHuggingFaceçš„é¢„è®­ç»ƒæ¨¡å‹é€šå¸¸ä½¿ç”¨å¤§é‡çš„æ— æ ‡ç­¾æ–‡æœ¬æ•°æ®è¿›è¡Œè®­ç»ƒã€‚è®­ç»ƒè¿‡ç¨‹åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µï¼šé¢„è®­ç»ƒå’Œå¾®è°ƒã€‚åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæ¨¡å‹å­¦ä¹ è¯­è¨€çš„ä¸€èˆ¬ç‰¹æ€§ï¼›åœ¨å¾®è°ƒé˜¶æ®µï¼Œæ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡çš„æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä»¥é€‚åº”è¯¥ä»»åŠ¡ã€‚

### 8.3 TensorFlowå’ŒPyTorchçš„æ€§èƒ½æ¯”è¾ƒ

é—®é¢˜ï¼šTensorFlowå’ŒPyTorchçš„æ€§èƒ½å¦‚ä½•ï¼Ÿ

ç­”æ¡ˆï¼šTensorFlowå’ŒPyTorchçš„æ€§èƒ½å¤§è‡´ç›¸å½“ã€‚ä¸¤è€…éƒ½æ”¯æŒGPUåŠ é€Ÿå’Œè‡ªåŠ¨å¾®åˆ†ï¼Œå¯ä»¥é«˜æ•ˆåœ°è¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è®­ç»ƒã€‚ç„¶è€Œï¼Œç”±äºTensorFlowä½¿ç”¨é™æ€è®¡ç®—å›¾ï¼Œå› æ­¤åœ¨æŸäº›æƒ…å†µä¸‹ï¼ŒTensorFlowçš„æ€§èƒ½å¯èƒ½ä¼šä¼˜äºPyTorchã€‚

### 8.4 å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¡†æ¶

é—®é¢˜ï¼šæˆ‘åº”è¯¥å¦‚ä½•é€‰æ‹©åˆé€‚çš„æ¡†æ¶ï¼Ÿ

ç­”æ¡ˆï¼šé€‰æ‹©åˆé€‚çš„æ¡†æ¶å–å†³äºä½ çš„å…·ä½“éœ€æ±‚ã€‚ä½ åº”è¯¥è€ƒè™‘ä»¥ä¸‹å› ç´ ï¼šä½ çš„ä»»åŠ¡ç±»å‹ï¼ˆä¾‹å¦‚ï¼Œå›¾åƒå¤„ç†ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰ï¼‰ã€ä½ çš„ç¡¬ä»¶ç¯å¢ƒï¼ˆä¾‹å¦‚ï¼Œæ˜¯å¦æœ‰GPUï¼‰ã€ä½ çš„ç¼–ç¨‹ç»éªŒï¼ˆä¾‹å¦‚ï¼Œä½ æ˜¯å¦ç†Ÿæ‚‰Pythonï¼‰ã€ä½ çš„ç”Ÿäº§éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼Œæ˜¯å¦éœ€è¦éƒ¨ç½²æ¨¡å‹ï¼‰ç­‰ã€‚