# 金融风控：小样本欺诈检测

作者：禅与计算机程序设计艺术

## 1.背景介绍

随着金融科技的迅猛发展,在线支付、网络借贷等创新金融服务模式不断涌现。然而,随之而来的金融欺诈风险也日益加剧。传统的欺诈检测方法主要依赖于大量的历史交易数据和已知欺诈模式,对新型欺诈手段的检测能力有限。如何从海量异构数据中快速准确地识别出欺诈交易,成为金融机构风控系统的重大挑战。

在实际场景中,已知的欺诈样本通常非常有限,而非欺诈样本却非常充足,属于典型的非平衡数据分类问题。传统的监督学习算法如逻辑回归、决策树等在小样本场景下很难取得理想的效果。因此,研究小样本条件下的欺诈检测算法,对提升金融风控的效率和准确性具有重要意义。

### 1.1 欺诈检测面临的挑战

- 黑产手段不断翻新,传统规则难以覆盖
- 已知欺诈样本稀少,正负样本严重不平衡  
- 业务场景多样,特征工程复杂度高
- 实时性要求高,算法响应时间有限

### 1.2 小样本学习的优势

- 充分利用先验知识,快速适应新的欺诈模式
- 降低模型对大量标注数据的依赖
- 提高模型的泛化能力和鲁棒性
- 加速模型迭代优化,实现快速部署上线

## 2. 核心概念与联系

### 2.1 少样本学习(Few-shot Learning) 

少样本学习是指利用极少量的标注样本(如每个类别仅有1~5个样本)来训练模型。其目标是通过学习已有类别的知识,快速适应新的未知类别。常见的Few-shot Learning范式有:

- N-way K-shot:每个任务包含N个类别,每个类别有K个已标注样本
- 元学习(Meta-Learning):通过学习一系列小任务来掌握快速学习新任务的元知识

### 2.2 孪生神经网络(Siamese Neural Networks)

孪生神经网络由两个结构相同的子网络组成,用于学习两个输入样本之间的相似度。其核心思想是最小化同类样本对的距离,最大化异类样本对的距离。常用的孪生网络有:

- 连体网络(Tied Weights)  
- 伪孪生网络(Pseudo-Siamese)
- 三元组损失(Triplet Loss)

### 2.3 对比学习(Contrastive Learning)

对比学习是一种自监督学习范式,通过构建正负样本对来学习数据的内在结构和特征表示。其目标函数一般包含两个部分:
- 正样本对的相似度尽可能大
- 负样本对的相似度尽可能小

对比学习常用方法有:
- SimCLR
- MoCo
- BYOL 
- SimSiam

### 2.4 图与图神经网络(Graph Neural Networks)

将交易数据抽象为图结构,可以挖掘交易主体之间的关联信息。常见的GNN模型有:

- 图卷积网络(Graph Convolutional Networks, GCN)
- 图注意力网络(Graph Attention Networks, GAT) 
- 图同构网络(Graph Isomorphism Networks, GIN)

通过对图结构数据的建模和推理,GNN可以有效捕捉交易行为模式和用户群体特征。

## 3. 核心算法原理与操作步骤

本节重点介绍基于孪生网络和图神经网络的小样本欺诈检测算法,主要分为数据建模、特征学习和分类预测三个部分。

### 3.1 异构图构建

- 定义图的节点类型:Transaction/User/Card/Device/IP等
- 定义图的边类型:属于/发生/登录/绑定等语义关系
- 根据交易日志构建异构图,每笔交易为中心节点

### 3.2 元路径聚合

- 基于业务先验定义关键元路径(meta-path),如:
  - Txn -> User -> Txn
  - Txn -> Card -> User -> Device -> Txn  
- 采样每个交易实例关联的局部异构子图
- 利用元路径聚合节点邻域信息,生成聚合特征

### 3.3 孪生图神经网络

- 共享权重的双塔图神经网络,学习顶点的低维嵌入
- 采用对比损失函数,拉近正样本距离,拉远负样本距离
- 基于欧氏距离度量顶点嵌入之间的相似性

$$
D(h_i,h_j)=\left \| h_i-h_j \right \|_2
$$

- 使用Focal Loss缓解类别不平衡问题

$$
FL(p_t)=-\alpha_t(1-p_t)^{\gamma}\log(p_t)
$$

### 3.4 Few-shot Detector

- 支持集:每个已知欺诈类型采样K个样本
- 查询集:待预测的交易样本
- 计算查询样本与支持集的相似度,如余弦相似度:

$$
S(q,s)=\frac{q^Ts}{\left \| q \right \|\left \| s \right \|}
$$  

- 基于相似度加权的多分类器集成,预测欺诈类型:

$$
\hat{y}=\arg\max_{k}\sum_{i=1}^KS(q,s_i^k)
$$

## 4. 模型讲解与公式推导

### 4.1 孪生网络的三元组损失

三元组损失(Triplet Loss)由Anchor样本(a)、Positive样本(p)和Negative样本(n)组成。其中a与p属于同一类别,a与n属于不同类别。三元组损失函数的定义为:

$$
L(a,p,n)=\max(d(a,p)-d(a,n)+\alpha, 0)
$$

其中$d(·)$表示两个样本之间的距离度量函数,$\alpha$为超参数,表示希望正负样本对之间的距离大于$\alpha$。

为了最小化三元组损失,我们希望:
- $d(a,p)$尽可能小,即$a$与$p$的特征表示尽可能接近
- $d(a,n)$尽可能大,即$a$与$n$的特征表示尽可能远离

### 4.2 异质图神经网络

考虑一个异质图$\mathcal{G=(V,E,T,R)}$,其中节点类型映射函数$\tau(v): \mathcal{V} \rightarrow \mathcal{T}$,边类型映射函数$\phi(e): \mathcal{E} \rightarrow \mathcal{R}$。异质GNN的层级传播规则为:

$$
h_i^{(l)}=\sigma(\sum_{r \in \mathcal{R}}W_r^{(l)}\sum_{j \in \mathcal{N}_i^r}\frac{1}{\sqrt{|\mathcal{N}_i^r||\mathcal{N}_j^r|}}h_j^{(l-1)})
$$  

其中$h_i^{(l)}$表示第$l$层第$i$个节点的隐藏状态,$\mathcal{N}_i^r$表示节点$i$关于关系$r$的邻居节点集合,$W_r^{(l)}$为关系$r$的权重矩阵,$\sigma$为激活函数如ReLU。

图级表示可通过池化所有顶点的嵌入向量得到:

$$
h_{\mathcal{G}}=\operatorname{AGGREGATE}(\{h_i^{(L)}|v_i \in \mathcal{V}\})
$$

其中AGGREGATE可以是求和/平均/最大池化等聚合函数。

### 4.3 对比损失函数  

给定一批N个样本$\{x_i\}_{i=1}^N$,基于数据增强策略构造正样本对$(x_i,x_i^+)$。对比学习的目标是最大化正样本对的相似度:

$$
\mathcal{L}_{CL}=-\sum_{i=1}^N\log\frac{\exp(f(x_i) \cdot f(x_i^+)/\tau)}{\sum_{j=1}^N\exp(f(x_i) \cdot f(x_j)/\tau)}
$$

其中$f(·)$表示编码网络(如CNN/Transformer),$\tau$为温度超参数。直观地,对比损失鼓励：
- 最大化$f(x_i)$与$f(x_i^+)$的互信息
- 最小化$f(x_i)$与其他样本$f(x_j)$的互信息

## 5. 项目实践：代码实例详解

接下来以一个简化的异构图欺诈检测为例,展示核心算法的PySpark实现。

```python
from pyspark.sql import SparkSession
from pyspark.ml.linalg import Vectors
from pyspark.ml.classification import LogisticRegression

# 构建异构图
spark = SparkSession.builder.getOrCreate() 
txn_df = spark.read.csv("transactions.csv") 
usr_df = spark.read.csv("users.csv")
# 定义边的DataFrame
edges = [(txn1, usr1, "by"), (usr1, txn2, "trans"), ...]  
edge_df = spark.createDataFrame(edges, ["src", "dst", "type"])

# 元路径采样与特征聚合
metapath1 = ["by", "trans"]
metapath2 = ["by", "link", "by"]  

adj_df1 = edge_df.filter(edge_df.type == metapath1[0])
         .join(edge_df.filter(edge_df.type == metapath1[1]), "dst")
         .groupBy("src").agg(collect_set("dst").alias("neighbors"))

adj_df2 = ...

# 孪生网络用户嵌入
def twin_encoder(src, dst, neighbor_list):
    src_emb = Vectors.dense([0.0] * EMBEDDING_DIM)  
    for n in neighbor_list:
        src_emb += model.getVertexEmbedding(n)
    
    dst_emb = model.getVertexEmbedding(dst)
    return (src, src_emb, dst, dst_emb)

Twin_df = adj_df.rdd.map(lambda x: twin_encoder(x[0], x[1], x[2])) \
        .toDF(["src", "src_emb", "dst", "dst_emb"]) 

# 对比学习损失
def contrastive_loss(src_emb, dst_emb, label):
    sim = cosine_similarity(src_emb, dst_emb)  
    loss = -label * math.log(sim) - (1 - label) * math.log(1 - sim)
    return loss

contrastive_loss_udf = udf(contrastive_loss, FloatType())
loss_df = Twin_df.withColumn("loss", contrastive_loss_udf("src_emb", "dst_emb", "label"))
total_loss = loss_df.agg({"loss": "avg"}).collect()[0][0]

# 小样本分类
support_set = [(101, [0.2, 0.1, ...], 1), (203, [0.3, -0.1, ...], 1) ...]
query_set = test_df.rdd.map(lambda x: (x[0], model.getVertexEmbedding(x[0]))).collect()

def cos_sim(emb1, emb2):
    return emb1.dot(emb2) / (norm(emb1) * norm(emb2))

def knn_vote(query_emb):
    sims = [cos_sim(query_emb, s[1]) for s in support_set]
    nearest = support_set[np.argmax(sims)]
    return nearest[-1]  
           
test_df = test_df.rdd.map(lambda x: (x[0], knn_vote(x[1]))).toDF(["id", "label"])
```

主要步骤包括:

1. 利用结构化数据构建异构图的节点和边DataFrame
2. 基于元路径采样局部子图,并聚合邻域特征 
3. 孪生网络学习顶点嵌入向量
4. 使用对比损失函数进行预训练
5. 定义支持集,并对查询样本进行KNN投票分类

## 6. 实际应用场景

小样本欺诈检测技术在金融领域有广泛的应用前景,典型场景包括:

- 银行卡盗刷:从少量已知盗刷交易中挖掘欺诈模式,对新交易进行实时预警
- 信用卡恶意透支:利用小样本学习模型,及时识别高危申请人
- 反洗钱(AML):从已知洗钱案例中快速发现相似的可疑交易 
- 保险欺诈理赔:基于小规模专家知识,构建智能反欺诈引擎
- 网络借贷反欺诈:通过小样本元学习,不断适应新型欺诈手法

除金融行业外,小样本学习在智能安防、工业质检、医疗诊断等领域也有诸多应用。

## 7. 工具和资源推