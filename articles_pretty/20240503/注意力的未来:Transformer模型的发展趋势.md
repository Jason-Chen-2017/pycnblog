## 1. 背景介绍

### 1.1. 从序列到序列：深度学习的自然语言处理之旅 

自然语言处理 (NLP) 一直是人工智能领域的关键挑战之一。早期的方法主要依赖于统计模型和规则，但随着深度学习的兴起，NLP 领域发生了翻天覆地的变化。循环神经网络 (RNN) 和长短期记忆网络 (LSTM) 等模型在序列建模任务中取得了显著的进展，例如机器翻译、文本摘要和语音识别。然而，这些模型存在着梯度消失和难以并行化等问题，限制了它们在长序列上的性能。

### 1.2. 注意力机制：