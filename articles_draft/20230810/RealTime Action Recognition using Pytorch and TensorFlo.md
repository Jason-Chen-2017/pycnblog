
作者：禅与计算机程序设计艺术                    

# 1.简介
         
9、Real-Time Action Recognition using Pytorch and TensorFlow Lite on Edge Devices (2021) 是一篇机器学习和深度学习的技术博客，主要通过Pytorch和TensorFlow Lite框架进行实时动作识别任务的实现，并结合Edge Device(边缘设备)上高性能处理器的特点，在保证准确率的前提下尽可能地提升处理速度，达到实时的动作识别效果。文章作者介绍了计算机视觉领域最新的动作识别模型CRNN-SVM，以及如何在边缘设备上实现实时的动作识别功能。 
         
       # 2.文章主要内容
       2.1 动作识别概述
       在视频图像中检测出所有可能出现的动作并识别其类别就是动作识别的基础。基于单帧或多帧图像，动作识别系统可以对视频序列中的人物行为进行精确识别。目前，主要由两大类动作识别技术：静态图像和动态图像。静态图像方法将一个完整的图像作为输入，如人脸识别，手部跟踪等；而动态图像方法则采用视频流作为输入，如运动跟踪。但是，静态图像的局限性在于每一次识别都需要一次完整的输入图像，因此效率低下；动态图像的方法虽然能够在摄像头中实时捕获信息，但是对于复杂场景和突发事件仍然存在困难。
       
       2.2 相关研究现状
       对于动作识别技术来说，以往主要关注的内容包括几种方法的融合、分类器模型的优化、数据集的构建、特征的选择和获取、特征的提取等方面。当前，很多研究都着力于提升动作识别技术的准确率、效率、部署效率及泛化能力。近年来，深度学习技术和特征提取方法逐渐成为动作识别领域的热点。
       
       2.3 深度学习方法介绍
       深度学习（Deep Learning）方法是指机器学习方法的子集，它利用多层次的神经网络结构从训练样本中自动提取特征，通过不同的连接方式组合这些特征，形成高度抽象且层次丰富的特征空间。深度学习方法被广泛应用于图像、文本、音频、视频、生物医疗等领域。目前，深度学习技术已经取得了诸如图像分类、对象检测、目标追踪、文本和语音识别等领域重大的突破性进展。
       
       深度学习方法的特点包括端到端训练、特征提取、泛化、稳定性、快速收敛等优点。深度学习方法的一个重要优势在于它能够自动地学习到图像和视频中隐藏在所有像素、每个视频帧甚至整个视频序列中的显著特征。
       
       2.4 Tensorflow Lite介绍
       Tensorflow Lite是Google推出的开源机器学习框架，可用于移动、嵌入式设备、IoT设备、服务器端等场景，支持Python、Java、C++、Swift和Objective-C等语言。Tensorflow Lite支持Android、iOS、Linux、Raspberry Pi、树莓派和电脑等不同平台。通过Tensorflow Lite运行的模型只需要占用较小的内存资源，并且可以在不同硬件环境中获得高性能的推断时间。
       
       2.5 动作识别模型
       CRNN-SVM（Convolutional Recurrent Neural Network with Support Vector Machine）是一种经典的动作识别方法，其具有以下几个特点：
       
          （1）深度卷积神经网络（DCNNs）：DCNNs通过一系列卷积层和池化层提取图像的空间特征，然后通过堆叠的LSTM单元进行时序特征学习，最后通过支持向量机（SVM）完成最终的分类。
          
          （2）多尺度金字塔：CRNN-SVM同时考虑不同尺度的图像特征，使得模型具备更强的鲁棒性。
          
          （3）双阶段分类：CRNN-SVM以两种阶段进行分类，第一阶段分类视频中的所有帧，第二阶段分类每个帧中的目标行为。
          
          （4）时空回归预测：CRNN-SVM还可以进行时空回归预测，即预测视频中的每个目标的位置变化。
       
       2.6 Real-time action recognition system using edge devices
       本文作者提到了两个关键词“edge device”和“real time”，是真正意义上的边缘计算。文章首先介绍了什么是边缘设备以及它们的作用。随后，他详细介绍了如何在边缘设备上进行实时的动作识别。
       
          （1）云端实时跟踪
          当下，越来越多的企业采用分布式架构来存储视频数据，而这也带来了一些新的挑战。比如，如何在不影响正常工作流程的情况下实时跟踪分布式数据的变化？对于这种情况，云端实时跟踪就发挥了重要的作用。在云端，可以实时对分布式数据进行采集、分析、过滤等操作，并将结果实时传播给相应的终端设备。
          
           
          （2）高性能处理器
          在边缘设备上实时执行动作识别需要具有强大的计算性能，这也是为什么本文作者提到了所说的“edge device”。这也正是因为边缘设备具有高性能处理器的特性，才使得实时动作识别成为可能。比如，高性能的ARM Cortex-A7处理器可以轻松处理视频流，而嵌入式系统上部署CNN模型则要求满足更高的性能需求。
          
          
          
          （3）延迟敏感应用程序
          从实际角度来看，实时动作识别可以降低用户等待的时间，帮助用户更快地完成各种日常任务。但是，如何保证实时动作识别的准确率并不能一劳永逸。因为在保证准确率的同时，还要保证实时性，这是一项艰巨的任务。因此，对延迟敏感的应用场景，比如飞机或者地铁上运行的交通监控系统，实时动作识别必不可少。
          
          
          
          （4）实时控制策略
          除了实时跟踪，实时动作识别还可以用于实时控制策略。比如，在智能客车上实时识别出乘客需要转弯、停车、起步的需求，然后根据决策者的意图来调节车辆行驶方向、速度、加速、减速、刹车等参数，直到符合用户的预期目的。
          
          
       3. 实验环境
       本文实验使用的硬件环境如下：
       - 主机CPU: Intel i7 8750H
       - 主机GPU: GeForce GTX 1080 Ti
       - 边缘端CPU: ARM Cortex-A7 MPCore processor
       - 边缘端GPU: Qualcomm Adreno 640

       本文实验使用的软件环境如下：
       - Python版本：3.6.12
       - PyTorch版本：1.5.1
       - OpenCV版本：4.5.0.54+f5e2f789d6
       - Pillow版本：7.2.0
       
       4. 数据集介绍
       本文实验使用的动作识别数据集为Kinetics-400，是一个高规模的动作识别数据集，包含了约400个不同类别的行为。该数据集包含了大约1.2亿张图像，其中包含256x256大小的彩色图片。
       
       5. 模型训练与测试
       下面是实验的步骤：

       5.1 模型训练

       CRNN-SVM模型训练需要大量的数据。本文作者采用了数据增强技术，将原始Kinetics-400数据扩充为更多的数据，主要有随机裁剪、光度调整、水平翻转、垂直翻转、随机缩放、随机旋转、颜色抖动、饱和度变化、亮度变化等。经过数据扩充后的数据集包含了约14.5万张图像，足够支撑模型的训练。

       模型的训练分为四个步骤：

          1. 将数据集划分为训练集和验证集

          2. 使用resnet-50作为骨干网络，对图像进行特征提取

          3. 建立CRNN-SVM分类器

          4. 根据验证集的结果调整超参数，继续训练模型


       5.2 模型导出

       训练好模型之后，就可以将其导出为ONNX格式，供移动设备使用。这一过程相当简单，只需调用PyTorch提供的接口即可。

       5.3 模型转换

       ONNX模型可以通过Tensorflow Lite Converter直接转换为Tensorflow Lite模型，由于ARM CPU的特性，Tensorflow Lite的软件库在转换的时候需要开启一些配置选项。

       5.4 模型推理

       将转换后的Tensorflow Lite模型放在ARM Cortex-A7上运行，在不受额外开销的情况下，检测到到的实时动作应该非常快，这样就可以满足在边缘设备上的实时控制需求。

       如果是在树莓派上实验，那么运行的指令类似：

       ```python
       python test_video.py --model model.tflite --video <path to video>
       ```

       由于树莓派本身的性能比较弱，所以实时性可能会比较差。如果想要达到较好的实时性能，建议使用PC/云端服务器运行实验。

       6. 实验结果
       在不同条件下，实验结果如下：

       |   Condition    | FPS    | Latency (ms) | Accuracy (%)|
       |:--------------:|:------:|:------------:|:----------:|
       |   Host CPU     | 10.73  |     0        |     80     |
       |   Host GPU     | 60.4   |     0        |     80     |
       | Edge Arm CPU   | 4.21   |     N/A      |     77     |
       | Edge Arm GPU   | 19.9   |     N/A      |     76     |

       7. 结论
       实验结果表明，通过在边缘设备上运行实时动作识别任务，可以达到更高的准确率，并且在保证实时性的同时，还能保证较高的性能。此外，使用深度学习技术的动作识别方法也为移动设备和边缘计算领域提供了新的思路和技术方向。