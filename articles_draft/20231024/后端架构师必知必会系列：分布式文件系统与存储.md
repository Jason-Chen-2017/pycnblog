
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


## 分布式文件系统的产生背景及其价值
### 文件共享网络应用
1990年代以前，个人计算机和小型服务器之间的文件共享仅限于同一个局域网内。当时，互联网还很 young，主要靠寻找其他服务器上的文件来进行数据交换。而现在，随着信息技术的飞速发展，越来越多的人开始在线上进行文件的共享和保存，比如网盘、云盘等。

文件共享网络应用的普及促进了分布式计算的发展。随着数据量的增长，单个服务器无法快速处理请求，需要将数据分布到多个服务器中进行处理，这就是所谓的分布式计算。而分布式计算带来的另一个问题是，如何管理和存储这些数据？所以，分布式文件系统应运而生。

### 分布式文件系统的定义
分布式文件系统(Distributed File System, DFS)是指基于分布式计算的海量数据的存储和访问方案。它通过集群存储方式实现海量数据存储，并提供统一的接口给客户端，使得应用层可以像对待本地文件一样方便地读写数据。

分布式文件系统具有如下四大特性:

1. 高容错性：分布式文件系统通过冗余备份的方式提升可用性，当一个节点发生故障时，仍然可以保证服务可用。

2. 数据访问快：分布式文件系统通过将数据分布在不同节点上，通过缓存技术提升访问速度。

3. 负载均衡：分布式文件SYSTEM可以通过调度算法动态分配任务，降低单点故障的影响。

4. 可扩展性：随着分布式计算的发展，分布式文件系统也应运而生。目前，HDFS、Ceph等产品已成为主流分布式文件系统。

## HDFS简介
### HDFS（Hadoop Distributed File System）是一个开源的分布式文件系统。HDFS经过Apache基金会并入了 Hadoop 大数据平台。HDFS 是 Hadoop 的核心组件之一。它的主要功能包括:

1. 支持超大文件：由于 HDFS 使用底层文件系统分块存储机制，因此能够支持超大文件。

2. 高容错性：HDFS 提供了一个高容错的体系结构，能够自动检测、替换失败节点。

3. 数据备份：HDFS 可以自动备份数据，并且支持跨机架部署。

4. 扩展性：HDFS 通过设计可以轻松扩展到上百台机器，解决海量数据存储的问题。

### HDFS组成
HDFS由 NameNode 和 DataNodes 两个进程组成。NameNode 负责维护整个文件系统的目录树，它同时也作为客户端向 DataNodes 发出命令，读取文件数据。DataNodes 负责存储实际的数据块。HDFS 中，所有的文件都存储在分片（Chunk）中。每个 Chunk 大小默认为 128MB。每个 Block 默认包含 3 个副本，且这些副本存在不同的机器上。这样即便某个 DataNode 出现故障，也可以从其他机器上恢复数据。HDFS 支持多用户访问，并且提供了权限控制机制。


## Hadoop 安装配置
首先安装 JDK、Maven、Zookeeper。

```
sudo apt update && sudo apt install default-jdk maven zookeeper -y
```

然后下载 Hadoop。

```
wget https://downloads.apache.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
```

解压后进入 hadoop-3.3.0 目录，执行如下命令配置环境变量：

```
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
export PATH=$PATH:$JAVA_HOME/bin
```

创建 Hadoop 配置文件 `core-site.xml`，添加以下内容：

```
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
  </property>
</configuration>
```

`fs.defaultFS` 指定默认的 HDFS URI。创建完毕之后，复制到 Hadoop 的各个节点上，修改对应的 IP 地址即可。

接下来，启动 Zookeeper 服务：

```
$ zkServer start /etc/zookeeper/conf/zoo.cfg
```

启动 NameNode：

```
$./sbin/start-dfs.sh
Starting namenodes on [localhost]
Starting datanodes
Starting secondary namenodes [0.0.0.0]
...
```

最后，启动 DataNode：

```
$ sbin/start-datanode.sh
Starting datanode daemon for hdp01.xunlong.me
Waiting for namenode to come up...
Registering datanode
Connecting to namenode via http://hdp01.xunlong.me:50070/...DONE
Starting data node
logs available at http://hdp01.xunlong.me:50075/jobdetails.jsp?jobid=application_1603552719253_0001
Starting DataNode
DATA_DIR=/data/datanode
Got hostname=hdp01.xunlong.me
In order to have a high availability of the name node it is recommended that you run at least two of them.
Starting journalnodes
Starting DN heartbeat service at port 50075
Note: No journal nodes defined in config file
JMX enabled by default with port unassigned (set 'rmi.server.hostname' if necessary)
Activating Namenode
Successfully started Namenode HTTP Server at http://hdp01.xunlong.me:50070/
Starting Secondary Namenodes [0.0.0.0]
Starting Journalnode
Journalnode not running yet, waiting for another round...
Started Namenode RPC server at hdp01.xunlong.me/10.234.33.10:8020
Starting All Datanodes
Start Datanode Netty Server at 0.0.0.0:50010
Start Datanode Lifeline RPC Server at 0.0.0.0:50020
Successfully joined DFS
Starting dfs health checker
Successfully stopped Datanode
```