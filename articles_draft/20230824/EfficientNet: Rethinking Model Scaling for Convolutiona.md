
作者：禅与计算机程序设计艺术                    

# 1.简介
  

EfficientNet是一个基于深度学习网络架构搜索方法提出的网络结构。相比于传统的网络结构，EfficientNet能够在更小的模型尺寸下取得更好的性能。本文将会从两个方面介绍这个网络结构——它是如何进行网络结构搜索的？它的设计原则和方法又有哪些？本文希望通过这篇文章，对EfficientNet有一个全面的认识，并且能够为我国机器学习方向的发展提供参考。
# 2.网络结构搜索
## 2.1 模型搜索
计算机视觉中的神经网络模型通常都是一个复杂的参数组合。不同的参数组合可能导致不同的性能表现。因此，要找到一个最优的模型结构或超参数组合就变得非常重要。当训练一个神经网络时，网络结构往往被固定，而超参数则需要被调整。本文将会介绍两种搜索策略——模型搜索（Model Search）和网络搜索（Network Search）。
### 2.1.1 模型搜索
模型搜索法的基本思想是在给定搜索空间中的模型集合中找到一个合适的模型，使得模型的效果达到最佳。模型搜索可以被看做是一种启发式搜索的方法。给定一个模型集合$M$,首先随机选择一个模型$m_t$作为起始点。然后使用某种指标对模型进行评估，比如准确率、参数数量等。接着生成一些候选子模型$m_{t+i}, i=1,\cdots,n$并评估它们的效果，再根据这些子模型的效果进行排序。按照顺序选取几个子模型，选择其中效果最好的子模型作为新的当前模型$m_{t+k}$。重复以上过程，直至满足一定条件或者达到预设的最大迭代次数为止。这里使用的指标主要是用于评估模型效果的损失函数。如下图所示。


模型搜索的过程可以总结成以下几步：

1. 初始化模型
2. 使用指定的优化器搜索模型，优化器参数一般包括学习率、权重衰减、动量等
3. 对得到的多个模型进行比较，选择效果最好的模型作为最终输出
4. 如果没有达到预设条件，返回第3步继续搜索；如果达到预设条件，返回最终结果。

模型搜索方法虽然简单，但是效率很低，因为模型搜索涉及到超多模型的评估，搜索时间也会相应增加。因此，该方法实际上只能在一些受限领域中应用。
### 2.1.2 网络搜索
网络搜索方法的基本思路是搜集不同层次的特征工程技术，并在这些特征工程方法的基础上提出网络结构的搜索空间。网络搜索首先对模型进行初始化，然后通过网络搜索方法在搜索空间中随机采样一些子结构进行探索。同时，网络搜索还采用了进化算法，逐渐引入各种搜索操作来发现新颖的网络结构。如下图所示。


网络搜索方法通过使用一系列的层次特征工程方式对图像进行处理，在这过程中，网络结构会不断进化。最终选择效果最好的子网络作为输出。网络搜索可以有效地解决网络搜索的问题，而且搜索速度快很多。但由于网络搜索需要考虑整个网络的所有参数，因此其搜索空间较大，且耗费资源大。

## 2.2 EfficientNet网络结构搜索策略
在计算机视觉任务中，神经网络模型的选择对模型性能的影响是至关重要的。最近，微调已被证明是一种有效的迁移学习方法。然而，微调的学习率一般很大，容易出现模型过拟合的问题。为了提高迁移学习的效果，作者提出了EfficientNet，它是一种针对目标检测、分类、分割等多种任务的通用模型。作者认为，不同类型的任务所对应的网络结构应该具有不同性质，如深度、宽度、卷积核大小等。因此，作者提出了EfficientNet网络结构搜索策略。

EfficientNet的网络结构搜索策略是基于先验知识和启发式的，它倾向于构建能够在不同任务上取得最佳性能的模型。为了能够在所有任务上取得最佳性能，EfficientNet的搜索策略应包含三个方面：

1. 分布式搜索空间
2. 单一网络块
3. 智能超参数调整

### 2.2.1 分布式搜索空间
分布式搜索空间意味着对于每一种子网络结构，模型的宽度、深度、分辨率、激活函数、压缩技术都有固定的搜索范围。如下图所示。


这种分布式搜索空间能够帮助模型在所有层次上获得更好的泛化能力。搜索范围可以扩展到各种卷积核大小、网络宽度、深度等。实践中，作者设置了一个宽的搜索空间，可以覆盖到相对比较复杂的任务上。

### 2.2.2 单一网络块
单一网络块意味着在每一种子网络结构中都采用相同的形式，如卷积层、归一化层、激活函数等。这样可以减少模型的复杂度，提升搜索效率。同样，单一网络块也可以帮助模型在所有层次上获得更好的性能。

### 2.2.3 智能超参数调整
为了提升模型的性能，作者提出了智能超参数调整机制。智能超参数调整通过一些自适应的策略自动调整模型的超参数，如学习率、权重衰减率、batch size等。这些超参数的调整可以提升模型的性能，如减少过拟合和提升收敛速度。另外，搜索过程也可以不断改善模型的性能。

## 2.3 EfficientNet的网络结构
### 2.3.1 网络组网
EfficientNet使用两个阶段的网络，第一阶段是深度可分离卷积，第二阶段是混合精度运算。如图所示。


#### 深度可分离卷积
深度可分离卷积即把卷积操作和BN层分开，如下图所示。


深度可分离卷积的特点是使用由可学习的卷积层和BN层构成的滤波器。这样可以加速计算，减少内存占用，增强模型的鲁棒性。这也是为什么EfficientNet的模型使用深度可分离卷积而不是普通卷积。

#### 混合精度运算
在深度可分离卷积之后，EfficientNet会在一定程度上提升模型的精度。EfficientNet使用混合精度运算，即将浮点运算转化为整形运算，以此来提升模型的计算效率。如图所示。


如上图所示，浮点运算(FP32)用于计算中间结果，而整数运算(INT8)用于前馈计算。这样可以节省模型的计算资源，提升模型的推理速度。

### 2.3.2 网络宽度搜索
EfficientNet的网络宽度搜索首先确定了深度可分离卷积的步长，然后设置一个初始宽度，随后进行宽度搜索。搜索范围一般设置为基线网络的两倍。搜索的过程如下图所示。


#### 组网方式
EfficientNet的搜索方法是在三种不同类型组网方式的基础上进行的。分别为EfficientNet-B0~B7。

##### EfficientNet-B0~B7
EfficientNet-B0~B7分别代表不同大小的基线网络。

- EfficientNet-B0：基线网络，宽度为1.0，深度为1.0，面积为3.1MB，参数量为6.00M。
- EfficientNet-B1~B7：EfficientNet-B1~B7模型均为一系列的模型堆叠，在相同的宽度和深度下降低了特征图的尺寸，面积和参数量约为EfficientNet-B0的二至四倍。

##### 一系列的模型堆叠
EfficientNet采用的是一系列的模型堆叠的方式，即在每个模块之间加入了残差连接和SE模块。这个架构被称为“ Compound model”。如图所示。


##### 特征图缩放因子
为了保证模型的输出尺寸不变，EfficientNet采用了类似分辨率缩小的操作。每个模块缩小特征图的尺寸为1/4。

##### SE模块
SE模块利用squeeze-and-excitation模块来扩充感受野，将注意力集中到那些有区别性的特征上。SE模块的计算公式如下。

$$
\operatorname{se}(x)=\frac{\mathrm{avg}\left(\sigma\left(W_{r} \cdot x\right)\right)}{\sigma\left(W_{a} \cdot x\right)} \cdot x \\
\text { where } W_{r}=K^{*}_{\mathrm{in}} \otimes M \\
\text { and } W_{a}=K^{*}_{\mathrm{in}} \otimes 1 \\
\text { with } K^{\ell}_{\mathrm{in}}=\text { kernel\_size of }\ell \text {th input feature map}\\
\text { and } M=\max (\left|X^{\ell}-\mu_{\ell}\right|, \epsilon )+\min (\left|X^{\ell}-\mu_{\ell}\right|, \epsilon ),\\
\text { and } \mu_{\ell}=\frac{1}{|\mathcal{P}(\ell)|}\sum_{\beta \in \mathcal{P}(\ell)}\left[s_{\ell}^{(\beta)} \circ X_{\beta}^{\ell}\right]
$$

其中$x$是输入特征图，$\sigma$是激活函数sigmoid或者softmax，$W_r$和$W_a$都是可学习的参数。

### 2.3.3 网络深度搜索
EfficientNet的网络深度搜索将针对特定任务进行，搜索得到最合适的深度。网络深度搜索一般设置为基线网络的两倍。

### 2.3.4 网络精度搜索
在网络深度、宽度以及基础网络结构上的搜索得到一系列的网络架构，然后选择其中效果最好的子网络作为最终输出。由于目标检测、分类、分割等任务各不相同，因此需要对网络的架构、超参数和超训练策略进行调整，才能得到最优的模型。因此，EfficientNet提供了强大的超参数搜索策略。