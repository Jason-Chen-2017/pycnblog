
作者：禅与计算机程序设计艺术                    

# 1.简介
  

**摘要:** 深度学习(Deep Learning)技术是一种基于人脑的神经网络算法，可以让机器像人的神经元一样模仿学习、记忆和理解数据的模式。这项技术在图像识别、自然语言处理等领域都取得了重大进步。本文主要介绍深度学习的相关原理、理论和实践方法，并分享如何利用TensorFlow或PyTorch实现深度学习模型。

文章的前半部分主要介绍了深度学习的背景、概念、术语和主要研究方向。对于普通工程师来说，了解这些知识有助于更好地理解深度学习背后的理论和原理，并能够通过实际案例快速上手训练自己的深度学习模型。阅读完毕后，读者应该掌握以下关键词和基本概念:

1. **深度学习**：深度学习是指机器学习中的一类技术，它使用多层级神经网络进行复杂的特征学习，提取出数据中的有效特征信息。
2. **神经网络（NN）**：神经网络（NN）是一种用来模拟生物神经系统工作方式的机器学习模型，由多个输入、输出和隐藏层节点组成。每一层都是由多个神经元组成，每个神经元接收上一层所有神经元的输入信号并生成一组输出值。
3. **特征学习**：深度学习的目的是为了对数据进行有效的表示，因此需要自动发现数据的各种潜在特性。这一过程可以分成两个阶段：第一阶段是通过输入数据提取初级特征；第二阶段是将初级特征组合成更高级的特征。
4. **目标函数（Objective Function）**：在深度学习中，目标函数通常采用损失函数作为优化的目标，用于衡量预测值和真实值的差距。损失函数越小，则预测值与真实值之间的误差就越小。不同的目标函数对应着不同的优化策略，例如分类任务中使用softmax函数作为目标函数，回归任务中可以使用均方误差函数。
5. **反向传播（Backpropagation）**：反向传播是指神经网络计算得到的误差通过各个节点的权重和偏置更新的方式更新参数，使得神经网络在全局参数下降最快。通过反向传播可自动化调整网络参数，从而达到学习效果的优化。
6. **卷积神经网络（CNN）**：卷积神经网络（CNN）是深度学习的一个子集，它运用卷积运算代替一般的线性运算，提取局部感受野特征。CNN可用于图像分析、物体检测、手写字体识别等领域。
7. **循环神经网络（RNN）**：循环神经网络（RNN）是一种特殊的神经网络，它的输入序列数据不仅会被传给网络的隐藏层节点，还会被传递至输出层节点。RNN可用于处理序列数据，如文本、音频、视频等。

文章的后半部分以实践为主，展示了如何利用TensorFlow或PyTorch框架实现深度学习模型，并分享了一些典型应用场景的实现代码。对于想深入了解深度学习的人来说，这是一份宝贵的学习资源。

最后，希望大家多多参与评论和讨论，共同促进深度学习技术的发展！



# 2.背景介绍

## 2.1 深度学习历史回顾

深度学习，是机器学习的一种方法，它运用多层级神经网络（NN）来进行复杂的特征学习，提取出数据中的有效特征信息。其历史可以追溯到1940年代，斯坦福大学教授李沐等人提出了著名的“深层网络（deep nets）”理论。随后，麻省理工学院、斯坦福大学等研究者陆续提出了许多深度学习算法。其中比较著名的有LeNet-5，AlexNet，VGG，GoogLeNet，ResNet等。

## 2.2 深度学习发展现状

深度学习已经成为当今人工智能领域中重要且热门的研究方向之一，尤其是在图像识别、自然语言处理等领域取得了长足的进步。2014年ImageNet大赛，主要竞赛方是微软亚洲研究院、谷歌Google团队、百度baidu研究院、清华大学、中科院自动化所等组织举办的。大赛采用的模型主张以深度学习技术解决图像分类、定位等任务。随后，国内外多家知名公司纷纷布局AI部门，包括腾讯QQ、阿里巴巴、百度、网易等，其目标也是构建一个具有自主学习能力的“人工智能”系统。

目前，深度学习已逐渐成为研究热点，是计算机视觉、自然语言处理、推荐系统、强化学习、医疗健康诊断、金融保险等领域的重要技术。截止2020年1月，中国国家自然科学基金委发布的数据显示，2019年我国深度学习技术的研究投入规模达到16万亿元人民币，超过了2018年全球第一。随着智能设备的普及和应用的广泛化，深度学习的应用范围也变得越来越广阔。


# 3.基本概念术语说明

## 3.1 神经网络

### 3.1.1 概念

神经网络（Neural Network，NN）是一种用来模拟生物神经系统工作方式的机器学习模型，由多个输入、输出和隐藏层节点组成。每一层都是由多个神经元组成，每个神经元接收上一层所有神经元的输入信号并生成一组输出值。NN是一种通过非线性变换与数据拟合的统计模型，具有自学习能力和灵活性。

如下图所示，是一个简单的二维神经网络模型。它由三个输入层、两个隐含层和一个输出层节点构成。输入层包括三个节点，分别代表输入特征x1、x2、x3。隐含层有两个节点，它们的激活函数是sigmoid函数。输出层有一个节点，它的激活函数是softmax函数，用于分类问题。其中，蓝色虚线框内的箭头表示输入层到隐含层的连接权重矩阵，白色虚线框内的箭头表示隐含层到输出层的连接权重矩阵。输入数据x经过输入层、隐含层和输出层后得到相应的输出值y。


### 3.1.2 定义

- 神经元（neuron）：一个神经元由三大基本组成单元：**感受野**（receptive field），**权重**（weight），**阈值**（threshold）。其中，感受野指神经元接受的邻近神经元的输入范围，权重代表着该连接的强度，阈值则代表该神经元的响应水平，决定了神经元是否被激活。
- 层（layer）：层是神经网络中神经元集合，一个层之间存在连接，每个层的输出都会作为下一层的输入。层的数量和大小，决定了神经网络的深度、复杂度、准确性。
- 节点（node）：节点是网络中的基本计算单元，它可以简单理解为神经元的集合。
- 输入层（input layer）：输入层是网络的输入，通常是一组向量，每一维对应一个特征。
- 输出层（output layer）：输出层是网络的输出，通常也是一组向量，每一维对应一个输出结果。
- 隐藏层（hidden layer）：隐藏层是网络的中间层，通常包含多个节点，隐藏层的作用是用来提取特征和学习模型的参数，使得模型的表达能力更强。

## 3.2 反向传播

### 3.2.1 概念

反向传播（Backpropagation，BP）是神经网络计算得到的误差通过各个节点的权重和偏置更新的方式更新参数，使得神经网络在全局参数下降最快。通过反向传播可自动化调整网络参数，从而达到学习效果的优化。

### 3.2.2 定义

反向传播算法可以概括为两步：

1. 误差计算：计算当前输出层节点的误差，即预测值y与真实值t之间的差距。
2. 参数更新：根据误差计算梯度，利用梯度下降算法更新参数。

## 3.3 激活函数

### 3.3.1 概念

激活函数（Activation Function）是NN模型中用于引入非线性因素的函数，它使得神经网络能够更好的学习、拟合数据，并产生较好的模型表达能力。常见的激活函数有Sigmoid函数、Tanh函数、ReLU函数等。

### 3.3.2 Sigmoid函数

Sigmoid函数是一种S型曲线函数，它的表达式为：

$$
\sigma (x)=\frac{1}{1+e^{-x}}
$$

它的图形如下所示：


Sigmoid函数的特点是输出值介于0~1之间，并且对输入变量的增益衰减程度非常敏感。由于它对输入变量的敏感度，Sigmoid函数适合于解决输出介于0~1的连续性问题。

### 3.3.3 Tanh函数

Tanh函数是Sigmoid函数的变种，它的表达式为：

$$
tanh(x)=\frac{\sinh(x)}{\cosh(x)}=\frac{(e^{x}-e^{-x})/(e^{x}+e^{-x})}={(e^{x}-(-e^{-x}))/(e^{x}+(e^{-x})}=\frac{2e^{2x}-1}{2e^{2x}+1}=2\cdot \sigma(2x)-1=2(\frac{1}{1+\exp{-2x}}) -1 =2\cdot \sigma(z)\circ z-\frac{1}{2}
$$

它的图形如下所示：


Tanh函数也叫双曲正切函数，它的输出值域为-1~1，但是对输入变量的增益衰减程度远远低于Sigmoid函数。所以，Tanh函数在实际使用中，常跟其他激活函数结合起来使用。

### 3.3.4 ReLU函数

ReLU函数（Rectified Linear Unit，ReLU）是一种非线性函数，它的表达式为：

$$
\mathrm{ReLU}(x)=max(0,x)
$$

它的图形如下所示：


ReLU函数的特点是当输入值小于0时，输出值等于0，否则等于输入值。由于其只保留正输入值，所以能够避免梯度消失的问题。

## 3.4 梯度下降算法

### 3.4.1 概念

梯度下降算法（Gradient Descent，GD）是一种最基础的迭代优化算法，它通过迭代的方法不断修正模型的参数，使得模型的预测值尽可能接近真实值。梯度下降算法常用于解决参数估计和回归问题。

### 3.4.2 定义

梯度下降算法是通过迭代的形式不断修正模型的参数，使得模型的预测值尽可能接近真实值，直到模型收敛（Convergence）为止。算法的思路是计算模型的梯度，然后按照梯度的反方向移动模型的参数，以期望找到使得损失函数最小化的局部最小值。

梯度下降算法的步骤如下：

1. 初始化模型参数
2. 在输入数据X上计算前向传播
3. 使用损失函数计算模型预测值Y与真实值T之间的误差
4. 对模型参数进行梯度下降调整
5. 返回第2步

## 3.5 均方误差函数

### 3.5.1 概念

均方误差函数（Mean Squared Error，MSE）是监督学习中的常用损失函数，其表达式为：

$$
MSE=\frac{1}{m}\sum_{i=1}^{m}(y_{\hat{i}}-t_{i})^2
$$

### 3.5.2 定义

均方误差函数是描述预测值与真实值之间距离的损失函数。它是一种非负、光滑且一致可导的损失函数，使得模型的预测值更加贴近真实值。

均方误差函数适用于回归问题，比如线性回归。

## 3.6 Softmax函数

### 3.6.1 概念

Softmax函数（Softmax function）是一个归一化的指数函数，它的表达式为：

$$
softmax(x_{i})=\frac{exp(x_{i})}{\sum_{j=1}^{K}exp(x_{j})}
$$

其中，$x_{i}$表示第i个样本的输出值，$K$表示类别数。

### 3.6.2 定义

Softmax函数是用来将输出值转换成类别分布的函数，也就是说，它将输出值映射到0～1之间，并且总和等于1。其目的就是使得模型输出的值落在一个标准化的概率分布上，同时可以输出属于各个类别的概率值。

## 3.7 CNN

### 3.7.1 概念

卷积神经网络（Convolutional Neural Networks，CNN）是一种特定类型的深度学习模型，它使用卷积操作代替一般的线性运算，提取局部感受野特征。CNN可用于图像分析、物体检测、手写字体识别等领域。

### 3.7.2 定义

卷积神经网络就是具有卷积层的深度神经网络。卷积层是指输入数据经过一系列的过滤器处理之后，得到输出数据。过滤器是指卷积核矩阵，它由多个权重和偏置组成，过滤器与输入数据做互相关运算，得到特征图（Feature Map）。特征图包含了输入数据的某些空间上的局部特征。

卷积层能够提取到图像或其他数据的局部特征，并转化为向量形式，用作后面的全连接层或者输出层。所以，卷积神经网络往往比全连接神经网络更适合处理图像这样的复杂数据。

## 3.8 RNN

### 3.8.1 概念

循环神经网络（Recurrent Neural Networks，RNN）是一种特殊的神经网络，它的输入序列数据不仅会被传给网络的隐藏层节点，还会被传递至输出层节点。RNN可用于处理序列数据，如文本、音频、视频等。

### 3.8.2 定义

循环神经网络是一种特殊的神经网络，它的输入序列数据不仅会被传给网络的隐藏层节点，还会被传递至输出层节点。RNN有三种类型：循环网络、门控递归网络（GRU）、长短期记忆网络（LSTM）。循环网络结构是一个单向的链，它的隐藏状态可以反馈给另一个部分进行处理。门控递归网络（GRU）与传统的循环网络相似，但它增加了一个门控机制来控制隐藏状态的更新。LSTM则是一种特殊的RNN，它可以学习长期依赖关系。

# 4.核心算法原理和具体操作步骤以及数学公式讲解

本节将详细介绍深度学习模型的一些原理和具体操作步骤，并用数学公式进行推导和解释。

## 4.1 神经网络基本原理

### 4.1.1 模型表达能力

深度学习模型的关键是模型表达能力，模型表达能力决定了模型的学习能力。深度学习模型在捕获不同特征的同时，还能够通过权重共享和参数共享的方式来进行模型压缩，从而减少模型的参数数量。

### 4.1.2 梯度消失和梯度爆炸

梯度消失和梯度爆炸是深度学习模型容易出现的两种问题。梯度消失是指深度学习模型在反向传播过程中，每一次迭代更新参数的幅度都很小，导致更新步长迅速缩小，最终导致模型无法正确学习。梯度爆炸是指深度学习模型在反向传播过程中，每一次迭代更新参数的幅度都很大，导致更新步长迅速扩大，最终导致模型无法正确学习。

为了解决梯度消失和梯度爆炸的问题，可以尝试使用以下几种方式：

1. 采用Batch Normalization的方法：Batch Normalization是一种技巧，它对网络中的每一个节点的输入进行归一化处理，从而保证网络中的每一层的输入均值为0、方差为1。通过这种方式，可以防止梯度消失或爆炸。
2. 采用梯度裁剪的方法：梯度裁剪是指限制网络的梯度范数，从而防止梯度爆炸。
3. 采用动量法的方法：动量法是一种优化算法，它通过累积之前更新的梯度方向，来帮助当前的更新方向更快的抵达局部极值点。

### 4.1.3 Dropout

Dropout是深度学习模型用来减轻过拟合的一种技术。它通过随机扔掉一部分神经元的输出，从而降低模型的复杂度，避免出现欠拟合问题。

### 4.1.4 稀疏表示

稀疏表示是一种数据表示方法，它把输入信号分成多个子信号，并只保存和学习子信号的权重。稀疏表示能够降低计算量，加快模型训练速度，并能提升模型的表达能力。

### 4.1.5 预训练与微调

预训练和微调是深度学习模型的两种训练方式。预训练是指利用大量未标注的数据，先用监督学习方法训练模型，获得一个初始的预训练模型。微调是指利用微小的标注数据，对预训练模型进行微调，进一步提升模型的性能。

预训练方法有两种：特征提取和网络微调。特征提取方法是指利用大量未标注的数据，训练一个预训练模型，然后使用其提取到的特征进行目标任务的微调。网络微调方法是指利用微小的标注数据，对预训练模型进行微调，通过在多个任务上进行调优，来提升模型的泛化性能。

## 4.2 BP算法

### 4.2.1 概述

BP算法（Back Propagation Algorithm）是一种最基本的神经网络训练算法，它通过反向传播算法来更新模型的参数，使得模型在给定输入数据上的输出结果尽可能接近真实值。

### 4.2.2 误差计算

BP算法的误差计算，主要包括以下几个步骤：

1. 计算网络的输出：首先，通过前向传播算法计算网络的输出值。
2. 计算网络的误差：计算网络输出值与真实值之间的误差。
3. 计算网络的权重更新：计算网络的误差对每个权重的导数，并使用梯度下降算法更新权重。

### 4.2.3 更新规则

BP算法的更新规则为：

$$
w_{ij}^{l} := w_{ij}^{l} + \alpha (\delta_{ij}^l a_{j}^{l-1} + \lambda w_{ij}^{l}), i=1,...,n^{l}, j=1,...,n^{l-1}\\
b_{i}^{l}:= b_{i}^{l} + \alpha \delta_{i}^l
$$

其中，$\alpha$ 为学习率，$(a_{j}^{l-1}, w_{ij}^{l})$ 表示第$l$层的第$i$个节点的上一层节点的输出和权重，$b_{i}^{l}$ 表示第$l$层的第$i$个节点的偏置。

### 4.2.4 可选参数

1. $\alpha$ 学习率：调整学习效率的主要参数，取值一般在0.1~1之间，默认为0.01。
2. $\lambda$ 正则化系数：设置正则化参数，防止模型过拟合，取值一般为0~1之间，默认为0。

## 4.3 CNN

### 4.3.1 概述

CNN是一种特定类型的深度学习模型，它使用卷积操作代替一般的线性运算，提取局部感受野特征。

### 4.3.2 卷积操作

卷积操作是指卷积核与输入数据做互相关运算，得到特征图（Feature Map）。

卷积核与输入数据做互相关运算的结果称为感受野（Receptive Field）。感受野就是卷积核覆盖的周围区域。如果卷积核的尺寸比较小，那么感受野就会比较小，特征图就会比较小；如果卷积核的尺寸比较大，那么感受野就会比较大，特征图就会比较大。

卷积核的大小和感受野的大小一般有关，可以调整卷积核的大小来改变感受野的大小。

### 4.3.3 池化操作

池化操作是指对特征图进行降采样（Pooling）操作，降低特征图的分辨率，提取关键特征。

池化操作有最大池化和平均池化两种。最大池化就是取池化窗口内的最大值，而平均池化就是取池化窗口内的平均值。

池化操作的目的是为了降低特征图的分辨率，从而减少模型的计算量。

### 4.3.4 超参数选择

超参数（Hyperparameter）是指模型训练过程中的参数，其值不能直接影响模型的训练过程，而需要通过训练得到。

超参数一般包括：学习率、正则化系数、批处理大小、神经网络层数、神经元个数、激活函数、优化器、Epoch次数等。

超参数的选择需要通过验证集的评价指标来确定。

## 4.4 RNN

### 4.4.1 概述

RNN是一种特殊的神经网络，它的输入序列数据不仅会被传给网络的隐藏层节点，还会被传递至输出层节点。

### 4.4.2 时间展开

RNN的训练和测试过程需要将序列数据拆分成时间步长。

### 4.4.3 堆栈式RNN

堆栈式RNN（Stacked RNN）是一种深度学习模型，它将多层RNN堆叠在一起，并通过跳跃链接将信息流通从一层传递至另一层。

### 4.4.4 时序注意力机制

时序注意力机制（Sequence Attention Mechanism）是RNN中的一种 attention 技术，它能够帮助模型捕获序列中的依赖关系，并且能够自动的调整模型的复杂度。

时序注意力机制采用多头注意力机制（Multi-Head Attention Mechanism）来解决序列数据的关联性。

### 4.4.5 评估指标

深度学习模型的评估指标，包括精度、召回率、F1-Score、AUC、损失函数等。

精度（Precision）：预测为正的样本中，实际为正的占比。

召回率（Recall）：实际为正的样本中，预测为正的占比。

F1-Score：精确率和召回率的综合得分。

AUC：ROC曲线下的面积，表示模型的预测能力。

损失函数：模型预测的好坏与实际情况之间的差距。

# 5.具体代码实例和解释说明

## 5.1 TensorFlow实现MNIST数字分类任务

### 5.1.1 安装配置

安装配置 Tensorflow，参考官方文档 https://www.tensorflow.org/install 。

下载 MNIST 数据集，执行以下命令：

```python
import tensorflow as tf
from tensorflow import keras

mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()
```

加载 MNIST 数据集，执行以下命令：

```python
print("Train images shape:", train_images.shape)
print("Test images shape:", test_images.shape)
```

打印 MNIST 数据集的形状，执行以下命令：

```python
train_images = train_images / 255.0 # Normalize the input image so that each pixel value ranges from 0 to 1.
test_images = test_images / 255.0   # Normalize the input image so that each pixel value ranges from 0 to 1.
```

数据标准化，执行以下命令：

```python
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])
```

建立模型，执行以下命令：

```python
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
```

编译模型，执行以下命令：

```python
history = model.fit(train_images, train_labels, epochs=10, validation_split=0.1)
```

训练模型，执行以下命令：

```python
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print('\nTest accuracy:', test_acc)
```

评估模型，执行以下命令：

```python
predictions = model.predict(test_images)
```

预测模型，执行以上命令即可完成训练、评估和预测。

### 5.1.2 代码示例

完整的代码示例如下：

```python
import tensorflow as tf
from tensorflow import keras

# Load data
mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Data preprocessing
train_images = train_images / 255.0
test_images = test_images / 255.0

# Build model
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),
    keras.layers.Dense(128, activation='relu'),
    keras.layers.Dense(10, activation='softmax')
])

# Compile and train model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10, validation_split=0.1)

# Evaluate model on test set
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print('\nTest accuracy:', test_acc)

# Make predictions on test set
predictions = model.predict(test_images)
```

## 5.2 PyTorch实现MNIST数字分类任务

### 5.2.1 安装配置

安装配置 Pytorch，参考官方文档 https://pytorch.org/get-started/locally/ 。

下载 MNIST 数据集，执行以下命令：

```python
import torch
import torchvision
import torchvision.transforms as transforms

transform = transforms.Compose(
  [transforms.ToTensor(),
   transforms.Normalize((0.5,), (0.5,))])

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,
                                            shuffle=True, num_workers=2)

testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64,
                                           shuffle=False, num_workers=2)
```

加载 MNIST 数据集，执行以上命令即可。

### 5.2.2 代码示例

完整的代码示例如下：

```python
import torch
import torchvision
import torchvision.transforms as transforms

transform = transforms.Compose(
  [transforms.ToTensor(),
   transforms.Normalize((0.5,), (0.5,))])

trainset = torchvision.datasets.MNIST(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,
                                            shuffle=True, num_workers=2)

testset = torchvision.datasets.MNIST(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=64,
                                           shuffle=False, num_workers=2)

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = self.pool(x)
        x = F.relu(self.conv2(x))
        x = self.pool(x)
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

net = Net()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

for epoch in range(2):  # loop over the dataset multiple times

    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data

        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        # print statistics
        running_loss += loss.item()
        if i % 2000 == 1999:    # print every 2000 mini-batches
            print('[%d, %5d] loss: %.3f' %
                  (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0

print('Finished Training')

PATH = './cifar_net.pth'
torch.save(net.state_dict(), PATH)

dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ',''.join('%5s' % classes[labels[j]] for j in range(4)))

net = Net()
net.load_state_dict(torch.load(PATH))

outputs = net(images)

_, predicted = torch.max(outputs, 1)

print('Predicted: ',''.join('%5s' % classes[predicted[j]]
                              for j in range(4)))
```