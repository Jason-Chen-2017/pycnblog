
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


迁移学习（Transfer Learning）是深度学习领域中一个很热门的话题，在许多任务中都得到了广泛的应用。迁移学习主要用于解决计算机视觉、自然语言处理等领域中存在的问题——当新的数据集上没有足够的训练数据时，可以通过已有的大型训练集上的预训练模型（Pre-trained Model）进行快速的训练，从而有效地利用现有模型的知识提升新的任务性能。在传统的机器学习方法中，一般采用固定结构（比如神经网络），需要事先对数据的特征做出假设；而在迁移学习方法中，可以利用不同但相关的任务进行迁移学习，只用少量数据就可以取得较好的效果。

而本文要探讨的这个话题——跨领域迁移学习（Cross-Domain Transfer Learning），由于涉及的领域非常多元，因此难度相对较高。所谓跨领域，就是指两个不同的领域之间存在信息不对称性。举个例子，如果目标领域是一个自动驾驶系统，那么就需要将图像识别、语音识别等相关技术迁移到该领域，即使数据量很小，也是可以成功的。但是，很多时候，如果直接把图像分类迁移到文本识别领域，可能会遇到困难，因为两者的信息表达方式不同。同样的，如果要将跨行业的产品和服务迁移到另一家公司，也可能面临着巨大的挑战。因此，这是一个具有挑战性的话题。

迁移学习算法有很多，包括分类、回归、聚类等常见的机器学习算法。为了能够更加深入地理解这些算法的实现细节，作者将结合算法流程、关键参数、数学模型和实际代码来阐述这一概念。文章首先会对迁移学习的基本知识和技术流程进行概述。之后，通过多个具体实例，介绍不同类型的问题，并逐一分析其中的关键问题，例如数据划分、超参数调优、模拟退火算法等。最后，作者会着重介绍一种常用的迁移学习算法——注意力机制（Attention Mechanism）及其对应的代码实现，最后给出作者个人的意见和建议。


# 2.核心概念与联系
## 2.1 迁移学习的基本概念和术语
### 2.1.1 迁移学习
迁移学习（Transfer learning）是机器学习的一个重要分支，它研究的是如何利用一个已经训练好的模型，来对其他数据集进行更好地建模。其主要目的是解决两个难题：
* 在源数据集上训练出的模型对目标数据集上效果不佳。
* 没有足够的源数据集或源模型。

比如，手写数字识别模型在MNIST数据集上训练得很好，但是在应用到类似于物体检测、图像分割等新任务的时候，它的表现就会下降。迁移学习就是为了解决这个问题，通过利用已经训练好的模型，利用源数据集的知识来训练目标数据集的模型。这样，在目标数据集上就可以更好的建模。

### 2.1.2 数据划分
在迁移学习中，通常将源数据集分为两个子集：训练集（training set）和测试集（testing set）。训练集用于训练模型，测试集用于评估模型的效果。


如上图所示，训练集和测试集都是源数据集的一部分。训练集用于训练模型的参数，测试集用于评估模型的性能。通常情况下，训练集占总体数据集的80%左右，测试集占剩余的20%。在实际运用中，还可以用交叉验证的方法来划分数据集，保证训练集、测试集的差异性。

### 2.1.3 模型选择
迁移学习通常有两种模型选择策略：
1. 使用预训练模型（Pre-trained model）：通常是基于大规模的源数据集训练出的模型。使用预训练模型可以节省大量的计算资源和时间，而且在一定程度上，预训练模型已经对源数据集中的通用模式有了一定的了解，因此可以帮助我们迁移学习到目标领域。
2. 微调模型（Fine-tuning model）：既然源数据集和目标数据集之间存在较大的差异，那是否可以用源模型的参数来初始化目标模型？通过微调模型，可以适应目标数据集的特点，提高其泛化能力。

### 2.1.4 跨领域迁移学习
所谓跨领域，就是指两个不同的领域之间存在信息不对称性。举个例子，如果目标领域是一个自动驾驶系统，那么就需要将图像识别、语音识别等相关技术迁移到该领域，即使数据量很小，也是可以成功的。但是，很多时候，如果直接把图像分类迁移到文本识别领域，可能会遇到困难，因为两者的信息表达方式不同。同样的，如果要将跨行业的产品和服务迁移到另一家公司，也可能面临着巨大的挑战。

### 2.1.5 迁移学习算法
迁移学习算法又可分为以下四种类型：
1. 深度模型（Deep models）：基于深度神经网络（DNNs）的模型，如AlexNet、VGG、ResNet等。它们对输入的图像数据进行高效的处理，并能够有效地捕捉全局特征。这种模型的参数数量随着深度增加而增长，对于大型数据集来说，它往往需要很大的内存和计算资源。
2. 线性模型（Linear models）：基于线性分类器（logistic regression）或者决策树（decision tree）的模型。这种模型的性能受限于源数据集的维度，无法利用全局信息。
3. 嵌入（Embedding）模型：将源数据集中的特征转换成低维的向量，再进行线性组合，可以达到非线性分类的效果。这种模型具有广泛的应用，可以用于无监督的情形，也被用于推荐系统、文本分析、图像搜索等领域。
4. 层次模型（Hierachical models）：基于树状结构的模型，如多层感知机（MLPs），能够有效地融合不同层级的特征。这些模型通常用于分类任务，可以有效地处理海量数据。

## 2.2 深度迁移学习技术原理
### 2.2.1 AlexNet
AlexNet是迄今为止最具代表性的深度卷积神经网络之一。它由五个卷积层和三个全连接层组成，性能不断提升，被广泛用于图像分类任务。


AlexNet网络由5个模块组成，前四个模块为卷积层，第五个模块为全连接层。每个模块后面紧跟一个池化层，用于减小输出特征图的大小。AlexNet共有八千万个参数。AlexNet通过丢弃法（dropout）来防止过拟合。

### 2.2.2 VGG
VGG网络是深度神经网络的第二代，于2014年被提出。它由许多卷积层和池化层组成，并引入了“块”（block）的概念，允许我们组合多种类型层。


VGG网络在每个块内部，都使用相同的过滤器数目的卷积层，然后接着一个池化层。其中最大池化层保证了每层的输出空间尺寸不变。这样设计的好处是可以保持局部连接，避免了前面的层对后面的层的过度依赖。因此，在测试阶段可以直接跳过池化层。VGG共有大约十几万个参数。

### 2.2.3 ResNet
ResNet网络是深度神经网络的第三代，于2015年提出。它与VGG一样，也使用重复模块（residual module）来构建网络。不同的是，它在残差模块里加入了批量归一化（batch normalization）层。


ResNet相比VGG，网络更深，更宽，并加入了更复杂的结构。网络中的梯度不会消失或爆炸，并且可以使用很大的学习率加速收敛。ResNet共有近百万个参数。

### 2.2.4 迁移学习的应用场景
目前，迁移学习在计算机视觉、自然语言处理等领域已经有很大的应用。典型的应用场景如下：
* 目标领域样本较少：在目标领域数据量较少的情况下，通过迁移学习的方法可以提升模型的准确率。
* 目标领域样本偏差较大：在目标领域数据分布与源领域不同时，通过迁移学习可以较好的适配目标领域的样本。
* 不同领域之间存在信息不对称性：在跨领域迁移学习中，源领域和目标领域之间的信息不对称性导致迁移学习难以应用。

# 3.核心算法原理与代码实践
## 3.1 数据划分
在迁移学习中，通常将源数据集分为两个子集：训练集（training set）和测试集（testing set）。训练集用于训练模型，测试集用于评估模型的效果。训练集占总体数据集的80%左右，测试集占剩余的20%。训练集和测试集之间应该有尽可能大的差异。下面展示了一个典型的数据集划分过程。


## 3.2 Pre-trained Model
迁移学习一般分为预训练模型和微调模型。所谓预训练模型，就是训练一个基于源数据集的模型，再应用到目标数据集。在预训练过程中，模型会学习到源数据集的通用模式，因此可以提取出一些有用的特征，用来初始化目标模型。这样，目标模型就可以快速适应目标领域的数据分布，在目标领域表现良好。


AlexNet是第一个采用预训练模型的成功案例。除了AlexNet外，还有许多经典的预训练模型，如VGG、ResNet、GoogLeNet等。他们共同构成了迁移学习的主流框架。

### Pre-trained Model for Image Classification
我们以ImageNet数据集为例，展示如何使用预训练模型进行图像分类。这里，我们使用预训练模型AlexNet，并使用该模型提取特征，作为目标模型的输入。

```python
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms

# Define the device to use
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using device:', device)

# Load the pre-trained model (AlexNet in this case)
model = models.alexnet(pretrained=True).to(device)

# Freeze all the parameters of the pre-trained model except the last fully connected layer
for param in model.parameters():
    param.requires_grad = False

# Replace the output layer with a new one (in our case we want to classify on 10 classes instead of 1000)
num_ftrs = model.classifier[6].in_features
model.classifier[6] = nn.Linear(num_ftrs, num_classes).to(device)

# Create the DataLoader instances
train_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('/path/to/cifar10', train=True, transform=transforms.Compose([
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])), batch_size=batch_size, shuffle=True)
test_loader = torch.utils.data.DataLoader(
    datasets.CIFAR10('/path/to/cifar10', train=False, transform=transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])), batch_size=batch_size, shuffle=False)

# Train the target model using the pre-trained feature extractor and the CIFAR-10 dataset
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)

epochs = 10
best_acc = 0
for epoch in range(epochs):
    print('\nEpoch {}/{}'.format(epoch+1, epochs))
    print('-' * 10)

    # Each epoch has a training and validation phase
    for phase in ['train', 'val']:
        if phase == 'train':
            model.train()
        else:
            model.eval()

        running_loss = 0.0
        running_corrects = 0

        # Iterate over data.
        for inputs, labels in dataloaders[phase]:
            inputs = inputs.to(device)
            labels = labels.to(device)

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward
            # track history if only in train
            with torch.set_grad_enabled(phase == 'train'):
                outputs = model(inputs)
                _, preds = torch.max(outputs, 1)
                loss = criterion(outputs, labels)

                # backward + optimize only if in training phase
                if phase == 'train':
                    loss.backward()
                    optimizer.step()

            # statistics
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(dataloaders[phase].dataset)
        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)

        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))

        # deep copy the model
        if phase == 'val' and epoch_acc > best_acc:
            best_acc = epoch_acc
            best_model_wts = copy.deepcopy(model.state_dict())

print('Best val Acc: {:4f}'.format(best_acc))

# Save the trained model weights
torch.save(best_model_wts, '/path/to/target_model.pth')
``` 

### Pre-trained Model for Object Detection
下面的示例展示了如何使用预训练模型进行目标检测。这里，我们使用预训练模型Faster R-CNN，并使用其提供的特征，作为目标模型的输入。

```python
import torchvision
import torchvision.models.detection as detection
import torchvision.models.detection.rpn as rpn
import torchvision.transforms as T
from PIL import Image
import matplotlib.pyplot as plt

# Define the device to use
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using device:', device)

# Load the pre-trained model (Faster R-CNN in this case)
model = detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)

# Freeze all the parameters of the pre-trained model except the object classification head
params_to_update = []
for name, param in model.named_parameters():
    if "classification_head" not in name:
        param.requires_grad = False
    else:
        params_to_update.append(param)
        
# Create the DataLoader instance
transform = T.Compose([T.ToTensor()])
images = [Image.open(image_path)]
image_tensors = [transform(i) for i in images]
dataset = torchvision.datasets.ImageFolder("/path/to/your/object_detection_dataset", image_transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=utils.collate_fn)

# Make predictions on each input image
results = []
for image_tensor in image_tensors:
    image_tensor = list(image_tensor.to(device))[0]
    input_list = [{
        "image": image_tensor,
        "boxes": [],
        "labels": [],
        "scores": []}]
    images, targets = model.preprocess_image(input_list)
    features = model.backbone(images.tensors)
    proposals, _ = model.rpn(images, features, targets)
    pred_class_logits, pred_bbox = model.roi_heads._forward_box(features, proposals)
    results.extend(model.roi_heads.box_predictor.predict_probs_boxes((pred_class_logits, pred_bbox)))
    
# Display the predicted bounding boxes and class labels
for img, res in zip(images, results):
    img = np.array(img)
    fig, ax = plt.subplots(figsize=(16,10))
    ax.imshow(img)
    for label, box, score in zip(res['labels'], res['boxes'], res['scores']):
        x0, y0, x1, y1 = map(int, box)
        width, height = abs(x0 - x1), abs(y0 - y1)
        rect = patches.Rectangle((x0, y0), width, height, linewidth=2, edgecolor='b', facecolor='none')
        ax.add_patch(rect)
        plt.text(x0, y0, f"{label}: {score:.3f}", fontsize=14)
    plt.show()
``` 

## 3.3 Fine-tuning Model
微调模型是迁移学习的一种方式。在微调模型中，既保留了源模型的部分权重，同时添加了自己额外的层来适应目标领域的数据分布。这可以有效地利用源模型的知识，提升模型的性能。


上面是一种常用的微调模型形式。它首先冻结了除最后一层外的所有参数，然后再添加自己的层。这样可以把预训练模型的知识利用起来，加快收敛速度。如果在目标领域出现新的类别，可以在尾部添加新的分类层。

### Fine-tune for Image Classification
下面是如何用目标数据集微调AlexNet网络进行图像分类。

```python
import torchvision.models as models
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms

# Define the device to use
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using device:', device)

# Prepare the source data
source_dir = "/path/to/source_dataset/"
source_transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])
source_dataset = datasets.ImageFolder(source_dir, transform=source_transform)
source_loader = torch.utils.data.DataLoader(
    source_dataset, batch_size=batch_size, shuffle=True)

# Define the target data
target_dir = "/path/to/target_dataset/"
target_transform = transforms.Compose([
    transforms.Resize(224),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),
])
target_dataset = datasets.ImageFolder(target_dir, transform=target_transform)
target_loader = torch.utils.data.DataLoader(
    target_dataset, batch_size=batch_size, shuffle=True)

# Initialize the model
model = models.alexnet(pretrained=True).to(device)
num_ftrs = model.classifier[-1].in_features
model.classifier[-1] = nn.Sequential(nn.Dropout(p=0.5),
                                       nn.Linear(num_ftrs, num_classes)).to(device)

# Use the same learning rate for both phases
criterion = nn.CrossEntropyLoss().to(device)
optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),
                       lr=learning_rate)

# Train the model using two loaders
num_epochs = 10
current_iter = 0
for epoch in range(num_epochs):
    print("Epoch:", epoch+1)
    
    # Training phase
    current_iter = train(model, source_loader, optimizer, criterion,
                         current_iter, max_iter=len(source_loader)*num_epochs)
    
    # Validation phase
    test(model, target_loader, criterion)

# Save the trained model weights
torch.save(model.state_dict(), "/path/to/finetuned_model.pth")
``` 

### Fine-tune for Object Detection
下面是如何用目标数据集微调Faster R-CNN进行目标检测。

```python
import torchvision.transforms as T
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Define the device to use
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print('Using device:', device)

# Load the pre-trained model (Faster R-CNN in this case)
model = detection.fasterrcnn_resnet50_fpn(pretrained=True).to(device)

# Freeze the backbone part of the model
params_to_update = []
for name, param in model.named_parameters():
    if "backbone" not in name:
        param.requires_grad = True
    else:
        param.requires_grad = False
        params_to_update.append(param)

# Add a classification head
in_channels = 256  # Use the number of filters from the end of the first block of ResNet
model.roi_heads.box_predictor = FastRCNNPredictor(in_channels, num_classes).to(device)

# Prepare the target data
target_dir = "/path/to/target_dataset/"
target_transform = T.Compose([
    T.ToTensor(),
    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
])
target_dataset = torchvision.datasets.ImageFolder(target_dir, target_transform)
target_loader = torch.utils.data.DataLoader(target_dataset,
                                             batch_size=batch_size,
                                             shuffle=False,
                                             collate_fn=utils.collate_fn)

# Train the model using the pre-trained backbone and custom classifier
num_epochs = 10
num_steps = int(len(target_loader) * num_epochs)

optimizer = torch.optim.SGD(params_to_update, lr=0.005,
                            momentum=0.9, weight_decay=0.0005)
lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,
                                               step_size=3,
                                               gamma=0.1)

for epoch in range(num_epochs):
    print(f"Epoch {epoch}/{num_epochs}")
    epoch_loss = utils.train_one_epoch(model, optimizer,
                                        target_loader, device, epoch,
                                        print_freq=10)
    lr_scheduler.step()
    print(f"Loss: {epoch_loss}")

    coco_evaluator = CocoEvaluator(model, target_loader, device)
    coco_evaluator.evaluate()

# Save the trained model weights
torch.save(model.state_dict(), "/path/to/finetuned_model.pth")
``` 

## 3.4 Attention Mechanism
Attention机制是一种有趣且有效的迁移学习技术。它可以让模型注意到不同输入特征之间的关联关系，而不需要预先定义某些层之间的关联规则。换句话说，Attention机制可以学习到两个输入之间的关系，而不是简单的相乘。Attention机制可以用于图像、文本和视频分析领域，在迁移学习过程中起到至关重要的作用。

Attention机制最早由Vaswani等人在论文《Attention Is All You Need》中提出。论文认为，使用循环神经网络（RNNs）进行序列建模存在信息丢失的问题。因此，他们提出了一种新的架构——Transformer，利用注意力机制来保留序列中丢失的信息。然而，Transformer并不是一个单独的模型，它是一个包含多个子模块的模型，包括Encoder、Decoder、Encoder-Decoder和Self-Attention。


Attention机制可以分为三步：
1. Attention Pooling：通过查询和键值对之间的注意力，输入向量与上下文向量之间建立联系。
2. Scaled Dot-Product Attention：基于注意力权重矩阵计算软性正则化的注意力向量。
3. Softmax：应用softmax函数将注意力权重矩阵归一化，使得所有元素的值都落在0到1之间，表示注意力的强度。

### Cross-domain Textual Translation Using an Attention-based Neural Machine Translation Approach
下面的示例展示了使用注意力机制进行跨领域文本翻译的具体方案。

```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup

class MyDataset(Dataset):
    def __init__(self, texts, tokenizer, max_len):
        self.texts = texts
        self.tokenizer = tokenizer
        self.max_len = max_len
        
    def __getitem__(self, index):
        text = str(self.texts[index]).lower()
        
        encoding = self.tokenizer.encode_plus(
                      text,
                      add_special_tokens=True,
                      max_length=self.max_len,
                      pad_to_max_length=True,
                      return_attention_mask=True,
                      return_token_type_ids=False
                  )
        
        return {
                   'ids': torch.tensor(encoding['input_ids']).long(),
                  'masks': torch.tensor(encoding['attention_mask']).float()
               }
    
    def __len__(self):
        return len(self.texts)
    

class BERTClassifier(nn.Module):
    def __init__(self, n_classes):
        super(BERTClassifier, self).__init__()
        self.bert = BertModel.from_pretrained('bert-base-uncased')
        self.drop = nn.Dropout(p=0.3)
        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)
        
    def forward(self, ids, masks):
        o2 = self.bert(ids, attention_mask=masks)[0]
        out = self.drop(o2)
        return self.out(out[:,0,:])
    
    
def train_epoch(model, loader, optimizer, scheduler, device, n_examples):
    model = model.train()
    
    losses = []
    correct_predictions = 0
    
    for d in loader:
        ids = d["ids"].to(device)
        mask = d["masks"].to(device)
        token_type_ids = None
        targets = d["labels"].to(device)
        
        outputs = model(ids, mask)
        
        loss = loss_fn(outputs, targets)
        
        optimizer.zero_grad()
        loss.backward()
        clip_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()
        
        _, preds = torch.max(outputs, dim=1)
        correct_predictions += torch.sum(preds == targets)
        losses.append(loss.item())
        
    return correct_predictions.double() / n_examples, sum(losses)/len(losses)
    
    
def eval_model(model, loader, device, n_examples):
    model = model.eval()
    
    losses = []
    correct_predictions = 0
    
    with torch.no_grad():
        for d in loader:
            ids = d["ids"].to(device)
            mask = d["masks"].to(device)
            token_type_ids = None
            targets = d["labels"].to(device)
            
            outputs = model(ids, mask)
            
            loss = loss_fn(outputs, targets)
            
            _, preds = torch.max(outputs, dim=1)
            correct_predictions += torch.sum(preds == targets)
            losses.append(loss.item())
            
    return correct_predictions.double() / n_examples, sum(losses)/len(losses)
    

if __name__ == "__main__":
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    
    train_texts = [...]   # Source domain's texts for training
    val_texts = [...]     # Target domain's texts for validation
    test_texts = [...]    # Target domain's texts for testing
    
    MAX_LEN = 128         # Max length for padding
    
    train_dataset = MyDataset(train_texts, tokenizer, MAX_LEN)
    valid_dataset = MyDataset(val_texts, tokenizer, MAX_LEN)
    test_dataset = MyDataset(test_texts, tokenizer, MAX_LEN)
    
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE,
                              shuffle=True, num_workers=4)
    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE,
                              shuffle=False, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,
                             shuffle=False, num_workers=4)
    
    model = BERTClassifier(NUM_CLASSES).to(DEVICE)
    loss_fn = nn.CrossEntropyLoss().to(DEVICE)
    
    EPOCHS = 10          # Number of epochs
    BATCH_SIZE = 32      # Batch size for training
    WEIGHT_DECAY = 0.01  # Weight decay coefficient
    LEARNING_RATE = 2e-5 # Learning rate for Adam optimizer
    
    optimizer = AdamW(model.parameters(), 
                      lr=LEARNING_RATE,
                      weight_decay=WEIGHT_DECAY)
    scheduler = get_linear_schedule_with_warmup(optimizer, 
                                                num_warmup_steps=0,
                                                num_training_steps=EPOCHS)
    
    
    best_accuracy = 0
    
    for epoch in range(EPOCHS):
        print(f"\n Epoch {epoch+1}\n-------------------------------")
        
        train_acc, train_loss = train_epoch(model, train_loader,
                                            optimizer, scheduler, DEVICE,
                                            len(train_texts))
        
        print(f"Train Accuracy: {train_acc}, Train Loss: {train_loss}")
        
        val_acc, val_loss = eval_model(model, valid_loader, DEVICE,
                                       len(val_texts))
                                          
        print(f"Validation Accuracy: {val_acc}, Validation Loss: {val_loss}")
        
        if val_acc > best_accuracy:
            torch.save(model.state_dict(), "saved_weights.pt")
            best_accuracy = val_acc
            
    model.load_state_dict(torch.load("saved_weights.pt"))
    test_acc, _ = eval_model(model, test_loader, DEVICE, len(test_texts))
    print(f"\nTest Accuracy: {test_acc}")
```