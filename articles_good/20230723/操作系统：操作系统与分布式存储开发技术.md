
作者：禅与计算机程序设计艺术                    

# 1.简介
         
操作系统（Operating System，OS）是指管理计算机硬件和软件资源、控制程序执行流、方便用户使用的基础软件服务。由于众多应用系统的普及及计算设备的迅速增长，计算机系统需要运行各种各样的任务，而软件资源不断增加，处理速度也越来越快，因此操作系统必须高度灵活并快速响应用户需求。目前操作系统领域主要分成两个方向——操作系统内核（kernel）和分布式系统。
操作系统内核（Kernel）是指最基础、最重要的系统软件，它对计算机的资源管理和分配进行调控；分布式系统则是在操作系统之上的各种应用层程序，通过网络通信互相协作，实现信息共享和计算分工等功能。通过学习操作系统，可以了解到操作系统的工作机制、任务调度、内存管理、文件系统、存储管理、网络协议栈等内容。另外，对一些分布式系统编程模型的理解也可以帮助理解一些其背后的理论知识。
本文试图通过“操作系统”系列文章，探讨分布式存储技术如何融入操作系统中，并且研究分布式系统相关的常用技术实现，帮助读者更好地理解分布式存储的原理和运作机理。此外，在介绍了分布式存储的原理和系统架构后，还会通过实际案例的分析，展示分布式存储的开发方法及其价值。
# 2.基本概念与术语
## 2.1 操作系统
操作系统（Operating System，OS），是指管理计算机硬件和软件资源、控制程序执行流、方便用户使用的基础软件服务。它包括系统调用接口、进程调度、内存管理、文件系统、设备驱动、网络协议栈等功能模块，为应用程序提供一个简单的操作环境。一般来说，操作系统是一个复杂而庞大的系统，涉及很多方面，包括硬件管理、文件系统管理、进程管理、网络通信、设备驱动等，通过系统调用接口向上层提供丰富的服务。
## 2.2 分布式系统
分布式系统，又称分散系统或网状系统，是指由不同节点组成的计算机系统，彼此之间通过网络连接。分布式系统能够有效地提升系统性能和容错能力，并可用于支持大规模数据处理、科学实验、云计算、数据中心、万物互联等高性能计算、信息处理、服务和安全应用场景。分布式系统的特点是分布性、抽象性、透明性、局部性、一致性和可靠性等。分布式系统的结构通常采用星型、环形、树型、图型等方式。分布式系统常用的通信手段有共享存储器、消息传递、远程过程调用（RPC）、远程函数调用（RMI）等。分布式系统的应用主要有云计算、集群计算、数据库系统、大数据处理、网络存储、自然语言处理、游戏服务器、自动驾驶等。
## 2.3 网络通讯
网络通讯（Networking），是指通过电路交换、无线传输、广播传输、集线器等方式将物理世界的数据、信号传送到另一个地方。网络通讯是分布式系统的基础通信机制，其中大量的数据通过网络传输可以极大地提高信息处理的效率，促进多台计算机的协同工作。在分布式存储中，网络通讯负责数据的存储和检索，网络通信常用的协议有TCP/IP、UDP、HTTP、HTTPS、FTP、NFS、SSH等。
## 2.4 文件系统
文件系统（File system，FS），是指管理计算机的文件的一种组织形式。它组织起来使得文件易于查找、访问和管理。Linux操作系统中的ext4、XFS、NTFS、FAT都是典型的文件系统。分布式存储系统中，文件系统将物理磁盘分块，在逻辑上将分块组织成为一个个文件。
## 2.5 虚拟文件系统
虚拟文件系统（Virtual File System，VFS），是指实现了文件系统的抽象，允许在多个文件系统（比如本地磁盘、网络文件系统等）之间进行透明切换。VFS使得相同的代码可以同时运行在不同的文件系统上，这样就实现了跨平台移植。VFS定义了一套标准接口，应用程序可以通过VFS调用各种文件系统，实现文件操作的统一化。
## 2.6 分布式文件系统
分布式文件系统（Distributed File System，DFS），是指利用多个计算机共同合作的结果，在逻辑上把一个存储在单个文件系统中的文件复制到多个计算机上，实现文件共享和备份。HDFS（Hadoop Distributed File System）是 Hadoop 的默认文件系统，具有高容错性、高可用性和海量数据存储等优点。其数据块大小可以动态调整，适应不断变化的存储需求。Apache Hadoop 和 MapReduce 框架都依赖于 HDFS 来实现高性能的数据处理。
## 2.7 数据节点与元数据节点
数据节点（DataNode）与元数据节点（MetaNode）是分布式文件系统的重要组件。数据节点负责存储文件的原始数据，元数据节点负责维护文件系统的元数据（目录结构、权限信息、文件属性、副本数量等）。分布式文件系统通常存在一个主从模式，只有一个元数据节点，其他数据节点都作为备份。当发生故障时，其他备份节点接管数据，确保系统的高可用性。
## 2.8 客户端与服务器
客户端（Client）与服务器（Server）是分布式存储系统的两种角色，它们分别承担不同的角色。客户端发送请求给服务器，服务器返回响应数据。客户端与服务器之间通过网络通讯进行通信。
## 2.9 块
块（Block），是分布式存储系统的一个基本单位，通常等于磁盘的读写最小单元。在客户端上传输文件之前，先将文件划分成若干个大小相等的块，然后再按需读取这些块的内容。块可以看作是网络中传输的最小单元。块大小的选择对于整个分布式存储系统的整体性能、可靠性、吞吐量等影响很大。
## 2.10 复制因子
复制因子（Replication Factor）是指某个文件被保存至多个数据节点的次数。文件复制可以提高文件数据的可靠性和容错能力，但同时也增加了额外的存储开销。复制因子的选择需要结合文件大小、数据局部性、存储空间利用率、网络带宽等综合因素考虑。
## 2.11 主备份
主备份（Primary-Backup）是分布式系统中常用的一种设计模式，主节点负责接收所有写入请求并将它们同步到备份节点。主备份模式提高系统的可靠性和容错能力，但不能保证数据安全。在主备份模式下，如果主节点发生故障，备份节点可能失去数据的更新。
# 3.分布式存储技术概述
分布式存储技术是指利用计算机网络技术在存储上实现分布式，通过存储节点的分布部署，实现数据共享和存储迁移，以达到最佳存储利用率和服务水平。分布式存储系统通常包括数据节点（DataNode）、元数据节点（MetaNode）和客户端。数据节点就是分布式存储系统中保存数据的节点，它存储文件的原始数据，同时也负责数据的读取、写入和备份。元数据节点就是分布式存储系统中的数据路由表，它记录了文件到数据节点的映射关系，以便根据文件名快速找到数据所在的节点。客户端是对分布式存储系统进行读写操作的终端，它发送请求到元数据节点，并获取相应的数据节点的信息。
分布式存储系统基于以下几个要素构建：
- 分布性：分布式存储系统通过网络技术实现节点间的分布部署，节点间不必关心底层的物理位置，只需要在逻辑上保持数据完整性即可。
- 存储共享：分布式存储系统可以将数据分布到不同的存储节点上，降低单个节点的存储资源限制。同时，数据可以被不同节点共享，在某些情况下可以提升数据可用性。
- 数据迁移：分布式存储系统可以在存储节点间迁移数据，提升系统的可靠性和可用性。
- 一致性：分布式存储系统要求具有强一致性的实现，即所有的修改操作都立刻生效，所有的客户端都能看到相同的数据视图。为了确保数据一致性，分布式存储系统引入了基于状态机的方法，所有数据都由一组副本进行管理，同时通过一定的协议保证副本之间的同步。
# 4.元数据管理与数据编码
## 4.1 元数据管理
元数据管理（Metadata Management）是分布式存储系统的第一道防线。元数据管理的目的是记录文件到数据节点的映射关系，以便根据文件名快速找到数据所在的节点。元数据管理通过两类元数据存储来实现：文件属性存储（FASP）和块索引存储（BIS）。
### 4.1.1 文件属性存储
文件属性存储（File Attribute Storage，FAP）是元数据管理的基础，它记录了文件的名字、大小、创建时间、修改时间、访问时间等重要信息。FAP能够帮助快速定位文件，便于数据查询和迁移，但其最大缺点是占用了存储空间。目前最流行的FAP系统是MySQL。
### 4.1.2 块索引存储
块索引存储（Block Index Storage，BIS）记录了每个数据块所在的数据节点。BIS记录了每个数据块在分布式存储系统中所处的位置，它有助于对数据进行校验和重新分布。BIS可以减少数据丢失风险和维护代价，提高数据的可用性和可靠性。目前较新的分布式存储系统如Ceph和GlusterFS均支持块索引存储。
## 4.2 数据编码
数据编码（Data Encoding）是分布式存储系统中编码的另一个关键部分。数据编码负责对存储的数据进行压缩、加密、编码等预处理，以降低数据传输消耗和网络传输负载。分布式存储系统支持多种数据编码方式，包括无损编码、有损编码、编码混合等。例如，在HDFS中，支持的编码格式有Gzip、Snappy、LZO、BZIP2等。数据编码的选择可以依据数据类型、压缩率、传输效率、存储空间占用、网络带宽等多方面因素。
# 5.分布式数据存储架构
## 5.1 数据分块
分布式存储系统将数据分割成固定大小的块（block）进行管理。块的大小通常与磁盘扇区大小相匹配。数据块大小的选择需要充分考虑数据的分布特性，避免单个数据块过大或者过小导致节点间数据迁移和负载不均衡。例如，在HDFS中，一个数据块通常设置为128MB，这意味着一个HDFS文件被分割成128MB的片段，并存储在集群中的多个节点上。

块的分割并不是绝对的，系统也提供了预分块（Pre-sharding）的方式。预分块是指系统在文件写入前，预先将数据划分成若干个固定大小的块，以减少数据分布不均匀的问题。预分块可以减轻数据倾斜问题的影响。

另外，还可以使用分桶策略对数据进行分类，每个桶对应一个物理设备，然后将数据存储在不同的桶中。这种方式可以更好的满足数据可用性、可靠性和容量规划的要求。

## 5.2 数据分布
数据分布（Data Distribution）是指将数据存储在分布式存储系统中的各个节点上。在数据分布阶段，系统首先根据一定规则将文件划分到不同的节点上。在HDFS中，文件的默认分布方式是基于块分布的。块的大小通常与磁盘扇区大小相匹配。但是，HDFS也支持其他的分布方案，如字节范围（Byte Range）分布、键值对分布等。

在数据分布过程中，系统还要完成以下任务：
1. 将数据均匀分布到各个数据节点上；
2. 在数据节点之间采用负载均衡的方式，确保数据节点的负载尽量均衡；
3. 对数据进行编码，减少数据传输消耗和网络传输负载。

## 5.3 数据备份
数据备份（Data Backup）是分布式存储系统中非常重要的一环。由于分布式存储系统通常采用主从模式，所有节点都负责存储相同的数据，所以在出现单点故障时，整个分布式存储系统无法正常工作。为了确保数据安全，分布式存储系统需要引入数据备份机制，将数据多份拷贝保存，以提高系统的可用性。

数据备份主要由以下几类方式实现：
1. 主备份模式：将数据分别存储在主节点和备份节点上，当主节点出现故障时，备份节点自动接管数据。
2. 异步复制：将数据异步复制到多个节点上，采用异步复制可以提高数据的可靠性。
3. 顺序写：为了保证数据一致性，系统通常采用基于状态机的方法，所有数据都由一组副本进行管理。为了保证副本之间的同步，系统引入了基于日志的复制方式，所有的副本都通过日志记录修改操作，并且所有副本都会按照日志顺序执行修改操作。

## 5.4 数据容量规划
数据容量规划（Capacity Planning）是指确定存储系统中各个数据节点的最大存储容量和数据迁移计划。数据容量规划需要根据分布式存储系统的特点、用户的存储需求、存储设备的可用容量和业务持续发展情况等因素，制定出合理的存储配置方案。

数据容量规划可以分为以下几个步骤：
1. 根据系统的功能特性、数据访问模式和数据生命周期，确定合适的数据分块大小。
2. 根据磁盘的大小、网络带宽、节点资源等因素，确定存储系统的初始容量。
3. 根据当前的存储节点数、数据分布、访问模式和容量规划的历史数据等，确定数据节点的增加、删除、迁移计划，以适应当前业务的发展。

## 5.5 动态数据迁移
动态数据迁移（Dynamic Data Migration）是分布式存储系统中重要的组成部分。动态数据迁移能够根据存储节点的负载，实时地将数据迁移到不同的数据节点上，提高数据可用性。

动态数据迁移的过程如下：
1. 当数据块的大小或副本数量发生变化时，需要更新元数据信息。
2. 当存储节点发生故障时，系统将尝试将其上的块迁移到其他节点上。
3. 当数据复制因子增加或减少时，需要更新元数据信息，并完成数据重新分布。

动态数据迁移有助于提高数据可用性、节省存储成本。

# 6.存储系统API
分布式存储系统的API（Application Programming Interface，API）是供客户端程序调用的接口。客户端程序通过API向分布式存储系统发送请求命令，并获得对应的处理结果。分布式存储系统中支持的API有RESTful API、Thrift API、gRPC API等。

在分布式存储系统中，客户端和服务器端通过以下方式进行通信：
- 请求/响应模式：客户端向服务器端发送请求，等待服务器端回复结果。
- 主动推送模式：服务器端主动通知客户端新的数据更新。
- 事件通知模式：服务器端向客户端推送事件，包括数据变更通知、警告信息等。

# 7.编程模型
分布式存储系统的编程模型是指系统的逻辑组织方式，以及系统中元素的调用顺序。

编程模型的选择，往往要结合应用场景和系统特点，比如是否有状态的服务、集群规模、数据可靠性、访问模式、事务处理等。下面是常见的分布式存储系统的编程模型。

## 7.1 Master-Slave模式
Master-Slave模式是分布式存储系统中的一种常见的编程模型。Master-Slave模式下，一个Master节点负责管理集群，负责调度任务和监控集群的健康状态。Slave节点负责处理客户端的请求，它从Master节点获取元数据信息并缓存起来，并根据请求执行相应的操作。

Master-Slave模式下的典型应用场景是数据备份和高可用的集群服务。例如，HBase、MongoDB等都属于Master-Slave模式。Master节点主要负责元数据管理和集群管理，如分配数据块到不同节点、监控节点健康状态、故障转移等；Slave节点则负责数据查询、数据写入、数据备份等。

Master-Slave模式下，Master节点拥有比较重要的元数据信息，包括数据分布、数据块的大小、副本数量等，并且客户端不会直接与Slave节点通信，而是与Master节点通信，Master节点将结果返回给客户端。因此，Master节点通常会部署在单独的物理机器上，以保证它的高可用性。

## 7.2 Ring-All模式
Ring-All模式也是一种常见的分布式存储系统编程模型。Ring-All模式下，集群节点以环形的方式分布在不同的机器上。所有节点都可以互相访问，任意一个节点都可以根据需要读写集群中的数据。

Ring-All模式的典型应用场景是分布式文件系统、分布式数据库和分布式消息队列。

Ring-All模式下的节点分布，使得各个节点之间的通信和数据的分布更加均匀。这种模式能够在一定程度上解决数据倾斜的问题。Ring-All模式的优势在于简单、部署容易、扩展方便。

## 7.3 All-to-all模式
All-to-all模式，又称Fully-connected模式，是一种非常简单的分布式存储系统编程模型。All-to-all模式下，每个节点都直接与所有其他节点通信。

All-to-all模式的典型应用场景是多主多从模式的集群服务。例如，Cassandra、Hadoop、Kafka等。All-to-all模式的优点是部署简单，容错率高，适合部署在小型集群上。但是，All-to-all模式的性能不足，无法满足海量数据处理的需求。

## 7.4 Peer-to-Peer模式
Peer-to-Peer模式是指在分布式存储系统中，所有节点可以相互访问。

Peer-to-Peer模式的典型应用场景是P2P文件共享系统、P2P下载工具、P2P聊天系统、分布式视频播放系统等。

## 7.5 Hybrid模式
Hybrid模式是一种结合了Ring-All模式和Master-Slave模式的分布式存储系统编程模型。

Hybrid模式的典型应用场景是BitTorrent协议。BitTorrent协议的特点在于使用环形拓扑结构，让数据块分布更加均匀，降低单点故障的风险。同时，它采用Master-Slave模式来管理节点的元数据信息，并通过DHT（Distributed Hash Table）来定位目标节点。

# 8.案例分析：基于Hadoop的分布式文件系统HDFS实践
## 8.1 前言
在本章节，我将以“基于Hadoop的分布式文件系统HDFS实践”为题，详细阐述HDFS的原理、架构、优化建议、集群搭建及案例分析。本篇文章的内容主要面向初级级读者，欢迎有经验的用户阅读，对Hadoop、HDFS感兴趣的朋友也可以看一下，可以提供参考。
## 8.2 概述
HDFS（Hadoop Distributed File System）是一个开源的分布式文件系统，是一个全托管、高可靠、可伸缩的文件系统，设计目标就是具有高容错性和高可用性。HDFS兼容POSIX文件系统接口，并能够提供高吞吐量的数据访问，通过高度的容错能力和冗余机制，在商用环境中得到了广泛的应用。HDFS是一个超大文件存储系统，其文件以块（Block）为基本单位进行分布式存放。HDFS通过高度的容错能力和数据分布均匀性，能支撑每秒数十亿的 PB 级数据访问。HDFS的特点是高容错、高吞吐量、高可用性、横向扩展性。
## 8.3 HDFS的原理和架构
HDFS由NameNode和DataNode组成。NameNode主要负责管理文件系统名称空间，它是一个 master 服务器，用于管理文件系统的命名空间，以及客户端对文件的读写请求。NameNode维护文件系统的树状结构，树中每个节点表示一个目录或文件。每个文件都有一个唯一的路径名，路径名通过目录名和文件名来标识一个文件。

NameNode在内存中存储整个文件系统的名称空间，包括树状结构和文件以及块的映射信息。为了实现快速的路径名解析，NameNode会缓存文件和目录的位置信息。文件系统中所有的文件数据以块（Block）为基本单位进行分布式存放。每一个块大小都可以设置，默认为 128M。

DataNode主要负责存储文件数据。每个 DataNode 是一个 slave 服务器，负责存储文件系统的分片（Chunk）数据。一个 DataNode 可以同时服务多个块，它负责读写这些块。数据块以独立的文件形式存储在 DataNode 中，并且每个文件只能保存在一个 DataNode 上。

HDFS 的架构如图 1 所示。NameNode 是主导者，维护文件系统的树状结构，并负责处理客户端读写请求；DataNode 是工作者，存储文件系统的分片数据，并接收 NameNode 的指令。HDFS 使用 Java 开发，并提供了 Java API 以便客户端应用调用。HDFS 通过 Master-Slaves 架构实现数据备份、高可用性和扩展性。
![image](https://note.youdao.com/yws/public/resource/cf0f3c9a0ba3d8fc13b2d8ccaaedbbca/xmlnote/WEBRESOURCEe806faff6cfbf817c82fe1e489d3b0b2)
## 8.4 HDFS的优化建议
### 8.4.1 设置合适的 BlockSize 和 Replication
在 HDFS 配置中，BlockSize 和 Replication 值设置的不合适，会影响 HDFS 的读写效率和性能。

 blockSize 表示 HDFS 中的块大小，单位为 MB。假设 BlockSize 为 128M，那么表示创建一个 128M 的文件，最多可以存储 128 个 128KB 的数据。HDFS 默认的 BlockSize 为 128M。

Replication 表示 HDFS 中文件副本数量。比如，设定文件副本数为 3，表示在一个数据结点出现故障时，还有两个副本继续提供服务。

建议设置合适的值，以便最大限度地提高数据存储的容量、访问效率和性能。

### 8.4.2 压缩文件
HDFS 支持压缩文件。

压缩文件可以减少磁盘 I/O，降低网络传输压力。

建议开启压缩功能。

### 8.4.3 HDFS 的垃圾回收机制
HDFS 中的垃圾回收机制用于回收过期或冗余的文件块。

在 HDFS 配置中，可以设置参数 `dfs.namenode.gc-interval`，表示垃圾回收的间隔时间。

建议设置短的时间间隔，比如 30 分钟一次。

### 8.4.4 HDFS 的数据备份
HDFS 提供了数据备份机制，可以实现数据的自动备份和故障转移。

建议开启数据备份机制，将 HDFS 的数据副本部署在不同主机上，提高系统的可靠性和可用性。

### 8.4.5 评估 HDFS 的性能
评估 HDFS 的性能可以通过 jstat 命令查看，该命令可以显示 JVM 的性能指标，包括 CPU、内存、堆外内存等。

通过 fsck 命令检查 HDFS 文件系统的完整性，可以发现 HDFS 的文件块损坏。

HDFS 的读写性能受限于网络带宽，因此需要调整网络配置参数，优化网络。

建议使用 Hadoop 插件和工具进行性能测试。

## 8.5 Hadoop 集群的搭建
HDFS 是一个分布式文件系统，因此，要部署一个 HDFS 集群，首先需要准备好一组 Hadoop 集群节点，包括 NameNode 和 DataNode。

下面以 CentOS 7 操作系统为例，演示如何部署 Hadoop 集群。

### 8.5.1 安装 JDK
首先安装 JDK，版本为 1.8 或以上。

```bash
sudo yum install -y java-1.8*
```

验证 JDK 是否安装成功：

```bash
java -version
```

输出示例：

```bash
openjdk version "1.8.0_181"
OpenJDK Runtime Environment (build 1.8.0_181-b13)
OpenJDK 64-Bit Server VM (build 25.181-b13, mixed mode)
```

### 8.5.2 安装 Hadoop
安装 Hadoop 时，先安装 mvn（Apache Maven）：

```bash
sudo wget http://mirror.bit.edu.cn/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz
sudo tar xzf apache-maven-3.6.3-bin.tar.gz -C /opt/
sudo ln -s /opt/apache-maven-3.6.3/bin/mvn /usr/local/bin/mvn
```

然后安装 Hadoop：

```bash
sudo rpm -ivh hadoop-3.2.0-cdh6.1.0.rpm --force # 根据 Hadoop 版本号进行相应更改
```

验证 Hadoop 是否安装成功：

```bash
hadoop version
```

输出示例：

```bash
Hadoop 3.2.0
Subversion https://github.com/apache/hadoop.git - r33493905da8fbdc78b29d38f9d0de5a68f727485; compiled by 'jenkins' on 2020-04-02T12:18Z
Compiled by jenkins on 2020-04-02T12:18Z
From source with checksum efdcf200d5a5df0d5425ec181a56a941
This command was run using /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/jre/bin/java
```

### 8.5.3 配置 Hadoop
编辑配置文件 `/etc/hadoop/core-site.xml`：

```xml
<configuration>
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://localhost:9000</value>
  </property>
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/data/tmp</value>
  </property>
</configuration>
```

- `fs.defaultFS`: 指定 HDFS 的默认文件系统，这里指定为本地主机的 `9000` 端口。
- `hadoop.tmp.dir`: 指定 Hadoop 临时文件目录，这里指定为 `/data/tmp`。

编辑配置文件 `/etc/hadoop/hdfs-site.xml`：

```xml
<configuration>
  <property>
    <name>dfs.replication</name>
    <value>1</value>
  </property>
  <property>
    <name>dfs.permissions</name>
    <value>false</value>
  </property>
  <property>
    <name>dfs.namenode.name.dir</name>
    <value>/data/namenode</value>
  </property>
  <property>
    <name>dfs.datanode.data.dir</name>
    <value>/data/datanode</value>
  </property>
</configuration>
```

- `dfs.replication`: 指定 HDFS 中文件的副本数量，这里指定为 `1`。
- `dfs.permissions`: 指定是否启用 HDFS 的权限机制，这里指定为 `false`。
- `dfs.namenode.name.dir`: 指定 NameNode 的存储目录，这里指定为 `/data/namenode`。
- `dfs.datanode.data.dir`: 指定 DataNode 的存储目录，这里指定为 `/data/datanode`。

启动 Hadoop 服务：

```bash
sudo systemctl start hadoop-hdfs-namenode hadoop-hdfs-datanode
```

### 8.5.4 测试 HDFS
格式化 HDFS：

```bash
hdfs namenode -format
```

运行 HDFS 的 Web UI：

```bash
http://<any hostname>:50070/
```

运行结果如图 2 所示。
![image](https://note.youdao.com/yws/public/resource/cf0f3c9a0ba3d8fc13b2d8ccaaedbbca/xmlnote/WEBRESOURCE6eaabbfbcfc7561d590eb88bece9c6cb?ynotemdtimestamp=1588508813531)

图 2 Hadoop 集群的 Web UI。

