
作者：禅与计算机程序设计艺术                    

# 1.简介
  

在计算机科学的各个领域中，数据库系统是最重要和应用最广泛的系统。从企业级到互联网金融、政务建设、电子商务等各行各业都需要数据库系统进行数据的存储、管理、分析等一系列的功能。

作为一个深受众多IT从业者青睐的方向，数据库系统的设计对于任何公司或者组织来说都是至关重要的技能之一。对于中小型公司而言，尤其是信息化程度较低或没有历史数据库系统经验的公司，选择一个合适的数据库系统是非常关键的一环。如何才能充分发挥数据库系统的优势，优化数据库系统结构并提高数据库系统的性能是每一个IT从业人员都应该考虑的问题。

本篇文章基于作者自身的一些经验，将数据库系统的设计理论总结成系列的文章，并配以相应的代码实现和实例分析。希望能够帮助读者进一步理解数据库系统的设计原理以及实际应用。

# 2.数据库系统概述
## 2.1 数据模型
数据库系统的核心就是数据模型。数据模型定义了数据库中的数据对象的结构和关系，并确定这些对象之间的联系。数据库系统的选择取决于用户需求、应用场景以及组织结构。一般情况下，数据库系统可以分为三种数据模型：层次模型、网状模型和关系模型。

### 2.1.1 层次模型（Hierarchial Model）
层次模型是一个树形的数据模型，它将数据按照它们所处的上下级关系组织起来。这种模型通常用于组织关系复杂、层次繁复、分类密集的复杂系统。层次模型包括实体、属性、分支和集合。每个节点表示一个实体，可以拥有零个或多个属性；父节点和子节点之间存在一条唯一的联系；节点也可以成为分支或集合，这两种类型的节点均可具有层次结构。

层次模型的示例如下图所示：


### 2.1.2 网状模型（Network Model）
网状模型是一个网络拓扑结构的数据模型，它将数据存放在一个动态的、不断变化的网络中。这种模型由结点、边缘、顶点、属性组成，每个结点代表一个事物，通过边缘连接着不同的结点，顶点则代表整个网络。网状模型能够有效地表示复杂的多对多的关联关系。

网状模型的示例如下图所示：


### 2.1.3 关系模型（Relational Model）
关系模型是一个表格形式的数据模型，它把所有数据按一定模式存放于关系表中。这种模型建立在关系代数的基础上，属于一种真正的数学计算方法。关系模型包括关系变量和关系常量，其中关系变量指某种实体类型或某类事物的集合，而关系常量则是表示某个关系属性的值的符号表达式。关系模型的数据可以方便地被分解、变换、组合，适合处理复杂的多对多的关联关系。

关系模型的示例如下图所示：


## 2.2 事务处理
事务（Transaction）是一个不可分割的工作单位，其中的操作要么都做，要么都不做。事务处理是管理数据、确保数据一致性的过程，通过确保一个事务中的所有操作成功完成，才会提交该事务，否则将回滚事务，使得数据库恢复到事务前的状态。

事务处理过程包括事务的四个阶段：

1. 准备(Prepare)：事务开始时，执行该阶段，此时数据库系统会检查是否满足事务的隔离级别要求，如果满足要求，则分配资源，并且开始执行事务的更新操作；
2. 执行(Execute)：事务的执行阶段，此时事务的操作将在资源上进行，当所有的操作都执行完成后，进入第3阶段；
3. 提交(Commit)：事务完成之后，执行该阶段，完成事务的提交；
4. 中止(Abort)：如果事务因为某种原因失败了，则会执行该阶段，对已分配的资源进行释放，并且回滚数据修改。

## 2.3 并发控制
并发控制是为了防止多个事务同时访问同一资源而采用的手段。并发控制机制是通过识别事务之间的冲突并采取适当的措施来管理数据的访问。主要的方法包括封锁、时间戳、乐观并发控制和悲观并发控制等。

### 2.3.1 封锁（Locking）
封锁是一种基于数据项级别的共享锁和排他锁的机制。共享锁允许多个事务同时读取数据项，但不允许它们修改数据项；排他锁则是独占锁，一次只能有一个事务对数据项进行写入，直到事务释放锁。封锁可以防止事务读写数据项时的错误产生，并保证数据的完整性。

### 2.3.2 时间戳（Timestamps）
时间戳是一种基于事务级别的并发控制策略。在这个策略下，数据库维护一个全局的时间戳，每当一个事务开始运行时，都会向数据库中写入自己的事务ID和当前时间戳。如果一个事务想要读取一个数据项，首先向数据库查询自己和其他事务的最新事务ID及时间戳，然后根据规则判断当前事务是否能够读取这个数据项，即判断自己的事务ID是否在其他事务的最新事务ID列表中，且自己的时间戳是否在其他事务中比自己更新的那个时间戳更晚。

### 2.3.3 悲观并发控制（Pessimistic Concurrency Control）
悲观并发控制也称为两阶段锁协议，它认为一个事务对数据项的读取和修改应当在开始之前加上共享锁和排他锁，从而阻止其他事务的写入，直到事务结束。由于这种策略需要对数据项进行加锁，因此可能导致其它操作的延迟。

### 2.3.4 乐观并发控制（Optimistic Concurrency Control）
乐观并发控制则不同，它认为并不是每个事务都需要加锁。相反，只在必要时对数据项加锁，以保证数据完整性。当一个事务读取数据项时，不需要再去请求锁。但是如果两个事务试图同时修改同一数据项，那么只有其中一个事务的提交成功，另外一个事务的提交就会失败，这时可以通过重试的方式解决冲突。

## 2.4 查询语言
查询语言是用来从数据库中检索数据的语言。SQL是最常用的查询语言，它支持查询、更新、删除、插入等操作。其命令包括SELECT、INSERT、UPDATE、DELETE、CREATE TABLE、ALTER TABLE、DROP TABLE、COMMIT、ROLLBACK等。

# 3.数据库设计理论
## 3.1 概念
数据库设计是指对数据模型、数据库结构及数据项之间的逻辑关系进行设计。数据库设计主要包括数据字典的制作、实体-联系模型的设计、关系模型的设计、数据库性能调优、数据库的安全性和完整性的保证。

## 3.2 数据字典
数据字典是关于数据库中各种数据对象的信息汇总，记录了数据对象名称、标识码、数据类型、描述、创建时间、最后修改时间、用户及责任人、长度及精度等详细信息。数据字典的目的是提供数据模型的文档化。它主要包括以下几个方面：

1. 数据对象清单：数据字典中列出了所有的数据库对象，包括表、视图、索引等；
2. 对象描述：数据字典中详细记录了每个数据库对象，如表的字段名、数据类型、描述、是否为空、默认值等；
3. 使用限制：数据字典中给出了不同用户对数据库对象的权限控制，比如管理员、普通用户、访客等；
4. 依赖关系：数据字典中显示了数据库对象的依赖关系，如表依赖于主键、外键等；
5. 约束条件：数据字典中给出了数据库对象的约束条件，比如唯一约束、非空约束、默认值约束等。

## 3.3 ER模型
实体-联系模型（Entity-Relationship model，简称ER模型），是一种结构化的数据模型，主要用来描述现实世界中的实体以及实体间的联系。它可以用矩形框表示实体、椭圆形表示实体属性、菱形表示实体间的联系，并用线条将实体和实体属性联系起来。实体-联系模型的特点是简单、易于理解、直观、明确，因而应用十分广泛。

## 3.4 关系模型
关系模型（Relational Model）是一种结构化的数据模型，是在数据库领域内较流行的一种数据模型。它用二维表格的形式来表示数据之间的关系，每张表格都包含若干列（称为属性、Attribute）以及若干行（称为记录、Record）。关系模型与层次模型、网状模型、实体-联系模型之间的区别在于，关系模型只关心数据项之间的逻辑关系，而不关注数据的物理结构。关系模型的优点是灵活、易于理解、方便存储和修改，缺点是对空间利用率不够高。

关系模型包括如下几个方面：

1. 属性：关系模型中，每个属性对应于表格中的一个列。属性主要分为三种类型：主键（Primary Key）、外键（Foreign Key）、候选键（Candidate Key）。主键是每张表格的核心属性，每个记录都有一个主键值。外键是指向另一张表格的主键，它描述了两个表之间的一对多的关系。候选键是指两个或多个属性共同组成的组合键，它不能被直接定义为主键，但可以作为主键生成器。

2. 实体集：实体集（Entity Set）是指一类相关记录的集合，实体集有固定的结构。例如，客户实体集可以包含所有具有相同客户编号的所有客户记录。实体集又可以划分为二元实体集、多元实体集、超多元实体集。二元实体集仅包含两个属性，多元实体集包含三个以上属性，超多元实体集包含五个以上属性。

3. 关系：关系（Relation）是指两个实体集之间的联系。在关系模型中，关系表示为一个三元组，包括两个实体集、连接的属性、连接方式。关系类型有一对一、一对多、多对多。一对一关系就是两个实体集之间只有一个连接，比如，一个订单和一个顾客。一对多关系是指一个实体集和另一个实体集的关系，比如，一个订单和一组商品，一个客户和一组订单。多对多关系是指两个实体集之间存在多条连接，比如，一个学生和一组老师。

4. 函数依赖：函数依赖（Functional Dependency）是指两个属性之间的关系，它可以看作是一条属性路径上的依赖关系。一个属性的集合与另一个属性的集合构成了一个函数依赖，函数依赖只有在这些属性中才有意义。例如，教师编号与课程编号之间的函数依赖表示每门课只能由一位老师授课。

5. 分解规则：分解规则（Decomposition Rule）是指多个属性之间存在的一种隐含关系，它可以用来简化关系模型。例如，一个订单有很多项商品，可以建立一个订单项的关系模型，其中订单号作为主键，商品号和数量作为外键，商品价格作为属性。分解规则的好处是可以减少关系模型的复杂度。

## 3.5 数据库性能调优
数据库性能调优是指通过调整数据库配置参数，增加硬件资源、优化数据库表结构、提高数据库的查询效率、减少磁盘IO等方式，提升数据库的整体性能。一般来说，数据库性能调优包括下面几方面：

1. 数据存储结构：数据的存储结构决定了数据库查询速度，如何选择合适的数据存储结构就显得尤为重要。常用的有B+树、Hash、堆文件、 LSM树等。
2. 索引：索引是数据库系统快速找到数据的有效工具，一般通过关键字定位记录。索引的建立需要耗费大量时间，所以建议索引尽量细致，不要太多。
3. SQL语句优化：SQL语句的优化对数据库的查询性能影响很大，建议通过EXPLAIN命令来查看优化效果。
4. 缓存：缓存是提升数据库查询速度的有效手段，系统缓存、应用程序缓存、数据库缓存均可。
5. 主从复制：主从复制是数据库集群的常用部署模式，通过主从复制可以实现数据备份、负载均衡、容灾恢复等功能。

## 3.6 数据库的安全性和完整性保证
数据库的安全性是指对数据库的读写权限进行管理，避免不法分子的破坏、泄露、恶意攻击。数据库的完整性是指对数据库中数据的正确性进行检测，防止数据被破坏或遗漏。一般来说，数据库的安全性和完整性保证包括下面几方面：

1. 用户权限管理：数据库的用户权限管理是决定谁有权对数据库进行读写操作的基础。
2. 审计日志：审计日志（Audit Log）是记录数据库活动的日志文件。审计日志可以帮助管理员追踪用户对数据库的访问行为。
3. 密码加密：数据库用户的密码需要加密保存，不能明文存储。
4. 防火墙：防火墙是保护数据库免受攻击的一种措施，它过滤不法分子的入侵，过滤掉不受信任的IP地址和端口。
5. 数据备份：数据备份是对数据库进行持续维护的关键环节，确保数据库的正常运行和数据的安全。定期备份可以保障数据安全，防止灾难性损失。

# 4.代码实现
## 4.1 B+树
B+树是一种平衡查找树，它具有以下特性：

1. 每个节点可以拥有多个孩子，即有多路查找，叶子节点所在层也有指针；
2. 所有的叶子节点都在同一层，即叶子节点之间无指针；
3. 有序性：左子树的所有节点的值均小于根节点的值，右子树的所有节点的值均大于根节点的值；
4. 完全性：除了根节点和最底层外，其他节点都有足够的元素；
5. 所有中间节点都有一个指针指向最接近它的两个孩子节点；
6. 每个节点的指针均分左右子树的平均元素个数。

下面我们来实现一个B+树数据结构：

```python
class Node:
    def __init__(self):
        self.keys = [] # keys for this node's children (only leaf nodes have values)
        self.children = [] # pointers to child nodes

    def search(self, key):
        """Search for a specific value in the tree."""
        i = 0
        while i < len(self.keys) and key > self.keys[i]:
            i += 1

        if i < len(self.keys) and key == self.keys[i]:
            return True

        if not self.is_leaf():
            return self.children[i].search(key)

        return False

    def insert(self, key):
        """Insert a new value into the correct position within the tree."""
        i = 0
        while i < len(self.keys) and key > self.keys[i]:
            i += 1

        if i < len(self.keys) and key == self.keys[i]:
            print("Value already exists")
            return

        self.keys.insert(i, key)

        if self.is_full() or self.has_duplicate_child():
            split_index = self.get_split_index()
            new_node = Node()

            if self.is_root():
                left_child = self

                root = Node()
                root.keys = [left_child.keys[split_index]]
                root.children = [new_node]

                right_child = Node()
                right_child.keys = left_child.keys[split_index + 1:] + self.keys
                right_child.children = self.children[split_index + 1:] + [right_child]

                root.children.append(left_child)
                root.children.append(right_child)

                return root

            else:
                parent = self.parent

                left_sibling = None
                j = -1

                while j < parent.num_keys()-1 and parent.keys[j+1] <= key:
                    left_sibling = parent.children[j+1]
                    j += 1

                if left_sibling is not None and left_sibling.has_space():
                    left_sibling.insert(key)
                    return self.merge()

                elif j >= 0 and parent.children[j+1].has_space():
                    k = i

                    while k > split_index:
                        del parent.keys[k]

                        if parent.is_leaf():
                            del parent.values[k]
                        else:
                            del parent.children[k]

                        k -= 1

                    parent.children[j+1].insert(key)
                    return self.merge()

                else:
                    new_node = Node()
                    parent.keys.insert(j+1, new_node.keys[-1])
                    parent.children.insert(j+1, new_node)
                    return parent.merge()

        else:
            self.update_parents()


    def get_split_index(self):
        midpoint = self.max_items//2
        min_items = self.min_items
        max_items = self.max_items

        if midpoint < min_items:
            return min_items

        if midpoint > max_items:
            return max_items

        diff = float('inf')

        index = -1
        candidate = -1

        for i in range(midpoint, min(-1, -len(self.keys))+1, -1):
            temp = abs((self.max_items + i)//2 - i)

            if temp < diff:
                diff = temp
                index = i

        return index

    def merge(self):
        """Merge two sibling nodes together."""
        if self.parent is None:
            raise Exception("Cannot merge root node.")

        parent = self.parent
        sib_index = parent.find_sib_index(self)

        neighbor = parent.get_neighbor(sib_index)
        num_keys = sum([len(n.keys)+1 for n in [self, neighbor]])

        # Merge the current node with its neighbor at the middle index.
        merged = Node()
        merged.keys = self.keys[:neighbor.min_items//2] + neighbor.keys[neighbor.min_items//2:]
        merged.children = self.children[:neighbor.min_items//2] + neighbor.children[neighbor.min_items//2:]

        # Update all affected parents' keys & children lists.
        cur = self
        while cur!= parent:
            cur_index = parent.find_child_index(cur)

            prev_size = len(parent.keys)-num_keys
            parent.keys = parent.keys[:cur_index+1] + [merged.keys[-1]+1]*num_keys + parent.keys[cur_index+1:]
            parent.children = parent.children[:cur_index+1] + [merged]*num_keys + parent.children[cur_index+1:]
            parent = parent.parent

        # Delete the old nodes from their respective positions in the tree.
        if sib_index >= 0:
            sib = parent.children[sib_index]
            if sib.keys[0] < merged.keys[0]:
                parent.keys.pop(sib_index)
                parent.children.pop(sib_index)
            else:
                for key in reversed(merged.keys[:-1]):
                    if sib.search(key):
                        break

                parent.keys[sib_index] = key
                sib.delete(key)

        for c in merged.children:
            c.parent = parent

        if parent.keys[0] > merged.keys[-1]:
            parent.keys = [parent.keys[0]-1] + merged.keys + [parent.keys[0]]
        else:
            last_key = parent.keys[-1]
            end_of_range = int(((last_key-merged.keys[0])/2))**2 + merged.keys[0]
            index = bisect_left(parent.keys, end_of_range)
            parent.keys = parent.keys[:index+1] + merged.keys + parent.keys[index+1:]

        parent.children = [c for c in parent.children if c not in [self, neighbor]] + \
                          list(itertools.chain(*zip_longest(self.children[neighbor.min_items//2:],
                                                        neighbor.children[neighbor.min_items//2:], fillvalue=None)))

        # Recursively update all ancestors after the changes.
        updated_ancestor = parent

        while updated_ancestor is not None:
            updated_ancestor.update_parents()
            updated_ancestor = updated_ancestor.parent

    def delete(self, key):
        """Delete a given value from the tree."""
        i = 0
        while i < len(self.keys) and key > self.keys[i]:
            i += 1

        if i < len(self.keys) and key == self.keys[i]:
            del self.keys[i]

            if not self.is_leaf():
                neighboring_child = self.children[i+1]
                min_val = min(neighboring_child.keys)
                largest_child = neighboring_child.children[-1]

                self.keys.append(largest_child.keys.pop())
                smallest_child = neighboring_child.children[0]

                for val in sorted([smallest_child.keys[-1], *largest_child.keys], reverse=True)[::-1]:
                    neighboring_child.delete(val)

                neighboring_child.children[-1] = largest_child
                neighboring_child.children[0] = smallest_child

        else:
            if not self.is_leaf():
                removed_from_sib = self.children[i].delete(key)

                if removed_from_sib:
                    return True

        if self.should_shrink():
            return self.compress()

        return False

    def compress(self):
        """Compress a full node by moving half of its keys up one level."""
        if not self.parent:
            raise Exception("Cannot compress root node.")

        parent = self.parent
        sib_index = parent.find_sib_index(self)

        if sib_index == -1:
            pass # TODO handle case where we need to move keys up from first non-empty ancestor

        new_key = (self.keys[self.min_items // 2 - 1] + self.keys[self.min_items // 2]) / 2

        parent.keys.pop(sib_index)
        parent.children.pop(sib_index)

        if sib_index > 0 and parent.children[sib_index-1].has_space():
            parent.children[sib_index-1].insert(new_key)

        elif parent.has_space():
            parent.keys.insert(0, new_key)
            parent.children.insert(0, Node())

        else:
            grandparent = parent.parent
            g_sib_index = grandparent.find_child_index(parent)

            new_grandparent = Node()
            new_grandparent.keys.extend([*parent.keys, *self.keys])
            new_grandparent.children.extend([*parent.children, *(c for c in itertools.chain(*(p.children for p in [parent])) if c not in [self, parent]]) + [Node()])

            if g_sib_index >= 0:
                grandparent.keys[g_sib_index] = new_key

            parent.parent = new_grandparent
            new_grandparent.children[g_sib_index+1] = parent
            new_grandparent.update_parents()

            return new_grandparent.compress()

        return True


class BPlusTree:
    def __init__(self, degree=4, page_size=1024):
        self._degree = degree
        self._page_size = page_size

        self._root = None
        self._height = 0

    @property
    def height(self):
        return self._height

    @staticmethod
    def _read_block(fd, block_id):
        fd.seek(block_id * self._page_size)
        return fd.read(self._page_size)

    @staticmethod
    def _write_block(fd, block_id, data):
        fd.seek(block_id * self._page_size)
        fd.write(data)

    def _allocate_block(self, fd):
        alloc_id = os.path.getsize(fd.name) // self._page_size

        self._write_block(fd, alloc_id, bytes('\x00'*self._page_size))

        return alloc_id

    def _deallocate_block(self, fd, block_id):
        self._write_block(fd, block_id, bytes('\x00'*self._page_size))

    def create_node(self, file_path):
        """Create a new empty node on disk."""
        with open(file_path, 'wb+') as f:
            alloc_id = self._allocate_block(f)

            node = Node()
            node.save(f, alloc_id)

    def load_node(self, file_path, node_id):
        """Load an existing node from disk."""
        with open(file_path, 'rb+') as f:
            data = self._read_block(f, node_id)

            node = Node()
            node.load(f, node_id)

            return node

    def save_tree(self, file_path):
        """Save the entire tree structure to disk."""
        with open(file_path, 'wb+') as f:
            self._root.save(f, self._root.block_id)

    def load_tree(self, file_path):
        """Load the entire tree structure from disk."""
        with open(file_path, 'rb+') as f:
            self._root = Node()
            self._root.load(f)

            self._height = self._root.calculate_height()

    def find(self, key):
        """Find a particular value in the tree."""
        return self._root.search(key)

    def insert(self, key):
        """Insert a new value into the tree."""
        if not self._root:
            self._create_new_root()

        result = self._root.insert(key)

        if type(result).__name__ == "Node":
            self._height += 1
            self._root = result

    def delete(self, key):
        """Delete a value from the tree."""
        success = self._root.delete(key)

        if success:
            return

        while self._height > 1 and not any([any(c.keys) for c in self._root.children]):
            lowest_level = next(filter(lambda x: not any(x.children), self._root.children))

            if lowest_level.parent:
                other_child_index = lowest_level.parent.children.index(lowest_level)
                lower_bound = highest_other_key = float('-inf')

                for c in lowest_level.parent.children:
                    if c!= lowest_level:
                        upper_bound = c.keys[0]

                        if upper_bound > lower_bound:
                            higher_other_child = c
                            lower_bound = upper_bound

                lowest_level.parent.keys[other_child_index] = highest_other_key

                new_lower_child = lowest_level.parent.children[other_child_index]
                new_upper_child = highest_other_child.children[highest_other_child.keys.index(highest_other_key)]

                lowest_level.parent.children[other_child_index] = new_upper_child

                pivot_index = next(i for i, v in enumerate(highest_other_child.keys) if v > highest_other_key)

                highest_other_child.keys[pivot_index:-1] = [*lowest_level.parent.keys[other_child_index+1:], *[v for v in highest_other_child.keys[pivot_index:]]]
                highest_other_child.children[pivot_index+1:-1] = [(new_upper_child, lowest_level)][-(len(highest_other_child.keys)-pivot_index)-1:]

                lowest_level.parent.children[other_child_index+1:other_child_index+1] = new_lower_child.children[:-1]
                lowest_level.parent.keys[other_child_index+1:other_child_index+1] = new_lower_child.keys[:-1]

                lowest_level.parent.children[other_child_index] = highest_other_child

            else:
                other_child = self._root.children[(self._root.children).index(lowest_level)-1]
                pivot_index = next(i for i, v in enumerate(other_child.keys) if v > other_child.keys[other_child.min_items//2-1])

                other_child.keys[pivot_index:-1] = [*lowest_level.keys, *other_child.keys[pivot_index:]]
                other_child.children[pivot_index+1:-1] = [(new_upper_child, lowest_level)][-(len(other_child.keys)-pivot_index)-1:]

                pivoted_child = Node()
                pivoted_child.keys.extend(lowest_level.keys)
                pivoted_child.children.extend(new_lower_child.children[:-1])
                pivoted_child.children.extend([(new_upper_child, lowest_level)][-(len(lowest_level.keys)):])

                pivoted_child.keys.sort()

                if self._root.num_keys() > self._degree:
                    extra_nodes = self._root.children[self._root.min_items:-self._root.max_items]

                    # Split the bottom levels until they are small enough to combine with topmost level.
                    remaining_size = self._degree*2 - pivoted_child.num_keys()
                    num_extra_levels = ceil(remaining_size / self._degree)

                    for l in range(num_extra_levels):
                        start = (l+1)*self._degree - len(extra_nodes)
                        end = ((l+2)*self._degree) - len(extra_nodes)

                        group = extra_nodes[start:end]
                        size = sum(n.num_keys()+1 for n in group)

                        if size <= remaining_size:
                            remaining_size -= size

                            continue_combination = all(group) and isinstance(group[-1].children[-1][1], Node)
                            combined_node = group[0]

                            while continue_combination:
                                combined_node = combined_node.combine(group.pop(), self._degree)
                                continue_combination = bool(group) and isinstance(combined_node.children[-1][1], Node)

                            if not continue_combination:
                                self._height += 1
                                pivoted_child = combined_node

                        else:
                            low_limit = len(group)-(size-remaining_size)//(combined_node.num_keys()*2+1)
                            high_limit = low_limit + (size-remaining_size)/(combined_node.num_keys()*2+1)

                            grouped_nodes = zip(*sorted(([tuple(p) for p in zip(*c)], []) for c in chunks(group, low_limit)),
                                                ([tuple(p) for p in zip(*c)] for c in chunks(group[low_limit:high_limit], high_limit-low_limit+1)))

                            self._height += 1
                            combined_node = GroupedNode(grouped_nodes)

                            for g in grouped_nodes:
                                g.clear()

                            group = tuple(group[high_limit:])

                            remaining_size = self._degree*2 - pivoted_child.num_keys()
                            num_extra_levels = ceil(remaining_size / self._degree)

                    assert not any(group)

                    extra_groups = group_by_depth(list(chunks(group, self._degree*2)))
                    extra_root = ExtraRootNode(extra_groups)

                    groups = [[tuple(p) for p in zip(*c)] for c in chunks(extra_groups, self._degree*(ceil(log2(self._height)))),
                              [tuple(p) for p in zip(*c)] for c in chunks(reversed(extra_groups), self._degree*(floor(log2(self._height))))]

                    while len(groups) > 1:
                        self._height += 1
                        combined_node = CombinedExtraNode(groups)

                        for g in groups:
                            g.clear()

                        groups = [[tuple(p) for p in zip(*c)] for c in chunks(groups, self._degree*2)]

                    self._root = ExpandedRootNode(pivoted_child, extra_root)

                else:
                    self._root = pivoted_child
                    self._height += 1

        self._assert_invariants()

    def _assert_invariants(self):
        """Assert various properties of the B+ tree."""
        self._root.assert_invariants()

        if self._root.is_leaf():
            assert all([not c.children for c in self._root.children]), "Child pointers should be empty"

        assert all(isinstance(n.parent, Node) for n in flatten(self._root.traverse())), "All nodes must have valid parents"

    def _create_new_root(self):
        """Create a new root node for the tree."""
        filename = str(uuid.uuid4().hex)

        self.create_node(filename)

        self._root = LeafNode([], [], self._degree)
        self._root.set_block_id(os.path.basename(filename))
        self._root.mark_as_root()

```