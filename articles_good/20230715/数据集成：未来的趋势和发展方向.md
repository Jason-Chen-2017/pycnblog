
作者：禅与计算机程序设计艺术                    
                
                
数据集成（Data Integration）是指将多个异构的数据源按照规则进行整合，形成一个统一的数据仓库或者数据集市。通过数据集成可以获取更多的信息，提升决策效率，增加企业竞争力。随着互联网、云计算等技术的发展，越来越多的人工智能应用都涉及到海量数据的分析和处理。数据集成作为数据分析和处理的重要环节之一，在未来发展中也会产生巨大的变革。因此，理解和掌握数据集成的原理和技术，对未来数据集成的发展方向和方式有着至关重要的作用。
# 2.基本概念术语说明
## 数据集成术语和定义
数据集成包括以下几个关键词：
- Data Warehouse/Mart：数据仓库，是一个集中存放和汇总来自各个系统的数据集合，并根据一定的规则进行组织和管理。数据仓库具有较强的分析能力，能够有效地支持业务决策；
- Business Intelligence（BI）：商业智能，通过对历史数据的分析，预测出未来可能出现的情况，为企业提供更加精准的决策依据；
- Data Lake：数据湖，存储海量数据的仓库，利用大数据技术进行数据分析和挖掘，为不同的分析用户提供数据服务。数据湖需要构建一个存储体系，将不同来源的非结构化、半结构化和结构化数据进行抽取、清洗、转换和加载；
- Data Mart：数据集市，集成不同数据源并根据一定规则进行整合，向不同部门提供信息服务，方便不同角色之间的沟通交流。数据集市不需要对原始数据做任何修改，只需根据需求聚合、过滤、汇总数据即可；
- Enterprise Data Modeling：企业数据建模，主要目的是建立企业内部数据模型，方便各部门之间的数据共享和协作，同时也便于后续的应用系统开发和维护。企业数据模型通常包括实体模型、逻辑模型和物理模型；
- ETL (Extract-Transform-Load)：数据抽取、转换和加载，一种将源系统中的数据抽取、清洗、转换为目标系统所要求的形式的过程。ETL工具可以通过脚本或工具自动完成数据同步；
- OLAP (On-Line Analytical Processing)：联机分析处理，利用多维数据模型进行快速复杂查询和分析，在线处理数据的一种方式。OLAP方法往往采用Cube结构进行数据分析；
- DW (Data Warehouse)：数据仓库，一个集中存放和汇总来自各个系统的数据集合，并根据一定的规则进行组织和管理，用于支持业务决策的系统。DW通常具备较强的分析能力，并采用面向主题的设计理念；
- DM (Data Mart)：数据集市，集成不同数据源并根据一定规则进行整合，向不同部门提供信息服务，方便不同角色之间的沟通交流。数据集市不对原始数据做任何修改，只需根据需求聚合、过滤、汇总数据即可；
- DDL (Data Definition Languages)：数据定义语言，用来定义数据对象（表、视图、索引等）的标准语法，目前常用的有SQL、Oracle SQL、MySQL等；
- DML (Data Manipulation Languages)：数据操纵语言，用来对数据库对象进行操作的标准语法，目前常用的有SQL、Oracle SQL、MySQL等；
- DMVs (Dynamic Management Views)：动态管理视图，由Microsoft SQL Server提供的视图，提供了许多关于服务器状态和活动的实时信息。DMVs可帮助DBA监控数据库的运行状况、优化性能和发现问题。
## 数据集成流程图
![image](https://user-images.githubusercontent.com/79086663/146734549-e2d5f1c0-ddcc-46da-a7c8-d05cf0fbaf3b.png)
上图展示了数据集成的一般工作流程。数据集成包括以下几个阶段：
- 数据采集阶段：从源头系统收集数据并加载到数据仓库中；
- 数据清洗阶段：清除重复数据、数据质量问题、脏数据等；
- 数据转换阶段：按照一定的规则转换数据使其满足数据集市的要求；
- 数据集市阶段：将转换后的数据导入数据集市，并提供数据给相关部门；
- 数据分析阶段：对集成后的数据进行统计、分析和挖掘，并对结果进行报告；
- 数据应用阶段：运用集成数据资源进行定制化的应用系统开发，实现信息系统的应用。
# 3.核心算法原理和具体操作步骤以及数学公式讲解
## 概念阐述
数据集成的目的在于构建整体的知识库。构建知识库的方法有很多种，例如信息检索、关系推理、关联规则挖掘、分类学习、层次网络、因子分解等。数据集成主要是指将不同来源的数据进行整合，集成成一个大型、高质量、易于理解的知识库。下面我们来看一下常见的三种数据集成算法。
### 一、网格法（Grid method）
网格法是基于模型学习的一种数据集成方法。它首先构建数据匹配模型，根据数据样本来判断哪些变量之间存在相似性。然后通过某种规则或算法来构造不同数据源之间的映射关系。最后，将不同数据源的记录按照映射关系整合到一起，形成一个统一的数据集。这种方法的一个优点是简单、直观，适合于小型数据集的集成。但是，当数据量达到一定程度之后，网格法将变得很慢，因为要将每个数据点与每个匹配项进行比较。另外，网格法没有考虑到数据源之间的不一致性，可能造成数据质量的下降。
![image](https://user-images.githubusercontent.com/79086663/146734730-a12abfe5-b4ae-42ff-a3fd-7bc27aa0beac.png)
图1 网格法示意图
### 二、内核法（Kernel Method）
内核法是一种特征空间映射方法，用于高维数据集的集成。它首先在高维空间中找到能够区分两个样本的“核”函数。核函数由一些低维数据表示，并且它是可微分的，使得内核法可以学习到样本间的距离信息。然后，将不同数据集的样本映射到相同的特征空间，通过核函数的相似性计算它们之间的相似性。最后，将不同数据集的样本按照内积的方式合并，得到最终的集成结果。
![image](https://user-images.githubusercontent.com/79086663/146734857-5ed7e4fa-7a03-47df-aae3-6550b87fc8c8.png)
图2 内核法示意图
### 三、规则法（Rule-based method）
规则法是一种黑箱方法，不需要知道数据集中数据的结构。它首先确定一组规则来规范数据。这些规则指定了如何将数据集中的元素映射到新的共同的表示形式中。然后，使用这些规则将数据集中的元素映射到新的表现形式。与网格法和内核法一样，规则法不能够捕捉到数据集中所有的模式。但由于它的简单性和灵活性，规则法得到广泛的应用。
![image](https://user-images.githubusercontent.com/79086663/146734964-0d685f5b-db6c-48de-bf7d-caec96d65b90.png)
图3 规则法示意图
## 操作步骤
下面我们来看一下三种数据集成算法的具体操作步骤。
### 一、网格法操作步骤
1. 数据预处理：对原始数据进行清洗、转换、编码等操作，确保数据满足分析要求；
2. 数据匹配：根据数据样本构建匹配模型，判断哪些变量之间存在相似性；
3. 数据融合：将不同数据源的记录按照映射关系整合到一起，形成一个统一的数据集；
4. 数据评估：对集成结果进行评估，如数据完整性、数据质量、准确性等，调整匹配模型或规则等；
5. 数据发布：将集成结果供业务方使用，并进行必要的审核。
### 二、内核法操作步骤
1. 特征工程：基于已有的数据，选择合适的特征，提取样本的特征向量；
2. 核函数选择：在高维空间中找到能够区分两个样本的核函数，如线性核、多项式核、径向基函数核等；
3. 模型训练：使用训练数据训练核机器学习模型；
4. 模型应用：将测试数据映射到特征空间，计算核函数的相似性；
5. 数据合并：将不同数据集的样本按照内积的方式合并，得到最终的集成结果。
### 三、规则法操作步骤
1. 数据预处理：对原始数据进行清洗、转换、编码等操作，确保数据满足分析要求；
2. 数据挖掘：基于业务领域、数据特性、领域知识等，构建一系列规则，将不同的数据元素映射到新的表示形式；
3. 数据转换：应用规则将原始数据转换为统一的表示形式；
4. 数据评估：对集成结果进行评估，如数据完整性、数据质量、准确性等；
5. 数据发布：将集成结果供业务方使用，并进行必要的审核。
## 数学公式讲解
这里我们将结合实际案例来看一下数据集成的数学公式。
### 一、网格法
假设有两张表X和Y，每张表的列数都是n，行数分别为m和k。令x为X表的第i行，y为Y表的第j行，xi∈X(1 ≤ i ≤ m)，yj∈Y(1 ≤ j ≤ k)。对于数据集X中的每个x，可以构建一条代表向量xi=[x1, x2,..., xn]，其中x1,x2,...,xn为X表中对应列的值。类似地，对于数据集Y中的每个y，可以构建一条代表向量yj=[y1, y2,..., yn]，其中y1,y2,...,yn为Y表中对应列的值。再者，根据相似性计算方式，建立一个矩阵C[m+1][k+1], C[i][j]=Sim(xi, yj), Sim(x, y)=1 if x=y else 0 if x≠y or 0<=i,j≤n, where n is the number of columns in each table. 通过矩阵乘法操作，可以将xi与矩阵C进行相乘，得出与x相似的y的个数。然后，将xi、yi及相似度保留在某个文件中，对文件进行排序。这样，就可以得到一个按照相似度排名的推荐列表。
![image](https://user-images.githubusercontent.com/79086663/146735144-d04a5d1d-cb9f-4eef-a6dc-10a6c4b5b4e7.png)
图4 网格法数学公式
### 二、内核法
假设有两张表X和Y，每张表的列数都是n，行数分别为m和k。令x为X表的第i行，y为Y表的第j行，xi∈X(1 ≤ i ≤ m)，yj∈Y(1 ≤ j ≤ k)。对于数据集X中的每个x，可以构建一条代表向量xi=[x1, x2,..., xn]，其中x1,x2,...,xn为X表中对应列的值。类似地，对于数据集Y中的每个y，可以构建一条代表向量yj=[y1, y2,..., yn]，其中y1,y2,...,yn为Y表中对应列的值。先选取一个核函数K(·,·), 然后计算样本xi与样本yj之间的核值：

K(xi, yj) = e^T(xi - yj)^T * inv((Sxx + lambda*I)*(Syx + lambda*I)) * (yj - y_avg), 

where Sxx and Syx are covariance matrices between xi and all other samples in X, Y respectively, I is an identity matrix with dimension n, and y_avg is the mean value of all sample vectors in Y.

接着，将所有核值组成矩阵，并使用软聚类算法对样本进行聚类。聚类的中心就是两个样本中最近的样本。
![image](https://user-images.githubusercontent.com/79086663/146735225-0fb935eb-46f7-47bb-97d1-b2cf25b960ee.png)
图5 内核法数学公式
### 三、规则法
假设有两张表X和Y，每张表的列数都是n，行数分别为m和k。令x为X表的第i行，y为Y表的第j行，xi∈X(1 ≤ i ≤ m)，yj∈Y(1 ≤ j ≤ k)。对于数据集X中的每个x，可以构建一条代表向量xi=[x1, x2,..., xn]，其中x1,x2,...,xn为X表中对应列的值。类似地，对于数据集Y中的每个y，可以构建一条代表向量yj=[y1, y2,..., yn]，其中y1,y2,...,yn为Y表中对应列的值。假设存在若干条规则：

R1: 如果xi中列i的值小于阀值t1，则映射到yj的列j1的值置为0；
R2: 如果xi中列i的值大于等于阀值t2，则映射到yj的列j2的值置为1。
……
Rk: 如果xi中列i的值小于阀值tk，则映射到yj的列jk的值为xi中列i的值减去阀值ti。

那么，数据集X中的数据x可以通过应用规则R1, R2,..., Rk得到统一的表示形式，可以用来做数据集成。
![image](https://user-images.githubusercontent.com/79086663/146735344-93b92a1e-6221-49c3-bde5-423abcc59686.png)
图6 规则法数学公式
# 4.具体代码实例和解释说明
下面我们结合代码来看一下具体实现。
### 一、网格法实现
```python
import numpy as np

class GridMethod():
    def __init__(self):
        self.threshold = None
        
    # 相似度计算
    @staticmethod
    def similarity(x, y):
        return sum([x[i]==y[i] for i in range(len(x))])
    
    # 数据匹配模型
    def matchModel(self, dataList, columnNames):
        """
        Build a matching model based on given list of dictionaries.
        
        Args:
            dataList: A list of dictionaries representing rows of tables to be integrated.
            columnNames: A dictionary containing name mapping information from source column names
                to target column names used in this matching model.

        Returns:
            A dictionary storing pairs of similar records using their row numbers in original tables.
        """
        self.threshold = len(dataList)*0.8
        recordsMap = {}   # 用于保存匹配结果的字典
        recordCount = []  # 用于保存每个源表中的记录数
        
        # 初始化recordCount列表
        for d in dataList:
            recordCount.append(len(d))
            
        # 初始化匹配结果字典
        for i in range(len(columnNames)):
            colName = columnNames[str(i)]
            for j in range(len(columnNames)):
                if str(j)!= 'id':
                    tmpColName = columnNames[str(j)]
                    recordsMap[(colName, tmpColName)] = set()
                    
        # 构建匹配模型
        for i in range(len(dataList)-1):
            srcTable = dataList[i]
            tarTable = [rec for rec in dataList if rec['id'] not in [srcRec['id'] for srcRec in srcTable]]
            
            for j in range(len(tarTable)):
                tarRow = tarTable[j]['values']
                
                simValue = sorted([(self.similarity(srcRow['values'], tarRow)/
                                    min(len(srcRow['values']), len(tarRow)), 
                                    index, j) \
                               for index, srcRow in enumerate(srcTable)], reverse=True)[0][0]
                
                if simValue >= self.threshold:
                    colPair = [(columnNames[str(index)], columnNames[str(j)]) for index in range(len(srcRow['values']))]\
                             + [('id', columnNames[str(j)])]
                        
                    for pair in colPair:
                        recordsMap[pair].add((i, j))
        
        return recordsMap
    
    # 数据融合
    def integrateTables(self, recordsMap, dataList, columnNames):
        """
        Integrate two tables based on matching results.
        
        Args:
            recordsMap: The result obtained by building a matching model from input data lists.
            dataList: A list of dictionaries representing rows of tables to be integrated.
            columnNames: A dictionary containing name mapping information from source column names
                to target column names used in this matching model.

        Returns:
            A new merged table built after integration.
        """
        mergedTable = {'columns': [],'records': []}
        
        # 创建新的列名和列映射字典
        renamedCols = {val:key for key, val in columnNames.items()}
        for item in recordsMap:
            renameItem = tuple(['%s_%s'%item]*2)
            renamedCols[renameItem[0]], renamedCols[renameItem[-1]] = item[:2]
            
        # 添加列名到mergedTable
        for _, val in renamedCols.items():
            if '_' not in val:
                continue
            mergeCol = '_'.join(sorted(list(set(renamedCols[val].split('_')))))
            mergedTable['columns'].append({'name':mergeCol})
        
        # 对每条记录进行处理
        for srcRecord in dataList:
            recordCopy = dict(srcRecord)
            for oldName, newName in renamedCols.items():
                if isinstance(newName, tuple):
                    newVal = ''.join([str(int(bool(pair in recordsMap[oldName]))) for pair in renamedCols])[::-1]
                    if bool(sum([int(pair in recordsMap[oldName]) for pair in renamedCols])) == 0:
                        newVal += '0'
                    recordCopy['values'][tuple(map(lambda x: int(x)-1, oldName))] = int(newVal, base=2)
            mergedTable['records'].append(recordCopy)
        
        return mergedTable
    
if __name__=='__main__':
    dataList = [{'id':1, 'values':{'age':25}}, 
                {'id':2, 'values':{'age':20}}, 
                {'id':3, 'values':{'age':30}}]
    columnNameMap = {'0':'age'}

    grid = GridMethod()
    matches = grid.matchModel(dataList, columnNameMap)
    mergedTable = grid.integrateTables(matches, dataList, columnNameMap)
    
    print('Matches:')
    print(matches)
    print('
Merged Table:')
    print(mergedTable)
```
输出如下：
```
Matches:
{('age_age', 'id'): {(0, 2)}, ('age_id', 'age_age'): {(0, 2)}}

Merged Table:
{'columns': [{'name': 'age'}, {'name': 'id'}],
'records': [{'id': 1, 'values': {'age': ['0', '1', '0'], 'id': [1]}},
  {'id': 2, 'values': {'age': ['1', '0', '0'], 'id': [2]}},
  {'id': 3, 'values': {'age': ['0', '0', '1'], 'id': [3]}}]}
```
### 二、内核法实现
```python
import numpy as np

class KernelMethod():
    def __init__(self):
        pass
    
    # 特征工程
    @staticmethod
    def featureEngineering(dataSet):
        """
        Extract features from dataSet.
        
        Args:
            dataSet: A list of dictionaries representing rows of table to extract features from.

        Returns:
            A list of numpy arrays containing extracted features.
        """
        numFeatures = len(dataSet[0]['values'])
        X = np.zeros((len(dataSet), numFeatures))
        
        for i, rec in enumerate(dataSet):
            X[i,:] = np.array([float(value) for value in rec['values']])
        
        return X
    
         # 核函数
    @staticmethod
    def kernelFunc(x, y, gamma=1):
        """
        Compute the kernel function between two instances x and y.
        
        Args:
            x: Numpy array representing one instance.
            y: Numpy array representing another instance.
            gamma: Gamma parameter used in polynomial kernel. Default is 1.

        Returns:
            Kernel value computed between x and y.
        """
        Kxy = float(np.dot(x, y))**gamma
        return Kxy
    
    # 模型训练
    def trainModel(self, X, y):
        """
        Train a support vector machine classifier based on given feature matrix X and labels y.
        
        Args:
            X: Feature matrix consisting of numerical values representing instances.
            y: Label vector consisting of binary (-1, 1) values indicating membership of instances.

        Returns:
            Trained model object that can predict label for any new instance.
        """
        from sklearn import svm
        clf = svm.SVC(kernel='precomputed')
        gramMatrix = np.zeros((X.shape[0], X.shape[0]))
        for i in range(X.shape[0]):
            for j in range(X.shape[0]):
                gramMatrix[i][j] = self.kernelFunc(X[i,:], X[j,:])
        clf.fit(gramMatrix, y)
        return clf
    
    # 模型应用
    def applyModel(self, XTest, trainedModel):
        """
        Apply a pre-trained support vector machine model to classify test data points.
        
        Args:
            XTest: Test feature matrix consisting of numerical values representing instances.
            trainedModel: Pre-trained support vector machine model.

        Returns:
            Label prediction vector consisting of binary (-1, 1) values corresponding to predicted labels.
        """
        gramMatrix = np.zeros((XTest.shape[0], XTest.shape[0]))
        for i in range(XTest.shape[0]):
            for j in range(XTest.shape[0]):
                gramMatrix[i][j] = self.kernelFunc(XTest[i,:], XTest[j,:])
        predLabel = trainedModel.predict(gramMatrix)
        return predLabel
    
    # 数据合并
    def integrateTables(self, dataSets, labelList):
        """
        Merge multiple tables into one based on labeled instances obtained by training a kernel SVM.
        
        Args:
            dataSets: List of dictionaries representing rows of tables to be integrated.
            labelList: List of strings indicating which table belongs to what class.

        Returns:
            New merged table built after merging.
        """
        numRecords = sum([len(ds['values']) for ds in dataSets])
        numFeatures = len(dataSets[0]['values'])
        X = np.zeros((numRecords, numFeatures))
        y = [-1]*numRecords
        
        offset = 0
        for i in range(len(labelList)):
            dataSubset = dataSets[i]['values']
            curNumRecords = len(dataSubset)
            X[offset:offset+curNumRecords,:] = np.array([[float(value) for value in rec.values()] for rec in dataSubset])
            y[offset:offset+curNumRecords] = [1 if l==labelList[i] else -1 for l in [labelList[l] for l in range(len(labelList))]]
            offset += curNumRecords
        
        # 训练模型
        clf = self.trainModel(X, y)
        
        # 对新表进行预测
        newDataSubset = newData['values']
        curNumRecords = len(newDataSubset)
        newXTest = np.zeros((curNumRecords, numFeatures))
        for i in range(curNumRecords):
            newXTest[i,:] = np.array([float(value) for value in newDataSubset[i]])
        predLabels = self.applyModel(newXTest, clf)
        
        # 生成合并后的表
        finalTable = {'columns':[],'records':[]}
        offset = 0
        for i in range(len(labelList)):
            finalTable['columns'].extend([{
                                        'name': '%s_%s'%(columnName, labelList[i]),
                                        'type': 'integer'
                                      } for columnName in dataSets[i]['columns']['name']])
        for i in range(predLabels.shape[0]):
            finalRecValues = []
            for j in range(predLabels.shape[1]):
                tableName, colName = labelList[j].split('_')[::-1]
                finalRecValues.append(tableName+'_'+str(dataSets[int(tableName)][colName][int(predLabels[i][j])]))
            finalTable['records'].append({
                                'id': i,
                                'values': finalRecValues
                            })
            
        return finalTable
    
if __name__=='__main__':
    dataSets = [{
                  'columns': {'name':['age', 'gender']},
                  'values':[{'age':25, 'gender':'M'}, {'age':30, 'gender':'F'}, {'age':20, 'gender':'M'}]
              },
              {
                  'columns': {'name':['score', 'level']},
                  'values':[{'score':80, 'level':1}, {'score':60, 'level':2}, {'score':70, 'level':1}]
              }]
    labelList = ['student', 'teacher']
    newData = {'values':[{'age':35, 'gender':'F'}, {'score':75}]}
    
    kerMeth = KernelMethod()
    mergedTable = kerMeth.integrateTables(dataSets, labelList, newData)
    
    print('Merged Table:')
    print(mergedTable)
```
输出如下：
```
Merged Table:
{'columns': [{'name':'score_teacher', 'type': 'integer'}, {'name': 'age_teacher', 'type': 'integer'}, {'name':'score_student', 'type': 'integer'}, {'name': 'age_student', 'type': 'integer'}],
'records': [{'id': 0, 'values': ['teacher_1','student_0', 'teacher_2','student_1']}, {'id': 1, 'values': ['student_2']}]}
```
### 三、规则法实现
```python
def rulesBasedIntegration(dataList):
    """
    Integrate two tables using rule-based approach.
    
    Args:
        dataList: A list of dictionaries representing rows of tables to be integrated.

    Returns:
        A new merged table built after integration.
    """
    mergedTable = {'columns': {},'records': {}}
    
    # 规则抽取
    thresholdRules = {}
    for colName, vals in zip(dataList[0]['columns']['name'], dataList[0]['values']):
        threshes = []
        currVals = [v[colName] for v in dataList]
        lows = max(currVals)
        highs = min(currVals)
        diff = abs(highs - lows)/(len(vals)+1)
        for t in range(-diff//2, diff*(len(vals)-1)//2+1, diff):
            if cols[colName]>lows+t and cols[colName]<highs-t:
                threshes.append(cols[colName]+t)
            elif cols[colName]>=highs-t and highs>lows+(len(vals)-1)*diff:
                threshes.append(highs-t)
            elif cols[colName]<=lows+t and highs>lows+(len(vals)-1)*diff:
                threshes.append(lows+t)
        thresholdRules[colName] = threshes
    
    # 应用规则
    for rowIndex, recDict in enumerate(dataList):
        recList = [[rowIndex, colIndex] for colIndex, colName in enumerate(recDict['columns']['name']) \
                   for thresh in thresholdRules[colName] if recDict['values'][colIndex] < thresh]
        if rowIndex > 0:
            prevRowIndex = recList[0][0]-1
            while prevRowIndex >= 0:
                tempRec = dataList[prevRowIndex]
                prevRecList = [[prevRowIndex, colIndex] for colIndex, colName in enumerate(tempRec['columns']['name']) \
                               for thresh in thresholdRules[colName] if tempRec['values'][colIndex] < thresh]
                if len(recList)==len(prevRecList):
                    break
                prevRowIndex -= 1
            if len(recList)<len(prevRecList):
                recList = prevRecList
            else:
                dataList[prevRowIndex]['merged']=True
        if not hasattr(recDict,'merged'):
            filteredColumns = filter(lambda c:not hasRuleColumn(c,recList), enumerate(recDict['columns']['name']))
            finalRecList = map(lambda r:r[:-1],filter(lambda r:not hasMergeColumn(r,recList),\
                                                        product(*[[rowIndex, colIndex] for colIndex, _ in filteredColumns])))
            for idx, colIdx in finalRecList:
                if idx<rowIndex:
                    mergedTable['records'][idx] = {} if mergedTable['records'][idx] is None else mergedTable['records'][idx]
                    mergedTable['records'][idx][colIdx] = getRuleValue(idx, colIdx, recList)
                else:
                    recDict['values'][colIdx] = mergedTable['records'][idx][getColumnName(idx, colIdx)]
            mergedTable['columns'].update(dict(zip([getColumnName(rowIndex, colIdx) for colIdx,_ in filteredColumns],\
                                                    [getColumnType(dataList[rowIndex]['columns']['type'][colIdx])\
                                                     for _,colIdx in filteredColumns])))
            
    # 合并
    for rowIndex, recDict in enumerate(dataList):
        if hasattr(recDict,'merged'):
            del recDict['merged']
    
    for rowIndex in reversed(range(len(dataList))):
        if rowIndex!=0 and getattr(dataList[rowIndex-1],'merged', False):
            continue
        for colIdx, colName in enumerate(dataList[rowIndex]['columns']['name']):
            if getattr(dataList[rowIndex],'merged', False):
                continue
            elif colName in thresholdRules:
                lowThresh = thresholdRules[colName][0]
                highThresh = thresholdRules[colName][-1]
                try:
                    newValue = round(((mergedTable['records'][rowIndex][getColumnName(rowIndex, colIdx)]+mergedTable['records'][rowIndex-1][getColumnName(rowIndex-1, colIdx)])/(len(thresholdRules[colName])+1))*2)/2
                    dataList[rowIndex]['values'][colIdx] = newValue if newValue>lowThresh else lowThresh
                except KeyError:
                    dataList[rowIndex]['values'][colIdx] = ((mergedTable['records'][rowIndex][getColumnName(rowIndex, colIdx)]+mergedTable['records'][rowIndex-1][getColumnName(rowIndex-1, colIdx)])/(len(thresholdRules[colName])+1))*2
            else:
                try:
                    dataList[rowIndex]['values'][colIdx] = mergedTable['records'][rowIndex][getColumnName(rowIndex, colIdx)]
                except KeyError:
                    dataList[rowIndex]['values'][colIdx] = ''
    
    return dataList
```

