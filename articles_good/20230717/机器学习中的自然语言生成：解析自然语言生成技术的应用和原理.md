
作者：禅与计算机程序设计艺术                    
                
                
自然语言生成（Natural Language Generation，NLG）是指通过计算机自动地生成与人类自然语言等效且具有某种信息含量、含蓄风格的语句或文本。例如，在对话系统中，可以通过用计算机生成的文本引导用户进行对话，从而提升用户体验；在智能助手中，可以通过生成特定领域的指令、问题或者查询来实现用户的需求；在信息推荐系统中，可以通过生成符合用户需求的信息推送给用户。随着技术的飞速发展，基于深度学习的自然语言生成技术已经成为一种热门研究方向，具有广泛的应用价值。本文将对机器学习中的自然语言生成技术的应用和原理进行分析。

# 2.基本概念术语说明
自然语言生成技术涉及到许多重要的基础技术，如计算语言模型、概率语言模型、上下文无关语法、语义角色标注、翻译模型、文本摘要、对抗训练等。下面简单介绍相关的术语和概念：
- 计算语言模型（Language Modeling）：计算语言模型（CLM）是计算一组单词出现的可能性的模型，用于估计当前词的出现概率，并根据这个模型预测下一个词出现的概率。计算语言模型可以用来建模词语出现的独立性、连贯性、定序关系、情感倾向、情绪表达等。
- 概率语言模型（Probabilistic Language Model）：概率语言模型（PLM）是基于语言模型的统计方法，它能够根据给定的历史观察序列，计算出某个词出现的概率。概率语言模型可以用来表示未来的潜在词和句子，评估生成的句子质量，以及改进语言模型的参数。
- 上下文无关语法（Context Free Grammar）：上下文无关语法（CFG）是一套形式化的方法论，用来描述语言结构的语法规则。CFG 可以用来定义各种语言的语法结构和语法特性，包括代词、形容词、名词、副词、介词等，还可以由更复杂的CFG规则组合而成，如包括修饰语、状语、并列短语、倒置句等。
- 语义角色标注（Semantic Role Labeling）：语义角色标注（SRL）是一种依赖于上下文和意图的自然语言理解技术，它利用句法分析和语义角色标注的能力，为每个谓词分配一个语义角色标记。例如，在一个句子“Alice gave Mary a book”中，“gave”是一个动词，它完成了主语“Alice”和受动词“Mary”之间的交换关系。语义角色标签可以用来分析句子结构，识别触发事件，并帮助做抽取任务。
- 翻译模型（Translation Model）：翻译模型（TM）是一种机器翻译模型，它通过统计学习的方式，把一种语言转换成另一种语言。通俗点讲，就是利用统计的方法，让计算机学习到不同语言之间的对应关系，并利用这些关系进行文本翻译。
- 文本摘要（Text Summarization）：文本摘要（TS）是对文档、视频、新闻等长文本进行自动化处理的过程，通过选取关键信息和摘取主题词，创建一段简洁而精准的文章摘要。
- 对抗训练（Adversarial Training）：对抗训练（AT）是一种通过最小化辅助损失函数，训练两个神经网络模型之间相互竞争的训练方式。此外，对抗训练还可以有效防止模型过拟合现象的发生。
# 3.核心算法原理和具体操作步骤以及数学公式讲解
## 3.1 基于条件随机场的生成模型
条件随机场（Conditional Random Field，CRF）是一种无向图模型，用于建模序列型数据的概率分布。该模型假设状态序列依赖于前一时刻的状态，并对状态转移概率进行建模。具体来说，CRF 通过最大化所有可能状态序列的联合概率，得到最优路径，作为最终结果。

CRF 的基础思想是：假设输入是长度为$T$的序列$\mathbf{x}=(x_1,\cdots,x_T)$，其中$x_t\in\mathcal{X}$表示第$t$个元素。则模型可以表示为：
$$P(\mathbf{x})=\frac{1}{Z}\exp\left(E(\mathbf{x})\right)$$
其中$Z= \sum_{\mathbf{y}}Q(\mathbf{y}|\mathbf{x})$是归一化因子，$Q(\cdot)$是边缘概率密度函数，$E(\mathbf{x})=-\log Z+\sum_{t=1}^TQ(y_t|x_t,y_{t-1},\ldots, y_1)$是条件期望，即每个位置的状态变量与其所有上一状态的联合分布。

条件随机场通常用于序列标注、命名实体识别、信息提取等任务。但是由于其计算复杂度高，通常只用于深度学习模型。
## 3.2 神经注意机制的生成模型
神经注意机制（Neural Attention Mechanism，NAM）是基于神经网络的生成模型，可以在语言模型和生成模型之间构建一种统一的框架。该模型结合神经网络和注意力机制，能够自动选择生成文本中需要关注的内容。

具体来说，NAM 使用双向循环神经网络（BiRNN），对文本进行编码。在训练阶段，对源序列和目标序列都采用相同的编码表示。NAM 在生成阶段采用两个RNN，分别编码源序列和候选目标序列，然后使用注意力机制进行重排序。

具体的，NAM 使用如下的算法：
1. 初始化源序列和目标序列的编码表示
2. 对每一步，计算源序列和目标序列在该步的编码表示，并计算注意力分布
3. 根据注意力分布，重排源序列和目标序列的元素顺序
4. 将重排后的源序列和目标序列输入到神经网络中进行解码

NAM 模型除了能够生成文本之外，还可以用于不同的机器翻译、文本摘要、问答回答等任务。

## 3.3 生成对抗网络的生成模型
生成对抗网络（Generative Adversarial Network，GAN）是近年来非常火的深度学习模型。其核心思想是：两个网络之间互相竞争，产生对抗样本，使得两个网络都学会更好的区分真实数据和生成样本。通过迭代优化两者的参数，GAN 模型可以生成具有各种属性的样本，比如音乐、图像、视频等。

具体来说，GAN 模型由生成器 G 和判别器 D 两个网络构成。G 负责生成样本，D 负责判断样本的真伪。训练过程由以下三个步骤重复进行：

1. 从随机噪声向量 z 中生成样本 x，称为生成器的采样过程。z 是随机噪声，它服从均匀分布。
2. 将 x 输入到判别器 D，得到判别值 D(x)，判断是否属于真实样本。
3. 将 D(x) 反向传播至 G，更新参数，使得 G 对于生成样本的判别值尽可能低。

经过多个迭代之后，G 会越来越擅长生成真实样本，而 D 会变得越来越聪明，同时也不断被 G 骗去分类错误的样本。

GAN 模型也可以用于图像编辑、视频创作、图像增强、图像风格迁移、虚拟现实、缺陷检测、病灶检查等领域。
## 3.4 序列到序列模型的生成模型
序列到序列模型（Sequence to Sequence，Seq2Seq）是一种利用编码器-解码器结构的生成模型。它的特点是在编码器将输入序列映射为固定维度的表示后，再将该表示作为输入，送入解码器，输出序列。 Seq2Seq 模型有很多应用，比如机器翻译、自动摘要、文本生成、语音合成、手写文字识别、图像 caption 生成、视觉问答等。

具体来说，Seq2Seq 模型包括编码器和解码器两部分。编码器将输入序列映射为固定维度的向量，并将该向量作为解码器的初始状态。解码器通过生成输出序列，逐渐生成输出序列。在解码器的每一步，它接受编码器的输出以及上一步生成的输出作为输入，并生成相应的输出字符或词。 Seq2Seq 模型还可以实现端到端的训练，即在整个过程中，都直接优化整个 Seq2Seq 模型的参数。Seq2Seq 模型的优势是可以自动生成适合于自然语言的输出。
## 3.5 Transformer 架构的生成模型
Transformer 架构是最近提出的一种用于机器翻译、文本摘要、语言模型等任务的生成模型。它使用自注意力机制和全连接层来进行特征提取，并引入纯净的端到端训练方式。Transformer 模型能够显著提高训练速度，降低训练难度，并取得很好的效果。

Transformer 模型主要由encoder和decoder两部分组成。encoder对输入序列进行特征抽取，其中包含若干个自注意力模块和一个FFN层。每个自注意力模块负责捕捉输入序列内的相邻词之间的关联，通过对齐机制捕捉全局关联；FFN层负责将编码的输入转换为中间表示，并对其进行非线性变换。

decoder采用一个类似于编码器的自注意力机制和FFN层，并将编码器的输出作为输入，输出序列的单词或片段。整个模型可以实现端到端的训练，并可用于不同的任务，如机器翻译、文本摘要、语言模型等。

总结：从以上三种生成模型中，相比于 Seq2Seq 模型，transformer 模型的性能更好，并且训练速度快、参数少，并且不需要像 Seq2Seq 模型一样使用多层 RNN 或 CNN 来处理输入序列。
# 4.具体代码实例和解释说明
本节将结合代码实例，详细介绍生成模型的具体实现和原理。
## 4.1 基于条件随机场的生成模型
### 4.1.1 CRF 的数学表示
假设输入是一个句子，词的数量为 $V$，标签集 $\cal{Y}=\{y_1,y_2,\cdots,y_V\}$, 有以下几个约束条件：
1. 每个句子只有唯一的一个正确标签序列。也就是说，在一个句子里，每个位置都有一个唯一的标签。
2. 如果词 $i$ 为第一个词，则其标签只能是 $\overline{\cal{Y}}$ 中的某个元素，否则的话，标签集合为 $\cal{Y}$ 。也就是说，第一个词的标签不能确定其他位置的标签，其他位置的标签只能由之前的词决定。
3. 对于任意的位置 $i$ 和 $j>i$ ，如果 $(v_i,y_i)
otin\prod_{k=1}^{i}(v_k,y_k),(u_i,y_i)
otin\prod_{k=1}^{i}(u_k,y_k), k<i$ ，那么就没有标签满足 $v_i+y_i=u_i+y_j$ 。也就是说，标签之间不能出现换位（shift）操作。
下面给出 CRF 的数学表示：
$$
\begin{aligned}
&\left\{y_{i}\right\}_{i=1}^{V}=argmax_{y_{1},y_{2},\cdots,y_{V}}\left[q(y_{1}|y_{2},\cdots,y_{i-1}),q(y_{2}|y_{1},y_{3},\cdots,y_{i-1}),\cdots,q(y_{V}|y_{1},\cdots,y_{V-1})\right]\\
&\forall i\geqslant 2,\quad q(y_{i}|y_{1},\cdots,y_{i-1})\equiv p(y_{i}|f(s_{i}))\\
&where f:\left\{s_{i}:=(v_{1},y_{1},\cdots,v_{i},y_{i-1},u_{i})\in\mathbb{R}^{d_{1}+\cdots+d_{i-1}+2n}\rightarrow\mathbb{R}^{m}\\
&s_{i}=[v_{1},y_{1},\cdots,v_{i},y_{i-1},u_{i}]    ext{ 表示第 }i    ext{ 个词及其对应的 n 个前驱词和 n 个后继词}\\
&\forall i\geqslant 2,\quad s_{i}[l]    ext{ 表示第 }i    ext{ 个词在第 l 个标签上的分数}\\
&\forall j
eq i,\quad\forall u_{j},p(y_{j}|y_{i-1})\leqslant q(y_{j}|y_{i-1})\\
&\forall i,\quad p(y_{i}|\lambda)=\frac{1}{\sum_{y\in Y}e^{-\beta E_{Y}(    heta^{(i)},\lambda)}}e^{\beta E_{Y}(    heta^{(i)},\lambda)}\\
&E_{Y}(    heta,h):=\sum_{y\in Y}\left(-\log p_    heta\left(y\mid h\right)+\sum_{l=1}^L r_{il}h_{l}\right)\\
&    heta:=\{W,r,b\}\\
&\beta\in\mathbb{R}_{\geqq}
\end{aligned}
$$
### 4.1.2 PyTorch 的实现
PyTorch 中提供了 CRF 相关的 API，可以方便地实现 CRF 的训练、预测和评估等功能。下面以 NER（Named Entity Recognition，命名实体识别）任务为例，演示如何使用 PyTorch 训练和测试一个 CRF 模型。
```python
import torch
from torchcrf import CRF

def get_data():
    """Get some sample data."""
    # Sample training data
    train_data = [
        ('Beyoncé lives in Los Angeles', ['PERSON', 'LOCATION']),
        ('Apple is looking at buying a MacBook Pro', ['ORGANIZATION', 'PRODUCT', 'TRANSACTION'])
    ]

    return train_data

def prepare_sequence(seq, to_ix):
    idxs = [to_ix[w] for w in seq]
    return torch.tensor(idxs, dtype=torch.long)

if __name__ == '__main__':
    # Prepare the dataset and vocabulary
    tagset_size = 3
    word_to_ix = {}
    for sentence, tags in get_data():
        for word in sentence.split():
            if word not in word_to_ix:
                word_to_ix[word] = len(word_to_ix)
        for tag in tags:
            if tag not in tag_to_ix:
                tag_to_ix[tag] = len(tag_to_ix)

    # Define model hyperparameters
    embedding_dim = 64
    hidden_dim = 128
    num_layers = 1

    # Initialize the model with pre-trained embeddings or randomly initialized weights
    model = CRF(embedding_dim, hidden_dim, tagset_size, num_layers)

    # Get the inputs and outputs from the dataset
    sentences, tags = zip(*get_data())
    inputs = prepare_sequence(sentences, word_to_ix).transpose(0, 1)
    targets = prepare_sequence([tags], tag_to_ix)

    # Train the model on the dataset
    loss_function = torch.nn.functional.cross_entropy
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)
    
    for epoch in range(num_epochs):
        # Forward pass through LSTM layer
        output = model(inputs)

        # Compute and print loss
        loss = loss_function(output, targets)
        print('Epoch [%d/%d], Loss: %.4f' % (epoch + 1, num_epochs, loss.item()))

        # Zero gradients, perform backward pass, and update parameters
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    # Evaluate the trained model on new test data
    test_sentence = 'Apple announces plans to sell more MacBooks than iPad pro this quarter.'
    test_input = prepare_sequence([test_sentence], word_to_ix).transpose(0, 1)
    test_target = prepare_sequence([''.join(['U-' if t=='O' else t.split('-')[0].upper()+'-'+t.split('-')[-1].lower() for t in ner])], tag_to_ix)

    # Predict the labels of each element in the input sequence using viterbi decoding algorithm
    predictions = []
    scores, prediction = model(test_input)
    for score in scores:
        _, predicted_index = score.max(0)
        predictions.append(predicted_index)

    # Compare predicted results with actual ones
    correct = sum([predictions[i]==test_target[0][i] for i in range(len(predictions))])/len(predictions)*100.0
    print("Test Accuracy:",correct,"%")
```
上面的代码首先定义了一个获取数据的函数 `get_data`，返回一些训练样本。然后准备了一个词表 `word_to_ix` 来记录所有的词以及它们的索引，以及一个标签表 `tag_to_ix`。接着初始化了一个 `CRF` 模型，并传入了一些超参数，然后获取训练数据，准备好输入和输出，定义了损失函数 `loss_function` 和优化器。

训练模型时，在每轮迭代中，首先前向传播得到模型的输出，然后计算损失，打印损失值。然后调用优化器进行梯度更新，并清除梯度。最后对模型进行评估，计算准确率。这里使用了最简单的损失函数，实际项目中可能会使用更复杂的损失函数。

为了说明模型的推断过程，最后生成了一个新的测试句子，准备好输入，运行模型得到预测结果，并比较预测结果与实际标签。
## 4.2 神经注意机制的生成模型
### 4.2.1 注意力机制的数学表示
注意力机制（Attention mechanism）是利用神经网络的特性，能够根据输入序列中的不同位置的相对重要性，动态调整模型的注意力，只关注需要的部分，从而提高模型的性能。具体来说，输入是一个长度为 $T$ 的序列 $\mathbf{x}=(x_1,\cdots,x_T)$，模型的参数为 $    heta$, 我们希望学习得到一个函数 $a:\left[0,1\right]^{T}    imes T\rightarrow \mathbb{R}^{T}$ ，其中 $a(i,j)=\alpha_{ij}$ ，$0\leqslant i\leqslant j\leqslant T$ ，$\alpha_{ij}>0$ ，$\sum_{j=1}^{T}a_{ij}=\sum_{j=1}^{T}a_{ji}=1$ 。这个函数描述的是输入序列中第 $i$ 个位置对第 $j$ 个位置的重要程度。

注意力机制通过增加一个神经网络层，计算出权重矩阵 $w$ ，使得第 $i$ 个位置对第 $j$ 个位置的影响可以由 $w_{ij}=a_{ij}f\left(\phi(x_i),\phi(x_j)\right)$ 计算出来，其中 $f$ 是激活函数，$\phi$ 是编码器，计算得到隐层表示。然后，可以得到整体的输出表示 $h=WQ+b$ ，其中 $Q$ 和 $W$ 是模型的参数，$h$ 是输出的表示。

注意力机制常用的有三种不同的计算方法：
- 加性注意力（Additive attention）：对于给定的输入 $x_i$ ，计算得到权重为 $\alpha_{ij}=a_{ij}=\sigma\left(w_{ij}\right)$ ，这样计算出的权重只取决于 $x_i$ 和 $x_j$ 。
- 乘性注意力（Multiplicative attention）：对于给定的输入 $x_i$ ，计算得到权重为 $\alpha_{ij}=a_{ij}=\dfrac{\exp(w_{ij})}{\sum_{k=1}^{T}\exp(w_{ik})}$ ，这样计算出的权重还会考虑其他位置的影响。
- 自注意力（Self-attention）：对于给定的输入 $x_i$ ，计算得到权重为 $\alpha_{ij}=a_{ij}=\dfrac{\exp(w_{ij}-\max_{j'
e i'}w_{ij'})}{\sum_{j'}e^{w_{ij'}-\max_{j''
e i''}w_{ij''}}}$(公式待定) ，这样计算出的权重会考虑当前位置和周围位置的影响。
### 4.2.2 PyTorch 的实现
PyTorch 中提供了自注意力机制相关的 API，可以方便地实现 self-attention 模型的训练、预测和评估等功能。下面以 NMT （Neural Machine Translation，神经机器翻译）任务为例，演示如何使用 PyTorch 训练和测试一个 self-attention 模型。

```python
import torch
import torch.nn as nn

class SelfAttnEncoderLayer(nn.Module):
    def __init__(self, hidden_dim, num_heads):
        super().__init__()
        
        assert hidden_dim % num_heads == 0, "hidden_dim must be divisible by num_heads"
        
        self.attn_layer = MultiHeadAttentionLayer(hidden_dim, num_heads)
        self.fc_layer = PositionwiseFeedforwardLayer(hidden_dim)
        
    def forward(self, src, src_mask):
        """
        Args:
            - src : Tensor shape (batch_size, src_len, hidden_dim)
            - src_mask : ByteTensor shape (batch_size, src_len)
        
        Returns:
            - output : Tensor shape (batch_size, src_len, hidden_dim)
        """
        
        attn_output = self.attn_layer(src, src, src, src_mask)
        fc_output = self.fc_layer(attn_output)
        
        return fc_output
        
class MultiHeadAttentionLayer(nn.Module):
    def __init__(self, hidden_dim, num_heads):
        super().__init__()
        
        assert hidden_dim % num_heads == 0, "hidden_dim must be divisible by num_heads"
        
        self.num_heads = num_heads
        self.hidden_dim = hidden_dim
        
        self.depth = int(hidden_dim / num_heads)
        
        self.wq = nn.Linear(hidden_dim, hidden_dim)
        self.wk = nn.Linear(hidden_dim, hidden_dim)
        self.wv = nn.Linear(hidden_dim, hidden_dim)
        
        self.dense = nn.Linear(hidden_dim, hidden_dim)
        
    def split_heads(self, x, batch_size):
        """Split the last dimension into (num_heads, depth).
        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)"""
        x = x.view(batch_size, -1, self.num_heads, self.depth)
        return x.permute(0, 2, 1, 3)
    
    def scaled_dot_product_attention(self, q, k, v, mask):
        """Calculate the attention weights.
        q, k, v must have matching leading dimensions."""
        
        matmul_qk = torch.matmul(q, k.transpose(-1, -2)) # (batch_size, num_heads, seq_len, seq_len)
        
        dk = torch.tensor(k.shape[-1]).type_as(q) # scalar
        
        scaled_scores = matmul_qk / torch.sqrt(dk)
        
        if mask is not None:
            scaled_scores += (mask * -1e9)
            
        att_weights = nn.Softmax(dim=-1)(scaled_scores)
        
        output = torch.matmul(att_weights, v) # (batch_size, num_heads, seq_len, depth)
        
        return output, att_weights
        
    def forward(self, query, key, value, mask=None):
        """Implements multihead attention.
        Args:
            - query : Tensor shape (batch_size, tgt_len, hidden_dim)
            - key : Tensor shape (batch_size, src_len, hidden_dim)
            - value : Tensor shape (batch_size, src_len, hidden_dim)
            - mask : ByteTensor shape (batch_size, tgt_len, src_len)
                
        Returns:
            - Output tensor shape (batch_size, tgt_len, hidden_dim)
        """
        batch_size = query.shape[0]
        
        # linear layers
        qw = self.wq(query)    # (batch_size, tgt_len, hidden_dim)
        kw = self.wk(key)      # (batch_size, src_len, hidden_dim)
        vw = self.wv(value)    # (batch_size, src_len, hidden_dim)
        
        # split heads
        qw = self.split_heads(qw, batch_size)           # (batch_size, num_heads, tgt_len, depth)
        kw = self.split_heads(kw, batch_size)           # (batch_size, num_heads, src_len, depth)
        vw = self.split_heads(vw, batch_size)           # (batch_size, num_heads, src_len, depth)
        
        # calculate attention
        attention, _ = self.scaled_dot_product_attention(qw, kw, vw, mask)
        
        # concatenation
        concatenated = attention.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.hidden_dim) #(batch_size, tgt_len, hidden_dim)
        
        # final linear layer
        output = self.dense(concatenated)   # (batch_size, tgt_len, hidden_dim)
        
        return output
    
class PositionwiseFeedforwardLayer(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        
        self.fc1 = nn.Linear(hidden_dim, 4*hidden_dim)
        self.fc2 = nn.Linear(4*hidden_dim, hidden_dim)
        
    def forward(self, x):
        """Implements position-wise feedforward network.
        Args:
            - x : Tensor shape (batch_size, seq_len, hidden_dim)
                
        Returns:
            - Output tensor shape (batch_size, seq_len, hidden_dim)
        """
        residual = x
        
        out = nn.functional.relu(self.fc1(x))
        out = self.fc2(out)
        
        out += residual
        
        return out
    
class Encoder(nn.Module):
    def __init__(self, vocab_size, embed_dim, enc_units, batch_sz):
        super().__init__()
        
        self.batch_sz = batch_sz
        self.enc_units = enc_units
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.gru = nn.GRU(embed_dim, enc_units, bidirectional=True, batch_first=True)
        
    def forward(self, input):
        """
        Args:
            - input : LongTensor shape (batch_size, seq_len)
        Return:
            - encoder_outputs : FloatTensor shape (batch_size, seq_len, enc_units*2)
        """
        embedded = self.embedding(input)
        output, state = self.gru(embedded)
        encoder_outputs = torch.cat((state[0], state[1]), dim=1)
        return encoder_outputs
    

class Decoder(nn.Module):
    def __init__(self, vocab_size, embed_dim, dec_units, batch_sz):
        super().__init__()
        
        self.batch_sz = batch_sz
        self.dec_units = dec_units
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.gru = nn.GRU(embed_dim+enc_units, dec_units, batch_first=True)
        self.out = nn.Linear(dec_units, vocab_size)
        self.attention = BahdanauAttention(dec_units)
        
    def call(self, input, hidden, enc_output, context):
        """
        Args:
            - input : LongTensor shape (batch_size, )
            - hidden : FloatTensor shape (batch_size, hidden_size)
            - enc_output : FloatTensor shape (batch_size, src_len, hidden_size*2)
            - context : FloatTensor shape (batch_size, src_len, hidden_size)
        Return:
            - logits : FloatTensor shape (batch_size, vocab_size)
        """
        # Step 1. Embedding
        emb_input = self.embedding(input) # (batch_size, embed_dim)
        
        # Step 2. Concatenate embedding with previous context vector
        step_context = self.attention(hidden, enc_output, context)
        gru_input = torch.cat([emb_input, step_context], axis=-1) # (batch_size, embed_dim+hidden_size)
        
        # Step 3. Update GRU cell
        output, hidden = self.gru(gru_input.unsqueeze(1), hidden.unsqueeze(0)) # (batch_size, 1, hidden_size)
        output = torch.squeeze(output, axis=1) # (batch_size, hidden_size)
        
        # Step 4. Output layer
        logits = self.out(output) # (batch_size, vocab_size)
        
        return logits, hidden.squeeze(0), step_context


if __name__ == '__main__':
    # Prepare the dataset and vocabulary
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    text = ["hello world", "my name is John"]
    max_length = 10
    
    src_tokenizer = Tokenizer(char_level=False)
    src_tokenizer.fit_on_texts(text)
    src_sequences = src_tokenizer.texts_to_sequences(text)
    
    padded_seqs = pad_sequences(src_sequences, padding='post', maxlen=max_length)
    
    src_vocab_size = len(src_tokenizer.word_index) + 1
    src_embedding_dim = 64
    src_units = 128
    
    # Initialize models and optimizers
    src_encoder = Encoder(src_vocab_size, src_embedding_dim, src_units, len(padded_seqs)).to(device)
    src_optimizer = Adam(src_encoder.parameters())
    
    target_tokenizer = Tokenizer()
    target_tokenizer.fit_on_texts(["hello", "world"])
    tar_vocab_size = len(target_tokenizer.word_index) + 1
    tar_embedding_dim = 64
    tar_units = 128
    
    decoder = Decoder(tar_vocab_size, tar_embedding_dim, tar_units, len(padded_seqs)).to(device)
    decoder_optimizer = Adam(decoder.parameters())
    
    criterion = CrossEntropyLoss()
    
    # Start training process
    for epoch in range(EPOCHS):
        start_time = time.time()
        
        src_encoder.train()
        decoder.train()
        
        src_encoded_sents = src_encoder(padded_seqs.to(device))
        
        total_loss = 0
        
        for i in range(src_encoded_sents.shape[0]):
            
            trg_seq = encoded_trg[:, i].reshape((-1,))
            
            decoder_hidden = decoder.initialize_hidden_state()

            # Teacher forcing - feeding the target as the next input
            for di in range(trg_seq.shape[0]):
                decoder_output, decoder_hidden, step_context = decoder(
                    trg_seq[di], decoder_hidden, 
                    src_encoded_sents.to(device), 
                    encoder_outputs.to(device))
                
                # Calculate the loss between predicted and true label
                step_loss = criterion(decoder_output, trg_seq[di].unsqueeze(0).to(device))
                
                total_loss += step_loss
        
        avg_loss = total_loss/len(padded_seqs)
        
        end_time = time.time()
        
        print('[Epoch:%d] Time taken: %.2fs Loss: %.3f'%
              (epoch+1, end_time - start_time, avg_loss.item()))

