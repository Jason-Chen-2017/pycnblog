                 

## 字节跳动2024校招：音视频开发工程师面试真题详解

随着数字媒体时代的到来，音视频开发工程师成为互联网行业的热门职位之一。字节跳动作为中国领先的互联网科技公司，每年都会吸引大量优秀的人才加入其音视频开发团队。本文将详细解析字节跳动2024校招中音视频开发工程师的相关面试真题，帮助考生更好地应对面试挑战。

### 面试题一：音视频编解码基本概念

**题目描述：** 请简要解释音视频编解码的基本概念，以及H.264和H.265的区别。

**答案解析：**

音视频编解码是指将音视频信号转换为压缩格式以便存储或传输，以及将压缩格式还原为原始信号的过程。编解码技术旨在减少数据量，提高传输效率和存储空间利用率。

H.264和H.265是两种常用的视频编解码标准，其主要区别在于：

1. **压缩效率：** H.265相比H.264提供了更高的压缩效率，可以在相同质量下使用更少的比特率，或者在使用相同比特率时提供更好的图像质量。

2. **编码复杂度：** H.265的编码复杂度更高，需要更多的计算资源和时间进行处理。

3. **兼容性：** H.264被广泛支持，几乎所有现代设备都能解码H.264视频。而H.265虽然提供了更好的性能，但兼容性较差，需要更多的设备支持。

源代码实例：

```c
// 假设我们使用某种音视频编解码库进行编解码操作
AVCodec* codec = avcodec_find_encoder(AV_CODEC_ID_H264);
if (!codec) {
    printf("Codec not found\n");
    return -1;
}

AVCodecContext* codec_ctx = avcodec_alloc_context3(codec);
if (!codec_ctx) {
    printf("Failed to allocate codec context\n");
    return -1;
}

// 设置编解码参数
codec_ctx->bit_rate = 4000000;
codec_ctx->width = 1920;
codec_ctx->height = 1080;
codec_ctx->frame_rate = 30;
codec_ctx->gop_size = 30;
codec_ctx->pix_fmt = AV_PIX_FMT_YUV420P;

// 打开编解码器
if (avcodec_open2(codec_ctx, codec, NULL) < 0) {
    printf("Failed to open codec\n");
    return -1;
}

// 进行编码操作
AVPacket packet;
AVFrame* frame = av_frame_alloc();
if (avcodec_encode_video2(codec_ctx, &packet, frame, &frame_pts) < 0) {
    printf("Encoding error\n");
    return -1;
}

// 处理编码后的数据
av_packet_unref(&packet);

// 释放资源
av_frame_free(&frame);
avcodec_close(codec_ctx);
av_free(codec_ctx);
```

### 面试题二：音视频同步技术

**题目描述：** 请解释音视频同步技术，并简要说明如何实现。

**答案解析：**

音视频同步技术是指确保音频和视频信号在播放时保持同步的技术。由于音频和视频数据传输和处理的速度可能不一致，因此需要采取同步技术来确保两者在播放时保持一致。

实现音视频同步的方法包括：

1. **时间戳同步：** 在音频和视频数据中添加时间戳，通过比较时间戳来确保两者同步。

2. **缓冲区控制：** 通过控制音频和视频缓冲区的大小和填充程度来调整播放速度，实现同步。

3. **关键帧控制：** 利用视频编解码中的关键帧来确保音视频同步，关键帧可以快速定位，有助于保持同步。

源代码实例：

```c
// 假设我们使用某种音视频播放库进行播放操作
AVFormatContext* format_ctx = avformat_alloc_context();
if (avformat_open_input(&format_ctx, "input.mp4", NULL, NULL) < 0) {
    printf("Failed to open input file\n");
    return -1;
}

if (avformat_find_stream_info(format_ctx, NULL) < 0) {
    printf("Failed to find stream information\n");
    return -1;
}

// 找到音频和视频流的索引
int audio_stream_idx = -1;
int video_stream_idx = -1;
for (int i = 0; i < format_ctx->nb_streams; i++) {
    if (format_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {
        audio_stream_idx = i;
    } else if (format_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
        video_stream_idx = i;
    }
}

if (audio_stream_idx == -1 || video_stream_idx == -1) {
    printf("Failed to find audio or video stream\n");
    return -1;
}

// 打开音频和视频编解码器
AVCodec* audio_codec = avcodec_find_decoder(format_ctx->streams[audio_stream_idx]->codecpar->codec_id);
AVCodecContext* audio_codec_ctx = avcodec_alloc_context3(audio_codec);
if (avcodec_open2(audio_codec_ctx, audio_codec, NULL) < 0) {
    printf("Failed to open audio codec\n");
    return -1;
}

AVCodec* video_codec = avcodec_find_decoder(format_ctx->streams[video_stream_idx]->codecpar->codec_id);
AVCodecContext* video_codec_ctx = avcodec_alloc_context3(video_codec);
if (avcodec_open2(video_codec_ctx, video_codec, NULL) < 0) {
    printf("Failed to open video codec\n");
    return -1;
}

// 播放音频和视频流
AVPacket packet;
while (av_read_frame(format_ctx, &packet) >= 0) {
    if (packet.stream_index == audio_stream_idx) {
        // 解码音频数据
        int got_frame;
        AVFrame* audio_frame = av_frame_alloc();
        if (avcodec_decode_audio4(audio_codec_ctx, audio_frame, &got_frame, &packet) < 0) {
            printf("Failed to decode audio frame\n");
            return -1;
        }
        if (got_frame) {
            // 处理解码后的音频数据
        }
    } else if (packet.stream_index == video_stream_idx) {
        // 解码视频数据
        int got_frame;
        AVFrame* video_frame = av_frame_alloc();
        if (avcodec_decode_video4(video_codec_ctx, video_frame, &got_frame, &packet) < 0) {
            printf("Failed to decode video frame\n");
            return -1;
        }
        if (got_frame) {
            // 处理解码后的视频数据
        }
    }
    av_packet_unref(&packet);
}

// 释放资源
avcodec_close(audio_codec_ctx);
avcodec_close(video_codec_ctx);
avformat_close_input(&format_ctx);
```

### 面试题三：音视频滤镜应用

**题目描述：** 请解释音视频滤镜的基本概念，并简要说明如何使用FFmpeg实现音视频滤镜。

**答案解析：**

音视频滤镜是一种对音视频信号进行加工处理的工具，可以用于调整图像和音频效果，如滤镜、特效、音效等。FFmpeg是一个强大的音视频处理库，支持多种音视频滤镜。

实现音视频滤镜的方法：

1. **查找滤镜：** 使用FFmpeg命令行工具或API查找支持的滤镜。

2. **应用滤镜：** 将滤镜应用到音视频流中，通过滤镜链（filter chain）进行操作。

3. **输出结果：** 将经过滤镜处理的音视频数据输出到文件或流中。

源代码实例：

```c
// 假设我们使用FFmpeg的libavfilter库进行音视频滤镜操作
AVFilterGraph* filter_graph = avfilter_graph_alloc();
if (!filter_graph) {
    printf("Failed to allocate filter graph\n");
    return -1;
}

// 创建滤镜链
AVFilter* video_filter = avfilter_get_by_name("scale");
AVFilter* audio_filter = avfilter_get_by_name("equalizer");
AVFilterInOut* in = avfilter_inout_alloc();
AVFilterInOut* out = avfilter_inout_alloc();

if (!video_filter || !audio_filter || !in || !out) {
    printf("Failed to find filters\n");
    return -1;
}

if (avfilter_graph_add_filter(filter_graph, &in, "in", NULL) < 0 ||
    avfilter_graph_add_filter(filter_graph, &out, "out", NULL) < 0 ||
    avfilter_graph_add_filter(filter_graph, &video_filter, "scale", "in") < 0 ||
    avfilter_graph_add_filter(filter_graph, &audio_filter, "equalizer", "in") < 0) {
    printf("Failed to add filters to graph\n");
    return -1;
}

if (avfilter_graph_configurate(filter_graph) < 0) {
    printf("Failed to configure filter graph\n");
    return -1;
}

// 连接滤镜链中的输入和输出
if (avfilter_link(filter_graph, in, out, 0) < 0) {
    printf("Failed to link filters\n");
    return -1;
}

// 设置滤镜参数
AVDictionary* video_params = NULL;
av_dict_set(&video_params, "s", "1920x1080", 0);

AVDictionary* audio_params = NULL;
av_dict_set(&audio_params, "bands", "100,1000", 0);

// 应用滤镜到输入流
AVFormatContext* input_ctx = NULL;
AVStream* stream = NULL;
AVFrame* frame = NULL;
AVPacket packet;

if (avformat_open_input(&input_ctx, "input.mp4", NULL, NULL) < 0) {
    printf("Failed to open input file\n");
    return -1;
}

if (avformat_find_stream_info(input_ctx, NULL) < 0) {
    printf("Failed to find stream information\n");
    return -1;
}

stream = avformat_new_stream(input_ctx, NULL);
if (!stream) {
    printf("Failed to create new stream\n");
    return -1;
}

if (avformat_write_header(input_ctx, NULL) < 0) {
    printf("Failed to write header\n");
    return -1;
}

while (av_read_frame(input_ctx, &packet) >= 0) {
    if (packet.stream_index == stream->index) {
        if (packet.flags & AVPACKET_KEY) {
            frame = av_frame_alloc();
            if (!frame) {
                printf("Failed to allocate frame\n");
                return -1;
            }

            if (avcodec_decode_video2(input_ctx->streams[packet.stream_index]->codec, frame, &frame_finished, &packet) < 0) {
                printf("Failed to decode video frame\n");
                return -1;
            }

            if (frame_finished) {
                // 应用视频滤镜
                AVFilterBufferRef* filter_ref = avfilter_bufferref_alloc();
                if (!filter_ref) {
                    printf("Failed to allocate filter buffer\n");
                    return -1;
                }

                if (av_buffersrc_get_buffer(video_filter_ctx, filter_ref, 1000000) < 0) {
                    printf("Failed to get buffer from filter\n");
                    return -1;
                }

                if (avframe_ref(frame) < 0) {
                    printf("Failed to reference frame\n");
                    return -1;
                }

                if (avfilter_bufferref_set_time(filter_ref, frame->pts) < 0) {
                    printf("Failed to set time of filter buffer\n");
                    return -1;
                }

                if (av_buffersrc_queue(video_filter_ctx, filter_ref, 0, AVBufferRefTraits<AVFrame>::get()) < 0) {
                    printf("Failed to queue buffer to filter\n");
                    return -1;
                }

                avfilter_bufferref_free(&filter_ref);
                av_frame_free(&frame);
            }
        }
    }
    av_packet_unref(&packet);
}

// 清理资源
av_dict_free(&video_params);
av_dict_free(&audio_params);
avfilter_inout_free(&in);
avfilter_inout_free(&out);
avfilter_graph_free(&filter_graph);
avformat_close_input(&input_ctx);
```

### 面试题四：音视频流加密与解密

**题目描述：** 请解释音视频流加密和解密的基本概念，并简要说明如何使用FFmpeg实现音视频流加密和解密。

**答案解析：**

音视频流加密是指对音视频数据进行加密处理，以防止未经授权的访问和篡改。音视频流解密则是对加密后的数据进行解密，以便正常播放。

实现音视频流加密和解密的方法：

1. **加密算法：** 选择合适的加密算法，如AES、RSA等。

2. **加密参数：** 配置加密算法的参数，如密钥、加密模式等。

3. **加密操作：** 对音视频数据进行加密处理。

4. **解密操作：** 对加密后的数据进行解密处理。

源代码实例：

```c
// 假设我们使用FFmpeg的libavcrypto库进行音视频流加密和解密操作
AVCryptoContext* encrypt_ctx = av_cryptoctx_alloc();
if (!encrypt_ctx) {
    printf("Failed to allocate crypto context\n");
    return -1;
}

// 设置加密算法和密钥
if (av_cryptoctx_init(encrypt_ctx, "aes_128_cbc", "0123456789abcdef", 0) < 0) {
    printf("Failed to initialize crypto context\n");
    return -1;
}

// 加密操作
AVPacket encrypted_packet;
av_init_packet(&encrypted_packet);
encrypted_packet.data = av_malloc(AVPACKET_MAX_SIZE);
encrypted_packet.size = 0;

AVFrame* frame = av_frame_alloc();
if (!frame) {
    printf("Failed to allocate frame\n");
    return -1;
}

if (av_frame_get_buffer(frame, 32) < 0) {
    printf("Failed to allocate frame buffer\n");
    return -1;
}

// 假设我们已经从视频流中获取了一帧数据
if (avcodec_decode_video2(video_codec_ctx, frame, &frame_finished, &packet) < 0) {
    printf("Failed to decode video frame\n");
    return -1;
}

if (frame_finished) {
    uint8_t* data = frame->data[0];
    int size = frame->linesize[0] * frame->height;

    // 加密数据
    encrypted_packet.size = avCryptoContext_encrypt(encrypt_ctx, encrypted_packet.data, size, (unsigned char*)data, size);
    if (encrypted_packet.size < 0) {
        printf("Failed to encrypt data\n");
        return -1;
    }

    // 输出加密后的数据
    av_interleaved_write_frame(output_ctx, &encrypted_packet);
}

av_packet_unref(&packet);
av_frame_free(&frame);

// 清理资源
av_cryptoctx_free(&encrypt_ctx);
```

### 面试题五：音视频质量优化

**题目描述：** 请解释音视频质量优化的基本原则，并简要说明如何使用FFmpeg进行质量优化。

**答案解析：**

音视频质量优化是指通过各种技术手段提高音视频播放效果的过程。基本原则包括：

1. **降低比特率：** 通过优化编解码参数降低比特率，减少数据传输和存储开销。

2. **图像锐化：** 使用图像锐化技术增强图像细节。

3. **色彩校正：** 调整色彩平衡和亮度，改善视觉效果。

4. **音效处理：** 优化音效，如回声消除、噪声抑制等。

使用FFmpeg进行质量优化：

1. **调整编解码参数：** 修改视频编解码参数，如比特率、帧率等。

2. **使用滤镜：** 应用FFmpeg提供的各种滤镜进行图像和音频处理。

3. **优化输出格式：** 选择合适的输出格式，如H.264、MP3等。

源代码实例：

```c
// 假设我们使用FFmpeg进行音视频质量优化操作
AVFormatContext* input_ctx = NULL;
AVCodecContext* video_codec_ctx = NULL;
AVCodecContext* audio_codec_ctx = NULL;
AVStream* video_stream = NULL;
AVStream* audio_stream = NULL;

if (avformat_open_input(&input_ctx, "input.mp4", NULL, NULL) < 0) {
    printf("Failed to open input file\n");
    return -1;
}

if (avformat_find_stream_info(input_ctx, NULL) < 0) {
    printf("Failed to find stream information\n");
    return -1;
}

video_stream = avformat_new_stream(output_ctx, NULL);
if (!video_stream) {
    printf("Failed to create new video stream\n");
    return -1;
}

audio_stream = avformat_new_stream(output_ctx, NULL);
if (!audio_stream) {
    printf("Failed to create new audio stream\n");
    return -1;
}

video_codec_ctx = avcodec_alloc_context3(avcodec_find_decoder(input_ctx->streams[0]->codecpar->codec_id));
if (!video_codec_ctx) {
    printf("Failed to allocate video codec context\n");
    return -1;
}

audio_codec_ctx = avcodec_alloc_context3(avcodec_find_decoder(input_ctx->streams[1]->codecpar->codec_id));
if (!audio_codec_ctx) {
    printf("Failed to allocate audio codec context\n");
    return -1;
}

avcodec_copy_context(video_codec_ctx, input_ctx->streams[0]->codecpar);
avcodec_copy_context(audio_codec_ctx, input_ctx->streams[1]->codecpar);

video_codec_ctx->bit_rate = 5000000;
video_codec_ctx->gop_size = 30;
video_codec_ctx->max_qdiff = 4;
video_codec_ctx->max_qps = 30;
video_codec_ctx->qmin = 10;
video_codec_ctx->qmax = 51;
video_codec_ctx->bf_count = 0;
video_codec_ctx->refs = 1;

audio_codec_ctx->bit_rate = 128000;
audio_codec_ctx->sample_rate = 48000;
audio_codec_ctx->channel_layout = AV_CH_LAYOUT_STEREO;

if (avcodec_open2(video_codec_ctx, avcodec_find_encoder(AV_CODEC_ID_H264), NULL) < 0) {
    printf("Failed to open video encoder\n");
    return -1;
}

if (avcodec_open2(audio_codec_ctx, avcodec_find_encoder(AV_CODEC_ID_AAC), NULL) < 0) {
    printf("Failed to open audio encoder\n");
    return -1;
}

AVPacket packet;
AVFrame* frame = av_frame_alloc();

while (av_read_frame(input_ctx, &packet) >= 0) {
    if (packet.stream_index == 0) {
        int got_frame;
        if (avcodec_decode_video4(video_codec_ctx, frame, &got_frame, &packet) < 0) {
            printf("Failed to decode video frame\n");
            return -1;
        }

        if (got_frame) {
            // 应用视频滤镜
            AVFilterGraph* filter_graph = avfilter_graph_alloc();
            if (!filter_graph) {
                printf("Failed to allocate filter graph\n");
                return -1;
            }

            AVFilter* filter = avfilter_get_by_name("scale");
            if (!filter) {
                printf("Failed to find filter\n");
                return -1;
            }

            AVFilterInOut* in = avfilter_inout_alloc();
            AVFilterInOut* out = avfilter_inout_alloc();

            if (!in || !out) {
                printf("Failed to allocate inout\n");
                return -1;
            }

            if (avfilter_graph_add_filter(filter_graph, &in, "in", NULL) < 0 ||
                avfilter_graph_add_filter(filter_graph, &out, "out", NULL) < 0 ||
                avfilter_graph_add_filter(filter_graph, &filter, "scale", "in") < 0) {
                printf("Failed to add filters to graph\n");
                return -1;
            }

            if (avfilter_graph_configurate(filter_graph) < 0) {
                printf("Failed to configure filter graph\n");
                return -1;
            }

            if (avfilter_link(filter_graph, in, out, 0) < 0) {
                printf("Failed to link filters\n");
                return -1;
            }

            AVDictionary* params = NULL;
            av_dict_set(&params, "s", "1920x1080", 0);

            if (avfilter_graph_create_context(&filter_graph, &params) < 0) {
                printf("Failed to create filter context\n");
                return -1;
            }

            AVFrame* filtered_frame = av_frame_alloc();
            if (!filtered_frame) {
                printf("Failed to allocate filtered frame\n");
                return -1;
            }

            if (av_frame_get_buffer(filtered_frame, 32) < 0) {
                printf("Failed to allocate filtered frame buffer\n");
                return -1;
            }

            if (av_buffersrc_get_buffer(video_filter_ctx, filtered_frame, 1000000) < 0) {
                printf("Failed to get buffer from filter\n");
                return -1;
            }

            if (av_frame_copy(frame, filtered_frame) < 0) {
                printf("Failed to copy frame\n");
                return -1;
            }

            av_frame_free(&filtered_frame);

            if (av_frame_make_writable(frame) < 0) {
                printf("Failed to make frame writable\n");
                return -1;
            }

            if (avcodec_encode_video2(video_codec_ctx, &packet, frame, &got_frame) < 0) {
                printf("Failed to encode video frame\n");
                return -1;
            }

            if (got_frame) {
                av_interleaved_write_frame(output_ctx, &packet);
            }
        }
    } else if (packet.stream_index == 1) {
        int got_frame;
        if (avcodec_decode_audio4(audio_codec_ctx, frame, &got_frame, &packet) < 0) {
            printf("Failed to decode audio frame\n");
            return -1;
        }

        if (got_frame) {
            // 应用音频滤镜
            AVFilterGraph* filter_graph = avfilter_graph_alloc();
            if (!filter_graph) {
                printf("Failed to allocate filter graph\n");
                return -1;
            }

            AVFilter* filter = avfilter_get_by_name("equalizer");
            if (!filter) {
                printf("Failed to find filter\n");
                return -1;
            }

            AVFilterInOut* in = avfilter_inout_alloc();
            AVFilterInOut* out = avfilter_inout_alloc();

            if (!in || !out) {
                printf("Failed to allocate inout\n");
                return -1;
            }

            if (avfilter_graph_add_filter(filter_graph, &in, "in", NULL) < 0 ||
                avfilter_graph_add_filter(filter_graph, &out, "out", NULL) < 0 ||
                avfilter_graph_add_filter(filter_graph, &filter, "equalizer", "in") < 0) {
                printf("Failed to add filters to graph\n");
                return -1;
            }

            if (avfilter_graph_configurate(filter_graph) < 0) {
                printf("Failed to configure filter graph\n");
                return -1;
            }

            if (avfilter_link(filter_graph, in, out, 0) < 0) {
                printf("Failed to link filters\n");
                return -1;
            }

            AVDictionary* params = NULL;
            av_dict_set(&params, "bands", "100,1000", 0);

            if (avfilter_graph_create_context(&filter_graph, &params) < 0) {
                printf("Failed to create filter context\n");
                return -1;
            }

            AVFrame* filtered_frame = av_frame_alloc();
            if (!filtered_frame) {
                printf("Failed to allocate filtered frame\n");
                return -1;
            }

            if (av_frame_get_buffer(filtered_frame, 32) < 0) {
                printf("Failed to allocate filtered frame buffer\n");
                return -1;
            }

            if (av_buffersrc_get_buffer(audio_filter_ctx, filtered_frame, 1000000) < 0) {
                printf("Failed to get buffer from filter\n");
                return -1;
            }

            if (av_frame_copy(frame, filtered_frame) < 0) {
                printf("Failed to copy frame\n");
                return -1;
            }

            av_frame_free(&filtered_frame);

            if (av_frame_make_writable(frame) < 0) {
                printf("Failed to make frame writable\n");
                return -1;
            }

            if (avcodec_encode_audio2(audio_codec_ctx, &packet, frame, &got_frame) < 0) {
                printf("Failed to encode audio frame\n");
                return -1;
            }

            if (got_frame) {
                av_interleaved_write_frame(output_ctx, &packet);
            }
        }
    }

    av_packet_unref(&packet);
}

av_frame_free(&frame);
avcodec_free_context(&video_codec_ctx);
avcodec_free_context(&audio_codec_ctx);
avformat_close_input(&input_ctx);
```

### 面试题六：音视频播放器设计

**题目描述：** 请简要说明音视频播放器的设计原理，并简要描述如何使用FFmpeg实现一个简单的音视频播放器。

**答案解析：**

音视频播放器的设计原理主要包括以下几个部分：

1. **解码器选择：** 根据输入的音视频文件格式选择合适的解码器。

2. **数据流处理：** 解码音视频数据流，将压缩数据还原为原始图像和音频信号。

3. **同步处理：** 确保音频和视频数据在播放时保持同步。

4. **渲染输出：** 将解码后的图像和音频信号输出到显示设备和音频设备。

使用FFmpeg实现一个简单的音视频播放器：

1. **初始化：** 配置FFmpeg库，打开输入文件，创建输出文件。

2. **读取数据：** 读取输入文件中的音视频数据，将其解码为原始图像和音频信号。

3. **同步播放：** 确保音频和视频数据在播放时保持同步。

4. **渲染输出：** 将解码后的图像和音频信号输出到显示设备和音频设备。

源代码实例：

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>

#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libavutil/avutil.h>
#include <libavutil/time.h>

int main(int argc, char **argv)
{
    AVFormatContext *input_ctx = NULL;
    AVFormatContext *output_ctx = NULL;
    AVCodecContext *video_codec_ctx = NULL;
    AVCodecContext *audio_codec_ctx = NULL;
    AVStream *video_stream = NULL;
    AVStream *audio_stream = NULL;
    AVFrame *video_frame = NULL;
    AVFrame *audio_frame = NULL;
    AVPacket packet;
    int video_stream_idx = -1;
    int audio_stream_idx = -1;
    int frame_count = 0;

    if (argc < 2) {
        printf("Usage: %s <input file>\n", argv[0]);
        return -1;
    }

    // 打开输入文件
    if (avformat_open_input(&input_ctx, argv[1], NULL, NULL) < 0) {
        printf("Failed to open input file\n");
        return -1;
    }

    // 寻找音视频流信息
    if (avformat_find_stream_info(input_ctx, NULL) < 0) {
        printf("Failed to find stream information\n");
        return -1;
    }

    // 打开输出文件
    if (avformat_alloc_output_context2(&output_ctx, NULL, "mp4", "output.mp4") < 0) {
        printf("Failed to allocate output context\n");
        return -1;
    }

    // 找到音视频流的索引
    for (int i = 0; i < input_ctx->nb_streams; i++) {
        if (input_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {
            video_stream_idx = i;
        } else if (input_ctx->streams[i]->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {
            audio_stream_idx = i;
        }
    }

    if (video_stream_idx < 0 || audio_stream_idx < 0) {
        printf("Failed to find video or audio stream\n");
        return -1;
    }

    // 创建新的音视频流
    video_stream = avformat_new_stream(output_ctx, NULL);
    if (!video_stream) {
        printf("Failed to create new video stream\n");
        return -1;
    }

    audio_stream = avformat_new_stream(output_ctx, NULL);
    if (!audio_stream) {
        printf("Failed to create new audio stream\n");
        return -1;
    }

    // 复制音视频流参数
    video_codec_ctx = avcodec_alloc_context3(input_ctx->streams[video_stream_idx]->codecpar);
    if (!video_codec_ctx) {
        printf("Failed to allocate video codec context\n");
        return -1;
    }

    audio_codec_ctx = avcodec_alloc_context3(input_ctx->streams[audio_stream_idx]->codecpar);
    if (!audio_codec_ctx) {
        printf("Failed to allocate audio codec context\n");
        return -1;
    }

    avcodec_copy_context(video_codec_ctx, input_ctx->streams[video_stream_idx]->codecpar);
    avcodec_copy_context(audio_codec_ctx, input_ctx->streams[audio_stream_idx]->codecpar);

    // 打开音视频解码器
    if (avcodec_open2(video_codec_ctx, avcodec_find_decoder(video_codec_ctx->codec_id), NULL) < 0) {
        printf("Failed to open video decoder\n");
        return -1;
    }

    if (avcodec_open2(audio_codec_ctx, avcodec_find_decoder(audio_codec_ctx->codec_id), NULL) < 0) {
        printf("Failed to open audio decoder\n");
        return -1;
    }

    // 写入输出文件头
    if (avformat_write_header(output_ctx, NULL) < 0) {
        printf("Failed to write header\n");
        return -1;
    }

    // 解码并播放音视频数据
    while (av_read_frame(input_ctx, &packet) >= 0) {
        if (packet.stream_index == video_stream_idx) {
            int got_frame;
            video_frame = av_frame_alloc();
            if (!video_frame) {
                printf("Failed to allocate video frame\n");
                return -1;
            }

            if (avcodec_decode_video4(video_codec_ctx, video_frame, &got_frame, &packet) < 0) {
                printf("Failed to decode video frame\n");
                return -1;
            }

            if (got_frame) {
                // 显示视频帧
                // ...

                av_frame_unref(video_frame);
            }
        } else if (packet.stream_index == audio_stream_idx) {
            int got_frame;
            audio_frame = av_frame_alloc();
            if (!audio_frame) {
                printf("Failed to allocate audio frame\n");
                return -1;
            }

            if (avcodec_decode_audio4(audio_codec_ctx, audio_frame, &got_frame, &packet) < 0) {
                printf("Failed to decode audio frame\n");
                return -1;
            }

            if (got_frame) {
                // 播放音频帧
                // ...

                av_frame_unref(audio_frame);
            }
        }

        av_packet_unref(&packet);
    }

    // 关闭解码器和输入文件
    avcodec_close(video_codec_ctx);
    avcodec_close(audio_codec_ctx);
    avformat_close_input(&input_ctx);

    // 写入输出文件尾
    if (avformat_write_footer(output_ctx, NULL) < 0) {
        printf("Failed to write footer\n");
        return -1;
    }

    // 关闭输出文件
    avformat_free_context(output_ctx);

    return 0;
}
```

