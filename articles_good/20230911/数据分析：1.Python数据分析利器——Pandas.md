
作者：禅与计算机程序设计艺术                    

# 1.简介
  

Pandas是一个开源的数据分析工具包，它提供了高级数据结构、数据读取、数据操纵、数据处理等功能，能简单、快速地进行数据分析工作。它的主要用途是在内存中存储和处理数据，提供数据的清洗、整理、可视化和建模等功能。

本系列教程从入门级的Pandas入手，对其各个重要模块及方法有详细讲解。通过这一系列教程，读者可以掌握Pandas在数据分析中的应用技巧，提升自己的能力，成为一名更出色的Python数据分析师。

# 2.环境配置
首先，下载安装Anaconda，并新建一个环境。然后打开Jupyter Notebook，在第一个cell输入以下命令即可完成Pandas的安装：

```python
!pip install pandas
```

# 3.导入模块
一般情况下，我们习惯把Pandas import成pd，但为了方便阅读和书写，我还是习惯用全称，即`import pandas as pd`。

```python
import numpy as np
import pandas as pd
```

# 4.数据类型
## 4.1 Series
Series是pandas里最基础的一种数据类型，类似于一维数组，可以存储整数、浮点数、字符串等数据类型，它有一个索引（index），用于标记不同的元素。你可以理解为DataFrame中的一列。

创建Series的方法有很多种，举例如下：

```python
# 从列表、字典或numpy array创建Series
s = pd.Series([1, 2, 3, 4])   # 根据列表生成Series
print(s)
print(type(s))    # <class 'pandas.core.series.Series'>

dates = pd.date_range('2019-01-01', periods=4)   # 生成时间序列
data = {'a': 1., 'b': 2., 'c': 3.}                   # 生成字典形式的Series
s = pd.Series(data, index=['a', 'b', 'c'])          # 根据字典生成Series
print(s)
print(type(s))    # <class 'pandas.core.series.Series'>

np_array = np.random.randn(5)                      # 生成numpy array
s = pd.Series(np_array)                            # 根据numpy array生成Series
print(s)
print(type(s))    # <class 'pandas.core.series.Series'>

# 通过现有的DataFrame中创建一个Series
df = pd.DataFrame({'A': [1, 2], 'B': ['x', 'y']})
s = df['A']                                         # 从DataFrame的列创建Series
print(s)
print(type(s))    # <class 'pandas.core.series.Series'>

s = df[['A']]                                       # 从DataFrame的列创建Series
print(s)
print(type(s))    # <class 'pandas.core.frame.DataFrame'>
```

上述方法也可以用来修改或者添加数据到Series。

## 4.2 DataFrame
DataFrame是pandas里二维表格型的数据结构，它可以包含多个Series组成的不同行、列。DataFrame可以使用多种数据源构造，包括csv文件、Excel表格、SQL数据库等。

创建DataFrame的方法有很多种，举例如下：

```python
# 从列表、字典、Series、numpy array、json格式的数据源创建DataFrame
data = {
    "name": ["Alice", "Bob"], 
    "age": [25, 30]
}
df = pd.DataFrame(data)
print(df)

# 从csv文件创建DataFrame
df = pd.read_csv("example.csv")
print(df)

# 创建空白的DataFrame
df = pd.DataFrame()
```

其中，从csv文件创建DataFrame的时候需要指定文件的路径。

# 5.基本属性与操作
## 5.1 属性
DataFrame的属性主要有：

1. shape：返回DataFrame的大小，即行数和列数。
2. columns：返回DataFrame的列名列表。
3. index：返回DataFrame的索引列表。
4. dtypes：返回每列数据的数据类型。

举例如下：

```python
df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], 
                  index=["a", "b"],
                  columns=["A", "B", "C"])
print(df)

print(df.shape)       # (2, 3)
print(df.columns)     # Index(['A', 'B', 'C'], dtype='object')
print(df.index)       # Index(['a', 'b'], dtype='object')
print(df.dtypes)      # A    int64
```

## 5.2 操作
### 5.2.1 选择数据
#### 5.2.1.1 按标签选择
可以通过标签选取单个或多个行和列，语法如下：

```python
df[label]         # 选取单个列
df[[label1, label2]]        # 选取多个列

df.loc[label]             # 选取单个行
df.loc[[label1, label2]]   # 选取多个行

df.iloc[integer]              # 使用整数位置选取单个元素
df.iloc[[int_list]]           # 使用整数位置选取多个元素
```

举例如下：

```python
df = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]], 
                  index=["a", "b", "c", "d"],
                  columns=["A", "B", "C"])

print(df["A"])                    # 选取单个列
print(df[["A", "B"]])               # 选取多个列

print(df.loc["a"])                 # 选取单个行
print(df.loc[["a", "b"]])            # 选取多个行

print(df.iloc[0])                  # 使用整数位置选取单个元素
print(df.iloc[[0, 2]])             # 使用整数位置选取多个元素
```

#### 5.2.1.2 按条件选择
可以使用布尔表达式筛选数据，同时支持两个逻辑运算符“&”（并且）、“|”（或者）。

```python
df[(condition)]                       # 使用括号确定优先顺序

df[((condition1) & (condition2))]    # 满足两者的条件才被选中

df[((condition1) | (condition2))]    # 只要满足任意一个条件就被选中
```

举例如下：

```python
df = pd.DataFrame({
    "A": [1, 2, 3, 4],
    "B": [5, 6, 7, 8],
    "C": ["x", "y", "z", "w"]
}, index=["a", "b", "c", "d"])

print(df[(df.A > 2) & (df.B == 6)])                     # 使用布尔表达式筛选数据
print(df[(df.A >= 1) & ((df.B <= 6) | (df.B >= 8))])    # 使用多重条件筛选数据
```

### 5.2.2 聚合与统计
#### 5.2.2.1 groupby
groupby函数能够对DataFrame按指定字段分组，并对每个组进行操作，比如求均值、求和、求最大值、求最小值、合并等。语法如下：

```python
grouped_df = df.groupby(by=[field1, field2], axis=axis) 

agg_func = {"col1": func1, "col2": func2}                                # 指定聚合函数
agg_result = grouped_df.aggregate(agg_func)                               # 执行聚合操作

apply_func = lambda x: len(set(x)) / len(x)                              # 指定自定义函数
apply_result = grouped_df.apply(apply_func)                             # 执行自定义操作

transform_func = lambda x: x ** 2                                        # 指定变换函数
transform_result = grouped_df.transform(transform_func)                   # 执行变换操作
```

举例如下：

```python
df = pd.DataFrame({
    "A": ["a", "b", "a", "b", "a", "b"],
    "B": [1, 2, 3, 4, 5, 6],
    "C": [-1, -2, -3, -4, -5, -6]
})

grouped_df = df.groupby(["A"])                           # 分组

sum_result = grouped_df.sum()                            # 对各组求和
mean_result = grouped_df.mean()                          # 对各组求均值
max_result = grouped_df.max()                            # 对各组求最大值
min_result = grouped_df.min()                            # 对各组求最小值

agg_func = {"B": max, "C": min}                         # 指定聚合函数
agg_result = grouped_df.aggregate(agg_func)              # 执行聚合操作

apply_func = lambda x: len(set(x)) / len(x)              # 指定自定义函数
apply_result = grouped_df.apply(apply_func)             # 执行自定义操作

transform_func = lambda x: x + 1                        # 指定变换函数
transform_result = grouped_df.transform(transform_func)   # 执行变换操作

merged_result = merged_result.sort_values(by="C")       # 对结果排序
```

#### 5.2.2.2 describe
describe函数能够计算DataFrame的一些描述性统计指标，如均值、方差、最大值、最小值等。语法如下：

```python
desc_result = df.describe()
```

举例如下：

```python
df = pd.DataFrame({"A": [1, 2, 3, 4],
                   "B": [5, 6, 7, 8]})

desc_result = df.describe()
```

### 5.2.3 排序
使用sort_values函数可以对DataFrame按照指定列进行排序，参数by表示待排序的列名称或列索引，ascending=False表示降序排序。语法如下：

```python
sorted_df = df.sort_values(by="col_name", ascending=True/False)
```

举例如下：

```python
df = pd.DataFrame({"A": [4, 1, 3, 2],
                   "B": ["w", "x", "y", "z"]})

sorted_df = df.sort_values(by="A", ascending=False)
```

### 5.2.4 缺失值处理
#### 5.2.4.1 isnull与notnull函数
isnull函数用于判断某个值是否为空，返回逻辑值Series；notnull函数则相反，用于判断某个值是否非空。语法如下：

```python
df[pd.isnull(df)]            # 判断某列所有值为NaN/NaT的值
df[pd.notnull(df)]           # 判断某列所有值为非NaN/NaT的值
```

举例如下：

```python
df = pd.DataFrame({
    "A": [None, None, 3, 4],
    "B": [1, np.nan, 5, None]
})

print(pd.isnull(df))          # 判断某列所有值为NaN/NaT的值
print(pd.notnull(df))         # 判断某列所有值为非NaN/NaT的值
```

#### 5.2.4.2 fillna函数
fillna函数用于填充空值，语法如下：

```python
fillna_df = df.fillna(value=fill_value, method=method, limit=limit)
```

- value：需要填充的固定值，如果不填写默认采用前一个有效值；
- method：指定填充方式，包括ffill（向前填充）、bfill（向后填充）、interpolate（线性插值）；
- limit：仅当method为pad/backfill时生效，表示向前向后填充的最大长度。

举例如下：

```python
df = pd.DataFrame({
    "A": [1, np.nan, 3, 4],
    "B": [1, 2, np.nan, 4]
})

filled_df = df.fillna(value=-1)                                    # 替换为固定值
interpolated_df = df.fillna(method="interpolate")                # 插值填补
padded_df = df.fillna(method="pad", limit=1)                     # 向前填充
backfilled_df = df.fillna(method="backfill", limit=1)             # 向后填充
```

#### 5.2.4.3 dropna函数
dropna函数用于删除含有空值的行或列，语法如下：

```python
dropna_df = df.dropna(how=how, axis=axis, thresh=thresh)
```

- how：删除规则，包括any（只要含有空值就删除）、all（全部为空才删除）；
- axis：0表示删除行，1表示删除列；
- thresh：当某行或某列的非空值个数小于指定阈值时，也会被删除。

举例如下：

```python
df = pd.DataFrame({
    "A": [1, np.nan, 3, 4],
    "B": [1, 2, np.nan, 4],
    "C": []
})

any_dropped_df = df.dropna(how="any")                  # 删除含空值行
all_dropped_df = df.dropna(how="all")                  # 删除全部为空值行
row_dropped_df = df.dropna(how="any", axis=0, thresh=2)    # 删除至少含2个非空值行
column_dropped_df = df.dropna(how="any", axis=1)         # 删除含空值的列
```

### 5.2.5 合并与拆分
#### 5.2.5.1 merge函数
merge函数用于合并多个DataFrame，语法如下：

```python
merged_df = pd.merge(left, right, on=on, how=how, left_on=left_on,
                     right_on=right_on, suffixes=suffixes, indicator=indicator)
```

- on：指定连接字段，根据该字段匹配两张表中的行；
- how：指定合并方式，inner表示只保留两个表的交集，outer表示保留所有行，left表示保留左边表的所有行，right表示保留右边表的所有行；
- left_on、right_on：分别指定左表、右表的连接字段；
- suffixes：设置不同列名的后缀，默认为(_x,_y)。

举例如下：

```python
left_df = pd.DataFrame({
    "key": ["K0", "K1", "K2", "K3"],
    "A": ["A0", "A1", "A2", "A3"],
    "B": ["B0", "B1", "B2", "B3"]
})

right_df = pd.DataFrame({
    "key": ["K0", "K1", "K2", "K4"],
    "C": ["C0", "C1", "C2", "C4"],
    "D": ["D0", "D1", "D2", "D4"]
})

merged_df = pd.merge(left_df, right_df, on="key")
```

#### 5.2.5.2 concat函数
concat函数用于将多个DataFrame或Series连接成单个DataFrame，语法如下：

```python
concat_df = pd.concat(objs, axis=axis, join=join, ignore_index=ignore_index, keys=keys, levels=levels, names=names, verify_integrity=verify_integrity)
```

- objs：一个或多个Series或DataFrame；
- axis：指定连接轴，0表示竖直方向，1表示水平方向；
- join：指定连接方式，outer表示只保留两个表的并集，inner表示只保留两个表的交集；
- ignore_index：忽略原始索引，重新建立一个索引；
- keys：给连接后的对象加上层级索引；
- levels：层级索引的名字；
- names：列名。

举例如下：

```python
seriess = [
    pd.Series(["a", "b", "c"]),
    pd.Series(["e", "f", "g"])
]

df1 = pd.DataFrame({
    "key": ["K0", "K1", "K2"],
    "A": ["A0", "A1", "A2"]
})

df2 = pd.DataFrame({
    "key": ["K0", "K1", "K3"],
    "B": ["B0", "B1", "B3"]
})

concatenated_df = pd.concat(seriess, axis=1)
multilevel_df = pd.concat([df1, df2], keys=["level1", "level2"], axis=0)
```

#### 5.2.5.3 拆分
使用split函数可以将DataFrame按照某一列拆分成多个子表，语法如下：

```python
dfs = df.str.split(pat=sep, n=-1, expand=True)
```

- pat：拆分字符，可以是一个正则表达式，也可以是一个字符串；
- n：拆分次数，默认为-1，表示所有匹配到的值都拆分出来。

举例如下：

```python
df = pd.DataFrame({
    "A": ["aa,bb,cc", "dd,ee", ",gg,hh"],
    "B": range(3)
})

splitted_df = df.A.str.split(",", expand=True).stack().reset_index(level=1, drop=True)
```