
作者：禅与计算机程序设计艺术                    
                
                
随着人工智能、云计算、容器技术等新兴技术的不断涌现和深入应用，越来越多的企业和组织都将重点放在自身的AI系统开发及管理之上，面临分布式环境下的AI系统的高可用性和可靠性问题，如何构建并实施一个可用的分布式AI系统架构，成为日益重要的一课。本文将详细阐述AI系统高可用性架构的设计和实现过程，包括但不限于分布式AI系统的关键技术、组件、模型和方法论，帮助读者掌握AI系统在实际生产中的部署和运维技巧。

# 2.基本概念术语说明
## 分布式计算
分布式计算是指由不同计算机节点（计算机或设备）上的多项计算任务组成的并行工作流，通过网络进行通信协调处理，能够将复杂的计算任务划分为多个相互独立的子任务，将这些子任务分别分布到不同的计算机上执行，最后再集中结果处理获得最终结果的一种计算方式。通过集群化的方式，分布式计算能够提升系统整体资源利用率和计算能力，极大的提升了计算机的利用效率和处理能力。分布式计算的主要特征就是计算过程是分散在多个节点上的，每个节点只负责一部分数据和运算，可以并行计算，从而降低了系统的响应时间，提高了系统的处理能力。

## 云计算
云计算是一种基于网络的数据中心基础设施服务，它提供按需付费的虚拟服务器资源，通过互联网提供云端存储、云端数据库、云端计算等业务功能。它可以有效解决IT的“超大规模”、“碎片化”、“动态”、“高速增长”的问题。云计算服务的优势在于：
- 技术创新：云计算领域始终处于引领者地位，它对技术发展保持了积极的态度，向前迈进一步，充满了激情。比如，阿里巴巴旗下支付宝、天猫精灵等团队均是云计算领域的先锋。
- 降低成本：无论是在设备投资、硬件维护还是服务器租用，云计算都可以让用户享受到经济的红利。
- 提高产品ivity：云计算的采用促进了“产品化”思想，也就是将核心竞争力集中在业务层，降低了内部软件开发与维护的成本，同时也使得公司产品的迭代速度更快。
- 降低风险：云计算的使用也减少了对于IT基础设施的依赖，降低了云服务商所带来的风险，并且可以降低IT部门的管理成本。

## 容器技术
容器技术是一种轻量级虚拟化技术，能够将应用程序和其运行环境打包成一个文件，然后发布到任何支持容器技术的平台上。容器通过软件层面的隔离，能够为应用提供一致的运行环境，避免因环境配置不一致导致的兼容性问题，节省了大量的时间和资源。目前，主流的容器技术有Docker、Kubernetes等。

## 弹性伸缩
弹性伸缩是一种自动化技术，它根据系统的负载情况自动调整计算机系统的运行参数，使其能够满足不同需求下的计算性能。它可以在不需要中断服务的情况下，按需增加或者减少资源的使用，提高系统的可用性和运行效率。弹性伸缩的实现需要考虑很多因素，如机器学习算法、数据处理和存储、网络带宽、可用资源等，因此，要确保弹性伸缩的准确性和合理性至关重要。

## 可用性设计理念
可用性设计理念是关于提升服务质量和系统鲁棒性的一系列原则，其目标是通过降低系统故障率和单点故障导致的影响，来保证系统持续运行，实现系统的高可用性。可用性设计理念包括以下几方面：
- SLA（Service Level Agreement）：服务水平协议，定义了服务的级别目标及相应的服务质量指标，比如99%的响应时间要求、99.999%的可用性要求。SLA通常以月度甚至更长时间周期作为基准。
- 服务质量目标（Quality of Service Targets）：服务质量目标是指特定场景下的期望值，如系统响应时间要求、可用性要求等。它们由性能指标、容量指标、可靠性指标等构成，用来衡量系统的服务质量。
- 冗余设计（Redundancy Design）：冗余设计是指为了防止系统中的单个组件出现故障，选择创建多个相同的组件，以提升系统的可靠性。冗余设计还可以防止因外部原因造成的故障，例如电源供应问题、天气变化等。
- 系统失效预测和分析（Failure Prediction and Analysis）：系统失效预测和分析是系统健壮性的关键，因为系统的稳定性取决于许多方面，包括硬件、软件、环境、人的因素等。系统的失效预测和分析主要依据以下几类技术：
    - 数据采集：监控系统会收集各种各样的数据，包括系统指标、日志、异常行为、系统调用等，用于预测系统的失效。
    - 模型训练：系统模型是描述系统行为的一些统计规律，比如CPU使用率的正态分布、网络带宽的负相关关系等。系统模型训练通过对已有的数据进行学习，来预测未来可能发生的错误。
    - 控制策略：控制策略是一种动态调整系统运行参数的机制，当系统产生错误时，控制策略会调整系统的参数以减小错误的影响。比如，当系统响应时间较慢时，控制策略可能会增加服务线程数量，以减小延迟；当系统响应超时时，控制策略可能会增加连接池大小，以提升系统的吞吐量。
    - 模糊测试：模糊测试是一种模拟真实用户请求的测试方法，通过发送虚假请求并检测系统是否正确响应，来发现系统中的潜在问题。

## 分布式AI系统高可用性的设计原则
分布式AI系统的高可用性主要由以下三个原则决定：
- 分布式特征：分布式环境中存在多个节点，每个节点都有自己的内存空间、计算资源、存储空间等。为了实现高可用性，分布式AI系统需要在多个节点之间进行数据同步、消息通信，并保证数据的完整性和一致性。
- 可靠性：分布式AI系统具有高度的可靠性要求，不能因为某些节点或网络出现问题，而导致整个系统无法正常运行。为了实现高可用性，分布式AI系统需要设计出能够容忍节点失败、失效的容错设计。
- 并行计算：分布式AI系统需要进行并行计算，提升系统的计算性能。为了实现高可用性，分布式AI系统需要对计算任务进行切分并分配到不同节点上，并采用异步通信模式，减少等待时间，避免单点故障。

# 3.核心算法原理和具体操作步骤以及数学公式讲解
## 概览
本节将介绍分布式AI系统的关键技术、组件、模型和方法论。首先，本章将介绍分布式AI系统的特点，即其计算模型需要考虑不同节点之间的数据同步、计算任务切分、通信和故障恢复等，才能实现高效的并行计算。然后，将详细介绍AI系统的编码和模型训练过程，主要包括神经网络的设计、训练算法、训练数据集、调参策略等。之后，将介绍高可用性设计的过程，如容错设计、可靠性评估、服务降级策略等。最后，将介绍基于弹性云架构的分布式AI系统部署实践。

## 分布式计算
分布式计算是指由不同计算机节点上的多项计算任务组成的并行工作流，通过网络进行通信协调处理，能够将复杂的计算任务划分为多个相互独立的子任务，将这些子任务分别分布到不同的计算机上执行，最后再集中结果处理获得最终结果的一种计算方式。通过集群化的方式，分布式计算能够提升系统整体资源利用率和计算能力，极大的提升了计算机的利用效率和处理能力。分布式计算的主要特征就是计算过程是分散在多个节点上的，每个节点只负责一部分数据和运算，可以并行计算，从而降低了系统的响应时间，提高了系统的处理能力。

### 分布式计算的优势
- 利用率提升：分布式计算能够提升系统整体资源利用率，降低了资源浪费率，显著提升了计算机系统的整体利用率。
- 更高的处理能力：由于计算任务被分散到不同的节点上并行计算，分布式计算能够提升系统的处理能力，适应更多的计算密集型任务。
- 异地多活：分布式计算可以实现异地多活，在局部区域内部署多套分布式集群，以减少单点故障影响。
- 更加灵活的部署方案：分布式计算的部署方案可以根据需求灵活选择，如物理机、云主机、虚拟机、容器等。

### 分布式计算的难点
- 分布式系统编程难度：分布式计算涉及到多个节点间的通信和数据同步，需要了解分布式系统编程的基本知识和方法。
- 一致性：分布式计算的计算结果和状态需要满足分布式系统的一致性，否则将无法正常运行。
- 性能调优：分布式计算系统需要进行系统的性能调优，才能提升计算的效率。

### 一致性协议
分布式计算环境下，各个节点之间需要进行数据同步和通信，因此需要共同遵守一定的协议，来保证数据同步和一致性。常用的一致性协议有以下几种：
- Paxos：是一种基于消息传递的一致性算法，属于容错算法，用于解决分布式计算中多个节点的值（数据）一致性问题。
- Raft：是一种复制状态机的一致性算法，用于管理服务集群中服务器的状态变更，以保证集群中各服务器的数据副本相同。
- Gossip：是一种去中心化的基于传播通信的协议，用于在分布式环境中快速发现节点的存在并进行通信。

### MapReduce
MapReduce 是 Google 提出的分布式计算框架，其目的是处理海量的数据，通过把数据划分为 M 个分片，并对每一个分片进行并行计算，将所有结果汇总得到最终结果。MapReduce 的具体操作步骤如下：

1. Map 阶段：对输入数据集中的每一条记录，对每个分片执行一次映射函数，生成中间结果。
2. Shuffle 和 Sort 阶段：对中间结果进行排序，合并同一个分片的中间结果，形成最终结果。
3. Reduce 阶段：对最终结果进行归约，处理多个分片的中间结果，生成最终结果。

### Spark
Apache Spark 是开源的分布式计算框架，其提供了丰富的 API 来支持内存计算、交互式查询以及复杂的 ETL（Extract Transform Load）工作流。Spark 的具体操作步骤如下：

1. 创建一个 SparkContext 对象，用于连接集群并创建一个 SparkSession。
2. 通过 DataFrame 或 DataSet API 来创建数据集。
3. 使用 transformation 操作来对数据集进行转换，得到新的 DataFrame 或 DataSet。
4. 使用 action 操作来触发计算并获取结果。

### Hadoop
Hadoop 是 Apache 基金会提出的分布式文件系统，能够对大规模数据进行并行的、分布式的处理。Hadoop 最早由 Nutch 发明，用于搜索引擎的爬虫项目。Hadoop 的具体操作步骤如下：

1. HDFS：Hadoop Distributed File System（HDFS），是一个分布式的文件系统。
2. MapReduce：MapReduce 是一个编程模型，用于并行处理海量的数据。
3. YARN：Yet Another Resource Negotiator（另一种资源协调器），用于调度和管理 Hadoop 集群中的资源。

## AI系统编码和模型训练过程
深度学习（Deep Learning）是近年来热门的机器学习技术，其成功的原因在于其巨大的计算能力。深度学习的关键在于对大量数据进行高效的训练，而这也是分布式AI系统关注的核心。

### 深度学习简介
深度学习是指基于神经网络的机器学习技术。其基本思想是模仿生物神经网络结构，在数据层次上建立起多个网络层，逐层学习，最终学习到数据的表示和推理过程。与其他机器学习算法相比，深度学习具有独特的特征。首先，它是高度非线性的，能够捕捉输入数据的复杂特性；其次，它在学习过程中通过反馈权重更新模型参数，而不是像普通机器学习那样基于损失函数优化参数；最后，它具有一定的正则化特性，防止过拟合。

### 深度学习的分类
深度学习可以分为两大类：
- 端到端（End-to-end）：一般指训练完成后直接使用机器学习模型进行预测或识别，不需要手工设计特征或预处理。典型的应用如图像分类、文本分类等。
- 结构化（Structured）：一般指通过设计神经网络结构、损失函数、正则化方式来控制模型的复杂度。典型的应用如卷积神经网络（CNN）、循环神经网络（RNN）、递归神经网络（RNN）等。

### 深度学习的学习过程
深度学习的学习过程可以分为四步：
1. 数据准备：获取、清洗和预处理数据。
2. 神经网络的设计：选择相应的模型架构，设计神经网络结构，设置损失函数、正则化方式等。
3. 模型训练：通过反向传播算法对模型进行训练，更新模型参数。
4. 结果评估：使用验证数据集或测试数据集评估模型效果。

### 深度学习的训练算法
深度学习的训练算法有三种：
- 随机梯度下降法（SGD）：这是最原始的、最简单的、最易实现的训练算法。它的基本思路是计算梯度（损失函数对模型参数的导数），沿着梯度方向更新模型参数，直到模型训练收敛。
- 小批量梯度下降法（Mini-batch SGD）：它结合了 SGD 的简单性和泛化性能，允许使用小批量数据进行训练。
- 动量法（Momentum）：它试图克服小批量梯度下降法的局部最优问题，其基本思路是对当前梯度方向进行惯性校正，避免陷入局部最小值或震荡。

### 数据集的选取
数据集的选取对深度学习的效果影响很大。如果数据集的特征没有明显的偏差，那么采用单一的任务相关数据集效果比较好。如果数据集的特征高度相关，例如图像数据，可以采用强相关性的数据集，同时需要进行数据增强。但是，如果数据集没有明显的标签，或者难以区分，那么数据集就没有办法用于训练。另外，不同类型的数据集（如音频、视频、文本）需要使用不同的模型架构，所以数据集的选取需要根据任务特点和模型架构进行调整。

### 模型的性能评估
模型的性能评估包括两个方面：
- 准确度：准确度是指预测正确的结果占所有预测结果的比例。
- 误报率（False Positive Rate，FPR）：误报率是指假阳性的概率，即预测为阳性的实际为阴性的比例。

为了改善模型的性能，可以通过以下方法：
- 正则化：正则化是指通过添加模型复杂度限制，来减缓模型过拟合，同时保证模型泛化能力。常用的正则化方式有 L1/L2 范数正则化、dropout、Batch Normalization 等。
- 数据增强：数据增强是指对原始数据进行变换，提升模型的鲁棒性和泛化性能。常用的数据增强方法有翻转、裁剪、缩放、旋转、颜色变换等。
- 集成学习：集成学习是指训练多个模型，通过平均或投票的方法得到最终结果。常用的集成学习方法有 Bagging、Boosting、Stacking 等。

### 模型部署
深度学习模型的部署主要有两种方式：
- 测试：一般在开发环境下，使用测试数据集来验证模型的性能。
- 线上：将训练好的模型部署到线上环境，通过在线接口或API接口接受输入数据，输出模型预测结果。

## AI系统的高可用性设计
分布式AI系统的高可用性设计需要注意以下几个方面：
- 容错设计：为了保证分布式AI系统的高可用性，需要对系统的节点、网络、存储等各个环节进行容错设计。容错设计可以分为如下三种：
    - 冗余设计：通过在不同的位置部署多个相同的组件，来减小单点故障对系统的影响。
    - 异步通信：异步通信可以避免同步通信存在的延迟问题，提高系统的并发度和性能。
    - 检查点和重启机制：为了保证系统的持久性，需要对计算任务进行切分并保存到磁盘，并在发生故障时恢复任务。
- 可靠性评估：为了对分布式AI系统的可靠性进行评估，需要对系统的每一个环节进行分析，包括硬件设备、软件、数据、服务等。评估过程包括以下几个步骤：
    - 自监控：对系统自身的状态进行监控，如硬件资源、负载、组件状态等。
    - 链路监控：对系统的所有组件之间的通信情况进行监控，判断网络传输或组件故障是否会导致系统的不可用。
    - 数据监控：对系统处理的数据进行监控，判断数据损坏、丢失、错误是否会导致系统的不可用。
    - 服务监控：对系统的服务质量进行监控，判断服务是否正常运行。
- 服务降级策略：为了提升系统的可靠性和鲁棒性，当系统的性能和资源达到瓶颈时，可以通过降级策略提升系统的服务质量，从而避免系统的崩溃。降级策略可以分为以下两种：
    - 暂停策略：暂停策略是指停止所有任务，并降低系统的响应速度。
    - 削峰策略：削峰策略是指采用波动性的流量控制策略，根据负载情况调整系统的负载。

## 基于弹性云架构的分布式AI系统部署实践
基于弹性云架构的分布式AI系统部署实践主要包括以下几个方面：
- 资源调配与编排：为了能够弹性伸缩分布式AI系统，需要对系统的硬件资源进行自动调配和编排。资源调配与编排需要考虑的因素有：硬件规格、网络带宽、存储空间、计算资源等。
- 安全策略与访问控制：为了保护分布式AI系统的隐私和安全，需要制定合理的安全策略和访问控制措施。安全策略需要考虑的内容包括身份认证、访问控制、加密传输等。
- 服务发现与负载均衡：为了保证分布式AI系统的高可用性，需要对系统的服务进行发现和负载均衡。服务发现与负载均衡需要考虑的内容包括服务注册、健康检查、服务路由等。
- 自动化部署与运维：为了实现自动化部署和运维，需要提升研发、测试和运维人员的专业素养，使用自动化工具和流程来部署和运维系统。自动化部署与运维需要考虑的内容包括：CI/CD流水线、配置文件模板、日志监控、事件通知、备份恢复、容量规划、容错恢复等。
- 故障诊断与追踪：为了对分布式AI系统进行故障诊断和问题追踪，需要建立全面的监控体系，收集系统的状态信息、日志、指标等，并制定故障处理策略。

# 4.具体代码实例和解释说明
## 基于Kubernetes的分布式AI系统架构设计与部署
本节将以基于Kubernetes的分布式AI系统架构设计与部署为例，详细阐述基于弹性云架构的分布式AI系统部署实践。本例中，我们将以机器视觉的案例来展示分布式AI系统架构设计与部署实践。机器视觉是人工智能的一个重要分支，通过计算机摄像头和图像处理单元进行机器视觉任务。

![基于Kubernetes的分布式AI系统架构设计与部署](https://img1.baidu.com/it/u=2770683195,415234680&fm=26&fmt=auto)

### Kubernetes简介
Kubernetes 是 Google、CoreOS、RedHat、CloudFoundry 等众多云厂商、容器技术公司和开源社区共同发起的开源系统，其通过容器和微服务的管理平台，提供一种新的分布式系统调度和部署方案。Kubernetes 可以跨云和本地环境部署容器化的应用程序，支持动态扩展，并提供强大的扩展性和自动化。

Kubernetes 的主要功能包括：
- 支持动态部署和扩展：Kubernetes 可以动态部署和扩展容器化的应用程序，根据实际需求扩容或缩容。
- 自动化服务发现和负载均衡：Kubernetes 提供基于 DNS 和 RESTful 接口的服务发现与负载均衡。
- 透明的服务间通信：Kubernetes 为容器提供安全的服务间通信，支持 intra-cluster 和 inter-cluster 的通信。
- 完备的生命周期管理：Kubernetes 提供完善的生命周期管理，包括部署、升级、回滚、自动伸缩等。
- 有状态应用的持久化存储：Kubernetes 支持基于 PVC 的持久化存储，提供高可靠性的存储服务。

### 机器视觉系统架构设计
机器视觉系统的架构设计主要包括以下几个方面：
- 算法模块：机器视觉任务的核心算法模块。
- 数据存储模块：负责数据存储和检索。
- 模型训练模块：负责模型的训练。
- 任务调度模块：负责任务的调度和执行。

![基于Kubernetes的分布式AI系统架构设计与部署-算法模块](https://img2.baidu.com/it/u=1521595862,2686611272&fm=26&fmt=auto)

![基于Kubernetes的分布式AI系统架构设计与部署-数据存储模块](https://img0.baidu.com/it/u=2276703820,270144114&fm=26&fmt=auto)

![基于Kubernetes的分布式AI系统架构设计与部署-模型训练模块](https://img2.baidu.com/it/u=2165700653,253987832&fm=26&fmt=auto)

![基于Kubernetes的分布式AI系统架构设计与部署-任务调度模块](https://img2.baidu.com/it/u=1262604521,1161505290&fm=26&fmt=auto)

### Kubernetes 集群部署
下面将详细介绍 Kubernetes 集群的部署，包括节点规划、安装 Docker CE、安装 kubectl 命令行工具、配置镜像仓库、配置 Helm CLI、安装 Kubernetes Dashboard、安装 Kubernetes Metrics Server 等。

#### 节点规划
一般来说，机器视觉系统的计算节点和存储节点可以根据业务需求进行规划。根据集群规模和负载情况，我们可以规划出相应的计算节点数量、存储节点数量和磁盘数量。下面给出了一个示例的节点规划：

| 名称   | IP地址         | CPU       | 内存(GB)      | GPU    | 硬盘(TB)     | 描述          |
|--------|----------------|-----------|---------------|--------|--------------|---------------|
| master | 192.168.100.10 | 4cores+   | 16G           | None   | 2x500 SSD    | Master节点    |
| worker | 192.168.100.11 | 4cores+   | 16G           | 2*P100 | 2x1.5T SAS   | Worker节点    |
|        |                |           |               |        |              |               |

#### 安装 Docker CE
为了运行 Kubernetes，我们需要安装 Docker CE。下面给出了 Ubuntu 18.04 LTS 上 Docker CE 的安装命令：

```bash
sudo apt-get update && sudo apt-get install \
    apt-transport-https \
    ca-certificates \
    curl \
    gnupg-agent \
    software-properties-common
    
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

sudo apt-get update && sudo apt-get install docker-ce docker-ce-cli containerd.io
```

#### 安装 kubectl 命令行工具
为了使用 Kubernetes 命令行工具kubectl，我们需要安装最新版本的kubectl。下面给出了 Ubuntu 18.04 LTS 上 kubectl 的安装命令：

```bash
sudo curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl

chmod +x./kubectl

mv./kubectl /usr/local/bin/kubectl
```

#### 配置镜像仓库
一般情况下，Kubernetes 需要配置一个镜像仓库用于拉取镜像。为了方便管理镜像，我们建议配置私有镜像仓库。下面给出了一个示例的配置，供参考：

```yaml
apiVersion: v1
kind: Config
preferences: {}
clusters:
- cluster:
    server: <镜像仓库地址>
  name: my-cluster
contexts:
- context:
    cluster: my-cluster
    user: ""
  name: my-context
current-context: my-context
users: []
```

#### 配置 Helm CLI
Helm 是 Kubernetes 包管理器。为了方便管理 Kubernetes 应用，我们可以使用 Helm 将应用打包为 Chart，并发布到 Kubernetes 集群。下面给出了一个 Ubuntu 18.04 LTS 上 Helm 的安装命令：

```bash
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get | bash
```

#### 安装 Kubernetes Dashboard
Kubernetes Dashboard 是 Kubernetes 中的 Web UI。它包含了大量的集群资源，并且可以通过浏览器查看和管理集群。下面给出了一个 Ubuntu 18.04 LTS 上 Kubernetes Dashboard 的安装命令：

```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml

kubectl proxy --port=8080 &
```

#### 安装 Kubernetes Metrics Server
Metrics Server 是 Kubernetes 中用于集群监控的组件。它可以提供集群中资源的使用情况和指标，包括 CPU 使用情况、内存使用情况、Pod 的指标、节点的指标等。下面给出了一个 Ubuntu 18.04 LTS 上 Kubernetes Metrics Server 的安装命令：

```bash
wget https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

kubectl create ns kube-system

kubectl apply -f components.yaml
```

#### Kubernetes 集群配置
在 Kubernetes 集群中，需要创建一个默认的命名空间，并开启集群DNS、Web UI Dashboard和Metrics Server等插件。下面给出了一个示例的配置，供参考：

```yaml
---
apiVersion: v1
kind: Namespace
metadata:
  labels:
    kubernetes.io/metadata.name: default
  name: default
---
apiVersion: helm.fluxcd.io/v1
kind: HelmRelease
metadata:
  name: coredns
  namespace: kube-system
spec:
  releaseName: coredns
  chart:
    repository: https://charts.bitnami.com/bitnami
    name: coredns
    version: 1.10.2
  values:
    replicaCount: 1
    podAnnotations:
      prometheus.io/scrape: 'true'
      prometheus.io/path: '/metrics'
      prometheus.io/port: '9153'
    nodeSelector: {}
    resources:
      requests:
        cpu: 5m
        memory: 50Mi
      limits:
        cpu: 1000m
        memory: 2000Mi
    priorityClassName: system-cluster-critical
    tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: admin-user
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: admin-user
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
- kind: ServiceAccount
  name: admin-user
  namespace: kube-system
---
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: '1'
  creationTimestamp: null
  labels:
    k8s-app: dashboard-metrics-scraper
  name: dashboard-metrics-scraper
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: dashboard-metrics-scraper
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: dashboard-metrics-scraper
    spec:
      containers:
      - args:
        - --secure-listen-address=0.0.0.0:8443
        - --upstream=http://127.0.0.1:8080/
        - --logtostderr=true
        - --v=10
        image: gcr.io/google_containers/addon-resizer:1.8.7
        imagePullPolicy: Always
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
        name: dashboard-metrics-scraper
        ports:
        - containerPort: 8080
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 30
        resources:
          requests:
            cpu: 100m
            memory: 30Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
              - ALL
            add:
              - NET_BIND_SERVICE
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 1000
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /tmp
          name: tmp-dir
      dnsPolicy: Default
      enableServiceLinks: true
      nodeName: master
      priority: 2000000000
      restartPolicy: Always
      schedulerName: default-scheduler
      serviceAccountName: admin-user
      serviceAccount: admin-user
      terminationGracePeriodSeconds: 30
      tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      volumes:
      - emptyDir: {}
        name: tmp-dir
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: 100m
  name: kubernetes-dashboard
  namespace: kube-system
  labels:
    addonmanager.kubernetes.io/mode: Reconcile
spec:
  rules:
    - host: dashboard.<域名>
      http:
        paths:
        - backend:
            serviceName: kubernetes-dashboard
            servicePort: 443
          pathType: ImplementationSpecific
  tls:
    - hosts:
        - dashboard.<域名>
      secretName: wildcard-tls-secret

