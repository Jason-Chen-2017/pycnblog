                 

关键词：联邦学习、数据隐私、技术创业、合作模型、算法优化、应用实践

> 摘要：本文将深入探讨联邦学习在技术创业中的应用，特别是在数据协作与隐私保护方面的挑战和机遇。通过详细阐述联邦学习的基本概念、核心算法原理、数学模型及其在具体项目中的实践应用，文章旨在为创业者提供一种新型的数据协作与隐私保护方案，助力他们在竞争激烈的市场中脱颖而出。

## 1. 背景介绍

在当今数字化时代，数据已经成为企业最重要的资产之一。然而，随着数据规模的不断扩大和数据类型的日益复杂，如何有效地利用这些数据同时确保用户隐私成为了一个亟待解决的问题。传统的集中式数据处理方法在数据安全性和隐私保护方面存在较大风险，而分布式数据处理方法虽然具有一定的隐私保护能力，但仍然难以实现高效的数据协作。

联邦学习（Federated Learning）作为一种新兴的分布式机器学习技术，提供了一种在保障数据隐私的同时实现协同学习的解决方案。它通过在多个参与者之间共享学习模型而非原始数据，从而避免了数据泄露的风险，同时也实现了数据价值的最大化。联邦学习的这一特性使其在技术创业领域具有广泛的应用前景。

本文旨在探讨联邦学习在技术创业中的关键作用，分析其在数据协作与隐私保护方面的优势，并通过具体案例和实践，展示联邦学习的实际应用价值。

## 2. 核心概念与联系

### 联邦学习的基本概念

联邦学习是一种分布式机器学习技术，其核心思想是在多个参与者（通常是数据拥有者和用户提供）之间共享学习模型，而不是共享原始数据。在联邦学习过程中，每个参与者在自己的本地数据集上训练模型，并将模型的更新（梯度）发送给中心服务器。中心服务器综合所有参与者的更新，生成全局模型，然后反馈给各个参与者。这一过程不断迭代，直到达到预定的模型性能或迭代次数。

### 联邦学习的架构

联邦学习的架构通常包括以下几个关键组成部分：

1. **中心服务器**：负责协调和管理整个联邦学习过程，包括初始化全局模型、收集参与者更新、生成全局模型并反馈给参与者。
2. **参与者**：可以是数据拥有者（如企业、医疗机构）或用户。参与者负责在自己的本地数据集上训练模型，并将模型的更新发送给中心服务器。
3. **通信网络**：负责参与者与中心服务器之间的数据传输。

### 联邦学习的工作流程

联邦学习的工作流程通常包括以下几个步骤：

1. **初始化全局模型**：中心服务器初始化一个全局模型，并将其发送给所有参与者。
2. **本地训练**：每个参与者在自己的本地数据集上使用全局模型进行训练，并计算模型的梯度。
3. **更新发送**：参与者将本地计算的梯度发送给中心服务器。
4. **全局模型更新**：中心服务器收集所有参与者的梯度，生成新的全局模型。
5. **模型反馈**：中心服务器将新的全局模型发送回给所有参与者。
6. **迭代重复**：重复上述步骤，直到达到预定的模型性能或迭代次数。

### 联邦学习与数据协作

联邦学习在数据协作方面具有显著优势。首先，它允许不同机构或用户在不共享原始数据的情况下共享数据价值，从而实现了数据价值的最大化。其次，联邦学习通过分布式计算，提高了数据处理的速度和效率。此外，联邦学习还能够处理不同格式和结构的数据，使其在多样化的数据环境中具有广泛的适用性。

### 联邦学习与隐私保护

联邦学习在隐私保护方面也具有独特的优势。由于联邦学习不共享原始数据，因此显著降低了数据泄露的风险。同时，联邦学习通过加密技术、差分隐私等技术手段，进一步增强了数据的隐私保护能力。

### Mermaid 流程图

```mermaid
graph TD
    A[初始化全局模型] --> B[本地训练]
    B --> C[更新发送]
    C --> D[全局模型更新]
    D --> E[模型反馈]
    E --> B
```

在这个流程图中，A代表初始化全局模型，B表示本地训练，C表示更新发送，D表示全局模型更新，E表示模型反馈。这个流程图清晰地展示了联邦学习的工作流程。

## 3. 核心算法原理 & 具体操作步骤

### 3.1 算法原理概述

联邦学习算法的核心思想是通过分布式计算和协作，在保护数据隐私的同时实现机器学习模型的优化。具体来说，联邦学习算法通过以下步骤实现：

1. **模型初始化**：中心服务器初始化全局模型，并将其发送给所有参与者。
2. **本地训练**：参与者使用全局模型在自己的本地数据集上进行训练，并计算模型的梯度。
3. **梯度聚合**：参与者将本地计算的梯度发送给中心服务器，中心服务器对梯度进行聚合。
4. **模型更新**：中心服务器根据聚合后的梯度更新全局模型，并将更新后的模型发送回参与者。
5. **迭代优化**：参与者使用更新后的全局模型进行新一轮的本地训练，并重复上述过程，直到达到预定的模型性能或迭代次数。

### 3.2 算法步骤详解

#### 3.2.1 模型初始化

在联邦学习算法的开始阶段，中心服务器初始化全局模型。这个全局模型可以是随机初始化的，也可以是基于先验知识的初始化。初始化后的全局模型将被发送给所有参与者。

#### 3.2.2 本地训练

参与者接收到全局模型后，在自己的本地数据集上使用该模型进行训练。在训练过程中，参与者需要计算模型的梯度。梯度是模型参数变化的一个度量，它反映了模型在训练过程中的学习效果。

#### 3.2.3 梯度聚合

参与者将本地计算得到的梯度发送给中心服务器。中心服务器负责收集所有参与者的梯度，并对这些梯度进行聚合。梯度聚合的方法可以是简单的平均值，也可以是更复杂的加权平均。

#### 3.2.4 模型更新

中心服务器根据聚合后的梯度更新全局模型。更新的模型将反映所有参与者的训练效果，从而实现全局模型的优化。

#### 3.2.5 模型反馈

更新后的全局模型将被发送回所有参与者。参与者将使用这个新的全局模型进行新一轮的本地训练。

#### 3.2.6 迭代优化

参与者重复进行本地训练、梯度聚合、模型更新和模型反馈的过程，直到达到预定的模型性能或迭代次数。通过这种迭代优化，联邦学习算法能够逐步提高模型的性能，并最终实现模型的优化。

### 3.3 算法优缺点

#### 优点

1. **数据隐私保护**：联邦学习通过不共享原始数据的方式，有效保护了用户的隐私。
2. **分布式计算**：联邦学习允许参与者在本地进行训练，从而降低了数据传输和计算成本。
3. **灵活性**：联邦学习适用于多种数据类型和场景，具有很高的灵活性。

#### 缺点

1. **通信成本**：联邦学习需要频繁地在参与者和中心服务器之间传输梯度，这可能会带来较高的通信成本。
2. **计算复杂性**：联邦学习算法的复杂度较高，需要一定的计算资源和时间。

### 3.4 算法应用领域

联邦学习在多个领域具有广泛的应用前景，包括但不限于：

1. **金融**：通过联邦学习，金融机构可以在保护客户隐私的同时，实现更精准的风险评估和欺诈检测。
2. **医疗**：联邦学习可以用于医疗数据的分析，帮助医疗机构实现个性化的诊断和治疗。
3. **电子商务**：联邦学习可以帮助电子商务平台实现个性化的推荐系统，提高用户体验和销售额。
4. **工业互联网**：联邦学习可以用于工业互联网中的设备监控和故障预测，提高生产效率。

## 4. 数学模型和公式 & 详细讲解 & 举例说明

### 4.1 数学模型构建

联邦学习中的数学模型主要涉及两个方面：模型参数的更新和梯度的计算。

#### 4.1.1 模型参数更新

设全局模型参数为 $w^0$，参与者 $i$ 的本地模型参数为 $w_i^0$。在联邦学习过程中，全局模型参数通过以下公式进行更新：

$$
w^t = \frac{1}{n} \sum_{i=1}^{n} w_i^t
$$

其中，$w^t$ 表示第 $t$ 次迭代的全局模型参数，$w_i^t$ 表示参与者 $i$ 在第 $t$ 次迭代后的本地模型参数。

#### 4.1.2 梯度计算

在联邦学习过程中，每个参与者需要计算全局模型参数相对于本地数据集的梯度。设损失函数为 $L(w)$，参与者 $i$ 的本地梯度为 $\nabla_w L(w_i^0)$，则全局梯度可以通过以下公式计算：

$$
\nabla_w L(w^0) = \frac{1}{n} \sum_{i=1}^{n} \nabla_w L(w_i^0)
$$

### 4.2 公式推导过程

#### 4.2.1 模型参数更新推导

设全局模型参数为 $w^0$，参与者 $i$ 的本地模型参数为 $w_i^0$。在联邦学习过程中，全局模型参数通过以下公式进行更新：

$$
w^t = \frac{1}{n} \sum_{i=1}^{n} w_i^t
$$

其中，$w^t$ 表示第 $t$ 次迭代的全局模型参数，$w_i^t$ 表示参与者 $i$ 在第 $t$ 次迭代后的本地模型参数。

这个公式的推导过程如下：

1. 假设全局模型参数在 $t-1$ 次迭代后为 $w^{t-1}$，参与者 $i$ 在第 $t-1$ 次迭代后的本地模型参数为 $w_i^{t-1}$。
2. 参与者 $i$ 在第 $t$ 次迭代时，使用全局模型参数 $w^{t-1}$ 在自己的本地数据集上训练，得到新的本地模型参数 $w_i^t$。
3. 参与者 $i$ 将新的本地模型参数 $w_i^t$ 发送给中心服务器。
4. 中心服务器收集所有参与者的本地模型参数，并计算平均值，得到新的全局模型参数 $w^t$。

因此，全局模型参数的更新公式为：

$$
w^t = \frac{1}{n} \sum_{i=1}^{n} w_i^t
$$

#### 4.2.2 梯度计算推导

在联邦学习过程中，每个参与者需要计算全局模型参数相对于本地数据集的梯度。设损失函数为 $L(w)$，参与者 $i$ 的本地梯度为 $\nabla_w L(w_i^0)$，则全局梯度可以通过以下公式计算：

$$
\nabla_w L(w^0) = \frac{1}{n} \sum_{i=1}^{n} \nabla_w L(w_i^0)
$$

这个公式的推导过程如下：

1. 假设全局模型参数为 $w^0$，参与者 $i$ 的本地模型参数为 $w_i^0$。
2. 参与者 $i$ 在自己的本地数据集上训练模型，得到损失函数 $L(w_i^0)$。
3. 参与者 $i$ 计算损失函数关于模型参数 $w_i^0$ 的梯度，即 $\nabla_w L(w_i^0)$。
4. 中心服务器收集所有参与者的梯度，并计算平均值，得到全局梯度 $\nabla_w L(w^0)$。

因此，全局梯度的计算公式为：

$$
\nabla_w L(w^0) = \frac{1}{n} \sum_{i=1}^{n} \nabla_w L(w_i^0)
$$

### 4.3 案例分析与讲解

#### 4.3.1 案例背景

假设有两个参与者 $A$ 和 $B$，他们各自拥有不同的数据集。参与者 $A$ 的数据集包含 1000 个样本，参与者 $B$ 的数据集包含 500 个样本。两个参与者希望通过联邦学习算法训练一个分类模型，用于预测某个变量的类别。

#### 4.3.2 模型初始化

中心服务器初始化全局模型参数 $w^0$，并将 $w^0$ 发送给参与者 $A$ 和 $B$。

#### 4.3.3 本地训练

参与者 $A$ 使用全局模型参数 $w^0$ 在自己的数据集上进行训练，得到新的本地模型参数 $w_A^1$。

参与者 $B$ 使用全局模型参数 $w^0$ 在自己的数据集上进行训练，得到新的本地模型参数 $w_B^1$。

#### 4.3.4 梯度聚合

参与者 $A$ 将本地模型参数 $w_A^1$ 发送给中心服务器。

参与者 $B$ 将本地模型参数 $w_B^1$ 发送给中心服务器。

中心服务器收集参与者 $A$ 和 $B$ 的本地模型参数，并计算平均值，得到新的全局模型参数 $w^1$。

#### 4.3.5 模型更新

中心服务器根据全局模型参数 $w^1$ 更新全局模型。

#### 4.3.6 模型反馈

中心服务器将新的全局模型参数 $w^1$ 发送给参与者 $A$ 和 $B$。

参与者 $A$ 和 $B$ 使用新的全局模型参数 $w^1$ 在自己的数据集上进行新一轮的训练。

#### 4.3.7 迭代优化

参与者 $A$ 和 $B$ 重复进行本地训练、梯度聚合、模型更新和模型反馈的过程，直到达到预定的模型性能或迭代次数。

通过这个案例，我们可以看到联邦学习算法在保护数据隐私的同时，实现了模型参数的优化。这个案例也展示了联邦学习算法的基本工作流程和关键步骤。

## 5. 项目实践：代码实例和详细解释说明

### 5.1 开发环境搭建

在本项目实践中，我们使用 Python 作为编程语言，利用 TensorFlow Federated（TFF）库实现联邦学习算法。首先，需要安装 TensorFlow 和 TFF：

```bash
pip install tensorflow tensorflow-federated
```

### 5.2 源代码详细实现

下面是一个简单的联邦学习项目实例，用于实现一个线性回归模型。

```python
import tensorflow as tf
import tensorflow_federated as tff

# 5.2.1 定义联邦学习算法
def build_model():
    # 定义线性回归模型
    model = tf.keras.Sequential([
        tf.keras.layers.Dense(units=1, input_shape=(1,))
    ])
    return model

# 5.2.2 定义损失函数和优化器
def linear_regression_model_fn():
    model = build_model()
    loss_fn = tf.keras.losses.MeanSquaredError()
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)
    return tff.learning.from_keras_model(
        model, loss_fn=loss_fn, optimizer=optimizer
    )

# 5.2.3 定义参与者训练过程
def train_on_batchROUND(model, batchROUND):
    model.fit(batchROUND[0], batchROUND[1], epochs=1)
    return model

# 5.2.4 定义中心服务器聚合函数
def federated_averageOURS(federated_model):
    return federated_model
```

### 5.3 代码解读与分析

在这个项目中，我们首先定义了一个线性回归模型，然后使用 TensorFlow Federated（TFF）库实现了联邦学习算法。以下是代码的关键部分及其解读：

- **线性回归模型**：我们使用 TensorFlow 的 `Sequential` 模型构建了一个简单的线性回归模型，该模型包含一个全连接层（`Dense`），输入层的大小为 1（因为我们处理的是一维数据）。

- **损失函数和优化器**：我们选择均方误差（`MeanSquaredError`）作为损失函数，并使用 Adam 优化器进行模型训练。

- **联邦学习模型**：使用 `tff.learning.from_keras_model` 函数，我们将 Keras 模型转换为 TFF 模型，以便进行联邦学习。

- **参与者训练过程**：`train_on_batchROUND` 函数定义了参与者在本地数据集上进行训练的过程。

- **中心服务器聚合函数**：`federated_averageOURS` 函数是一个简单的聚合函数，它将参与者的模型更新聚合为全局模型更新。

### 5.4 运行结果展示

以下是如何运行这个联邦学习项目：

```python
# 创建一个模拟的数据集
import numpy as np

def create_data(num_samples):
    np.random.seed(0)
    X = np.random.normal(size=(num_samples, 1))
    y = 3 * X + np.random.normal(size=(num_samples, 1))
    return X, y

num_samples = 100
X, y = create_data(num_samples)

# 运行联邦学习算法
tff_model = linear_regression_model_fn()
num_rounds = 10
state = tff_model.initialize()

for i in range(num_rounds):
    print(f"Starting round {i + 1}...")
    state = tff_model.next(state, [(X, y)])

# 打印全局模型参数
print("Global model parameters:", state.model.trainable_variables)
```

在这个项目中，我们创建了一个模拟的数据集，并使用 10 个迭代轮次运行联邦学习算法。最后，我们打印了全局模型参数，这些参数反映了联邦学习算法在多个参与者协作下的学习结果。

## 6. 实际应用场景

联邦学习在实际应用中展示了其强大的数据协作与隐私保护能力，以下是一些联邦学习在不同领域的应用案例：

### 6.1 金融

在金融领域，联邦学习可以帮助金融机构在保护用户隐私的同时，实现更精准的风险评估和欺诈检测。例如，银行可以使用联邦学习算法分析客户的交易数据，以识别潜在的风险和欺诈行为。由于联邦学习不共享客户的原始数据，因此有效保护了用户的隐私。

### 6.2 医疗

在医疗领域，联邦学习可以用于医疗数据的分析，帮助医疗机构实现个性化的诊断和治疗。例如，多家医院可以使用联邦学习算法共享医疗数据，以开发更精确的疾病预测模型。这种协作不仅提高了医疗数据的利用效率，还保护了患者的隐私。

### 6.3 电子商务

在电子商务领域，联邦学习可以帮助电子商务平台实现个性化的推荐系统，提高用户体验和销售额。例如，电商平台可以使用联邦学习算法分析用户的购买行为，为用户推荐他们可能感兴趣的商品。同时，联邦学习确保了用户隐私不受侵犯。

### 6.4 工业互联网

在工业互联网领域，联邦学习可以用于设备监控和故障预测，提高生产效率。例如，工业设备制造商可以使用联邦学习算法分析设备运行数据，以预测设备的故障风险，从而实现预防性维护。联邦学习确保了设备数据的隐私和安全。

### 6.5 未来应用展望

随着联邦学习技术的不断发展和完善，它将在更多领域得到应用。未来，联邦学习有望在以下几个方向取得突破：

- **更高效的数据协作**：联邦学习算法将进一步提高数据协作的效率，实现更快速和更准确的数据分析。
- **更广泛的应用领域**：联邦学习将在金融、医疗、电子商务、工业互联网等更多领域得到应用，推动这些领域的技术创新。
- **更强大的隐私保护**：联邦学习将结合更先进的加密技术和隐私保护算法，实现更强大的数据隐私保护能力。
- **更灵活的架构设计**：联邦学习架构将变得更加灵活，能够适应不同的应用场景和数据类型。

## 7. 工具和资源推荐

### 7.1 学习资源推荐

- **《联邦学习：原理与应用》**：这本书全面介绍了联邦学习的理论基础和应用实践，适合对联邦学习有兴趣的读者。
- **TensorFlow Federated（TFF）官方文档**：TFF 的官方文档提供了丰富的教程和案例，是学习联邦学习开发实践的好资源。

### 7.2 开发工具推荐

- **TensorFlow Federated（TFF）**：TFF 是一个开源的联邦学习框架，支持 TensorFlow，是开发联邦学习应用的首选工具。
- **PyTorch Federated（PyTorch-Fed）**：PyTorch-Fed 是 PyTorch 的联邦学习扩展，为 PyTorch 用户提供了联邦学习支持。

### 7.3 相关论文推荐

- **"Federated Learning: Concept and Application"**：这篇论文详细介绍了联邦学习的概念、优势和挑战，是联邦学习领域的重要文献。
- **"Communication-Efficient Learning of Deep Networks from Decentralized Data"**：这篇论文提出了通信效率高的联邦学习算法，对联邦学习的发展产生了重要影响。

## 8. 总结：未来发展趋势与挑战

### 8.1 研究成果总结

联邦学习作为一种新兴的分布式机器学习技术，已经在多个领域展示了其强大的数据协作与隐私保护能力。通过联邦学习，参与者可以在不共享原始数据的情况下共享数据价值，从而实现更高效的数据分析和应用。同时，联邦学习通过加密技术和差分隐私等手段，有效保护了用户的隐私。

### 8.2 未来发展趋势

随着联邦学习技术的不断发展和完善，未来联邦学习有望在以下几个方向取得突破：

- **更高效的数据协作**：联邦学习算法将进一步提高数据协作的效率，实现更快速和更准确的数据分析。
- **更广泛的应用领域**：联邦学习将在金融、医疗、电子商务、工业互联网等更多领域得到应用，推动这些领域的技术创新。
- **更强大的隐私保护**：联邦学习将结合更先进的加密技术和隐私保护算法，实现更强大的数据隐私保护能力。
- **更灵活的架构设计**：联邦学习架构将变得更加灵活，能够适应不同的应用场景和数据类型。

### 8.3 面临的挑战

尽管联邦学习在数据协作与隐私保护方面具有显著优势，但仍然面临一些挑战：

- **通信成本**：联邦学习需要频繁地在参与者和中心服务器之间传输梯度，这可能会带来较高的通信成本。
- **计算复杂性**：联邦学习算法的复杂度较高，需要一定的计算资源和时间。
- **数据不平衡**：不同参与者拥有不同规模和类型的数据，可能导致数据不平衡，影响联邦学习的性能。

### 8.4 研究展望

未来，联邦学习的研究方向将包括：

- **优化联邦学习算法**：通过改进算法设计，降低通信成本和计算复杂性。
- **增强隐私保护能力**：结合更先进的加密技术和隐私保护算法，提高数据隐私保护能力。
- **适应多样化数据场景**：开发适用于不同数据类型和场景的联邦学习算法。

总之，联邦学习作为一种新兴的分布式机器学习技术，将在未来数据协作与隐私保护领域发挥越来越重要的作用。通过不断的研究和优化，联邦学习有望实现更高效、更安全的数据分析与应用。

## 9. 附录：常见问题与解答

### 9.1 联邦学习与传统分布式学习的区别是什么？

**答案**：联邦学习与传统分布式学习的主要区别在于数据的使用方式。在联邦学习中，参与者不共享原始数据，而是共享学习模型参数的更新（梯度）。而在传统分布式学习中，参与者共享原始数据或预处理后的数据。因此，联邦学习在保护数据隐私方面具有显著优势。

### 9.2 联邦学习中的通信成本如何降低？

**答案**：降低联邦学习中的通信成本可以从以下几个方面进行：

- **梯度压缩**：通过梯度压缩技术，可以减少每次通信的梯度大小，从而降低通信成本。
- **局部训练**：参与者可以在本地进行部分训练，然后只传输模型更新（梯度），而不是整个模型。
- **异步通信**：允许参与者异步发送模型更新，以减少通信冲突和等待时间。

### 9.3 联邦学习中的数据不平衡如何处理？

**答案**：在联邦学习过程中，数据不平衡可能会影响模型的性能。以下是一些处理方法：

- **数据加权**：对数据集进行加权，使每个参与者的数据贡献更加均衡。
- **动态采样**：在迭代过程中动态调整参与者的采样比例，以适应数据变化。
- **混合模型**：结合不同数据类型的模型，以弥补单一模型在数据不平衡情况下的不足。

### 9.4 联邦学习中的隐私保护如何实现？

**答案**：联邦学习中的隐私保护通常通过以下技术手段实现：

- **加密技术**：使用加密算法对数据或模型参数进行加密，确保数据在传输过程中不被窃取。
- **差分隐私**：通过添加随机噪声，使数据集的统计信息无法被追踪，从而保护用户的隐私。
- **联邦学习框架**：使用现有的联邦学习框架（如 TFF、PyTorch-Fed），这些框架通常内置了隐私保护机制。

### 9.5 联邦学习是否适用于所有类型的机器学习任务？

**答案**：联邦学习适用于许多类型的机器学习任务，但并非所有任务。对于需要全局数据集的协同训练任务（如深度神经网络），联邦学习可能不太适用。但对于需要保护隐私或数据的机器学习任务，如个性化推荐系统、图像识别等，联邦学习具有显著优势。

### 9.6 联邦学习的性能如何？

**答案**：联邦学习的性能取决于多个因素，包括算法设计、数据分布、通信带宽和计算资源。在合理的设计和优化下，联邦学习可以在保持较高性能的同时，实现数据隐私保护和分布式计算。然而，在某些情况下，联邦学习的性能可能低于集中式学习，这需要通过优化算法和架构来缓解。

## 参考文献 References

[1] Konečný, J., McMahan, H. B., Yu, F. X., Richtárik, P., Suresh, A. T., & Bacon, D. (2016). Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492.
[2] Li, M., Yu, F., Toderici, G., Hsieh, C. J., Smola, A. J., & Dumitrescu, A. (2017). Communication-efficient distributed machine learning with K-means. Proceedings of the 34th International Conference on Machine Learning, 32, 913-921.
[3] Kairouz, P., McMahan, H. B., Yu, F. X., & Richtárik, P. (2018). The benefits of centralized, decentralized and federated learning. arXiv preprint arXiv:1812.06757.
[4] Liu, H., Wang, X., Wang, H., & Liu, J. (2019). A comprehensive survey on deep learning for healthcare: A transition from traditional machine learning. IEEE Journal of Biomedical and Health Informatics, 23(1), 16-43.
[5] Yang, Q., Huang, B., & Jin, R. (2019). A survey on federated learning: Collaborative machine learning for privacy-preserving and data sharing. Journal of Information Security and Applications, 47, 21-36.

