
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


在互联网行业蓬勃发展的当下，作为开发者需要掌握计算机、网络、数据结构等基础知识，同时具备对性能优化有一定的理解。随着互联网企业的快速发展，公司业务的多样性也越来越复杂，导致程序运行效率的问题逐渐凸显出来。在面试中提升编程能力、改善软件的运行速度、提高效率成为热门话题之一。因此，了解计算机系统结构、并发编程、网络通信、数据库设计与管理等性能优化相关知识对于应聘技术人员非常重要。本文将结合作者多年工作经验及所了解的性能优化相关知识，分享一些面试中常见的问题及相应的解决方案。
# 2.核心概念与联系
## 2.1 并发（Concurrency）
并发是一个很重要的计算机术语，用于描述一个事件或任务的执行过程中可以同时发生多个部分，而不会造成混乱。并发编程就是利用线程和进程的并发性，使得程序具有更好的并行性，从而获得更快的执行速度。
## 2.2 同步（Synchronization）
同步是指多个线程/进程之间控制资源的访问方式。主要包括两个方面：顺序一致性和临界区。
### 2.2.1 顺序一致性（Sequential Consistency）
在顺序一致性模型下，任意时刻都只能有一个线程/进程访问内存。也就是说，如果某个线程/进程要读取共享变量的值，其他线程/进程要修改该值之前，该线程/进程必须先完成上一次的写入操作。顺序一致性模型在一些弱上比较严重，比如读-写依赖，但是，由于其简洁性，具有较好的实时响应时间。
### 2.2.2 临界区（Critical Section）
临界区是一段由两个或多个指令组成的代码，这些指令被称为临界区，其中的指令可能包含读、写、条件判断等操作。只有持有临界区所有权的线程/进程才能访问临界区代码，访问结束后释放临界区的所有权。临界区是一种保护共享资源的方式，它保证了数据完整性。临界区通常通过同步机制实现，如互斥锁、信号量等。
## 2.3 内存（Memory）
内存是计算机用来存储数据的部件，它的容量越大，存储的数据容量就越大。为了提高内存的利用率，计算机会将内存分为若干个大小相同的连续内存块，称为页（Page）。为了方便缓存，操作系统会将内存分为两级，一级缓存和二级缓存。
### 2.3.1 一级缓存（L1 Cache）
L1 Cache 是位于CPU和主存之间的小型缓存，其容量一般为几KB，速度比主存还快。L1 Cache 在取指令阶段的作用是提高CPU的指令处理速度，在写回阶段的作用是减少写回主存的次数。L1 Cache 中的数据实际上都是从主存拷贝过来的，所以一级缓存的数据是最新的。但由于一级缓存的大小限制，一旦数据过期，则需要从主存再次加载。
### 2.3.2 二级缓存（L2 Cache）
L2 Cache 是位于L1 Cache 和主存之间的小型缓存，其容量一般为几十KB。二级缓存是L1 Cache 的补充，比起一级缓存，其容量更大，而且能缓存更多的数据。相比于一级缓存，二级缓存访问延迟更长。不过，因为二级缓存的数量较少，所以目前很多CPU都没有二级缓存。
## 2.4 负载（Load）
负载是指单位时间内系统能够处理的请求个数，这个数字反映了系统的稳定性，良好的负载可以极大地提高系统的处理能力和吞吐量。下面分别介绍常见的两种负载类型：
### 2.4.1 CPU负载（CPU Load）
CPU负载是指单位时间内系统的CPU繁忙程度，一个完全空闲的系统的CPU负载值为0%，一个处理完所有任务的系统的CPU负载值为100%。CPU负载的高低直接影响到系统的整体性能。如果CPU负载过高，说明系统的资源消耗过多，系统需要增加资源以提升处理性能；如果CPU负载过低，则说明系统的资源有剩余，可以适当降低资源用量以提升系统的整体性能。
### 2.4.2 请求负载（Request Load）
请求负载是指单位时间内系统的请求处理速度，该数字直接反映了系统的响应速度。请求负载的高低表明系统当前是否处于流畅状态，系统处于非流畅状态时应该考虑增加服务器硬件配置或调整应用逻辑以提高处理速度。
## 2.5 I/O带宽（I/O Bandwidth）
I/O带宽是指单位时间内系统的输入输出通道的利用率，系统中的I/O设备占用的带宽越高，单位时间内传输的字节数就越多。I/O带宽的高低表明系统当前的磁盘IO压力是否达到了瓶颈，如果达到了瓶颈，则应该考虑增加服务器硬件配置以提高I/O性能。
## 2.6 内存带宽（Memory Bandwidth）
内存带宽是指单位时间内系统的内存访问的速度，内存访问速度越快，单位时间内能传输的数据字节数就越多。内存带宽的高低表明系统的内存访问频率是否达到了瓶颈，如果达到了瓶颈，则应该考虑增加服务器硬件配置以提高内存访问速度。
## 2.7 系统总负载（System Total Load）
系统总负载是指系统总体的负载，包括CPU负载和请求负载。系统总负载的高低表明系统当前的整体处理能力，如果系统总负载过高，则应该考虑增加服务器硬件配置以提高整体处理性能。
# 3.核心算法原理和具体操作步骤以及数学模型公式详细讲解
## 3.1 算法性能分析方法
### 3.1.1 最坏情况分析法 (Worst Case Analysis)
最坏情况分析法用于分析某种算法在最坏情况下的性能。这种方法假设最大化某项性能要求下的最糟糕情况。其基本过程是找出最坏情况输入，然后设计一个方法，使得在最坏情况下，算法的性能不亚于此。分析过程中，需要考虑输入的各种组合及其可能出现的影响。最坏情况分析法对输入规模和数据结构进行假设，仅限于理论分析。
### 3.1.2 平均情况分析法 (Average Case Analysis)
平均情况分析法用于分析某些算法的平均性能。这种方法假设平均情况下某项性能要求下的性能。其基本过程是计算算法在各种输入组合下的性能平均值，并推广到所有可能的输入组合。平均情况分析法对输入规模和数据结构进行假设，仅限于理论分析。
### 3.1.3 比较分析法 (Comparative Analysis)
比较分析法用于对不同算法进行性能比较。这种方法主要基于对算法正确性、时间复杂度、空间复杂度及其他指标的比较。其基本过程是比较不同算法的时间和空间性能，选择更优秀的算法。比较分析法针对具体输入情况进行分析，可给出优化的建议。
### 3.1.4 模拟分析法 (Simulation Analysis)
模拟分析法用于模拟系统在实际运行时的行为，确定系统在不同输入下的性能。这种方法采用实时仿真工具，生成输入，模拟系统在不同输入下的行为，对结果进行统计分析。模拟分析法能够模拟真实环境下系统的性能，验证系统在预测、尚未出现的输入情况下的性能。
### 3.1.5 随机分析法 (Random Analysis)
随机分析法用于评估算法在分布均匀情况下的性能。这种方法构造具有随机性的输入，模拟系统在各类输入下的性能，推导出平均性能。随机分析法对输入的分布和随机性有较强的假设，仅限理论研究。
## 3.2 数据结构与算法
### 3.2.1 数组（Array）
数组是一种线性数据结构，其中存储的数据元素是按顺序排列的一组固定大小的内存位置。数组元素可以通过索引来访问。数组的插入、删除操作涉及移动大量元素，对效率有较大的影响。
#### 插入操作
数组的插入操作涉及移动大量元素，插入前后的数组如下图所示：
#### 删除操作
数组的删除操作涉及移动大量元素，删除前后的数组如下图所示：
### 3.2.2 链表（Linked List）
链表是一种非线性数据结构，它是由一系列节点组成的集合。每个节点包含两个部分：数据和指针。数据存储在节点中，指针指向下一个节点。头节点是一个特别的节点，它只存储数据，没有指针指向下一个节点。尾节点也是一个特别的节点，它只存储指针，指向空地址，表示列表结束。插入和删除操作仅需更改相应节点的指针即可。
### 3.2.3 栈（Stack）
栈是一种线性数据结构，它是一种容器，存放的数据元素有序且后进先出(Last In First Out)。栈顶部的元素是最后加入的元素，并且新加入的元素也只能放在栈顶部。
#### 压栈操作
栈的压栈操作为栈添加一个新元素。当创建一个栈时，系统分配一片内存，并初始化栈底指针top为空。新元素从栈底部进入，当栈满时，操作失败，即栈顶指针已经指向第一个元素，无法继续添加新的元素。压栈操作的时间复杂度为O(1)，即系统只需向内存中添加一个数据。
#### 弹栈操作
栈的弹栈操作删除栈顶元素。弹栈操作首先检查栈是否为空，如果为空，则操作失败。否则，弹栈操作从栈顶删除元素，并返回该元素的值。弹栈操作的时间复杂度为O(1)，即系统只需访问堆栈顶部的元素。
### 3.2.4 队列（Queue）
队列是一种线性数据结构，它是一种容器，存放的数据元素有序且先进先出(First In First Out)。队首的元素是最早进入队列的元素，队尾的元素是最近进入队列的元素。插入操作只能在队尾进行，删除操作只能在队首进行。
#### 入队操作
队列的入队操作在队尾添加一个新元素。入队操作的平均时间复杂度为O(1)，即系统只需往内存中添加一个数据。
#### 出队操作
队列的出队操作删除队首元素。出队操作的平均时间复杂度为O(1)，即系统只需访问队列头部的元素。
### 3.2.5 散列表（Hash Table）
散列表是一种键值对形式的无序结构。它以任意键值对的形式保存数据，键通过哈希函数映射到特定槽位（bucket），槽位存储对应值。插入操作首先计算哈希函数得到的槽位索引，并检查槽位中是否存在已有元素。如果槽位不存在，则插入新元素；如果槽位已有元素，则覆盖旧值。删除操作首先计算哈希函数得到的槽位索引，并搜索槽位中对应的元素，找到后，删除元素。
### 3.2.6 树（Tree）
树是一种抽象数据类型，它是一种用于组织数据结构的框架。它由结点（node）和边（edge）组成，结点可以是任何对象，边表示连接结点的链接关系。树的根节点是唯一的，外层的节点又称为父节点、子节点或者孩子节点，内层节点又称为兄弟节点。
#### 遍历操作
树的遍历操作可以实现对树中元素的访问，如BFS(广度优先搜索)、DFS(深度优先搜索)。遍历树的效率较低，不建议直接使用。
### 3.2.7 排序算法（Sorting Algorithm）
排序算法是用来将一组数据按一定顺序重新排列的方法。常见的排序算法有冒泡排序、选择排序、插入排序、归并排序、快速排序、计数排序、基数排序等。
#### 冒泡排序
冒泡排序算法是一种简单的排序算法。其基本思路是比较相邻的两个元素，如果左边的元素比右边的元素大，则交换他们的位置。重复这一过程，直至不需要交换位置。冒泡排序算法的平均时间复杂度为O(n^2)，最好、最坏、平均时间复杂度一样。
#### 选择排序
选择排序算法是一种简单直观的排序算法。它的基本思路是通过构建有序序列，使得每个元素只出现一次。选择排序算法的平均时间复杂度为O(n^2)，最好、最坏、平均时间复杂度一样。
#### 插入排序
插入排序算法是一种简单直观的排序算法。它的基本思路是每一步将一个元素插入有序序列的适当位置。插入排序算法的平均时间复杂度为O(n^2)，最好、最坏、平均时间复杂度一样。
#### 归并排序
归并排序算法是采用分治策略的排序算法。它的基本思路是先递归地把数组拆分成两个更小的数组，然后再合并两个已排序的数组。归并排序算法的平均时间复杂度为O(nlogn)，最好、最坏、平均时间复杂度一样。
#### 快速排序
快速排序算法是一种对排序过程进行优化的排序算法。它的基本思路是通过选取一个元素，将待排序列分成两个子序列，左边子序列元素值均小于选取的元素值，右边子序列元素值均大于选取的元素值。递归地排序左右子序列，直到子序列长度足够小，开始合并子序列。快速排序算法的平均时间复杂度为O(nlogn)，最好、最坏、平均时间复杂度一样。
#### 计数排序
计数排序算法是一种非比较排序算法，适用于整数排序。它的基本思路是计数，统计待排序列中的每个元素值出现的次数，并根据统计结果建立索引。计数排序算法的平均时间复杂度为O(n+k), k为元素值的范围，最好、最坏、平均时间复杂度一样。
#### 基数排序
基数排序算法是一种非比较排序算法，属于多关键字排序算法。它的基本思路是按照低位优先的顺序来排序，先按照个位进行排序，再按照十位进行排序，依次类推，直至高位。基数排序算法的平均时间复杂度为O(d*(n+r)), d为数组的维度，n为数组中的元素个数，r为基数范围，最好、最坏、平均时间复杂度一样。
## 3.3 操作系统性能分析
### 3.3.1 文件系统
文件系统（File System）是存储信息的一种结构，用于管理文件。文件系统提供对文件进行创建、打开、关闭、读、写、删、查等操作，以及对文件的权限、目录等属性进行控制。文件的读、写、删操作都需要进行系统调用。因此，文件系统的性能直接影响到应用程序的运行效率。
#### 文件读写
文件读写操作需要将数据从磁盘读取到内存，再写入到磁盘，耗费了大量的CPU资源。因此，为了加快文件的读写速度，通常设置缓冲池，在内存中缓存部分文件内容，降低磁盘I/O操作。缓冲池可以根据内存大小、使用频率和文件的大小进行动态调整。另外，可以使用纠错码来检测和纠正磁盘错误，缓解磁盘错误对文件系统性能的影响。
#### 文件操作的并发
文件操作可能会遇到竞争条件，多个进程或线程同时操作同一文件。为了避免冲突，需要引入锁或事务机制。锁可以确保同一时刻只有一个进程或线程可以访问文件，从而避免冲突。事务则可以确保操作成功或者失败，从而确保数据的完整性。
### 3.3.2 内存管理
内存管理是操作系统对内存资源的分配和释放，包括虚拟内存（Virtual Memory）、页面置换算法（Page Replacement Algorithms）、进程调度算法（Process Scheduling Algorithms）等。
#### 虚拟内存
虚拟内存是操作系统提供的一个抽象概念，它是对真实物理内存的一种模拟。它允许多个进程共同申请内存，使得操作系统可以为它们提供一致的可靠的地址空间。同时，它也提供了一种松耦合的程序结构，使得程序的编写、调试和维护变得容易。
#### 页面置换算法
页面置换算法是操作系统用来处理内存碎片问题的一种策略。当系统发现某个进程的内存需要换出时，就会触发页面置换算法。页面置换算法的目的在于减少内存碎片，提高内存的利用率。常见的页面置换算法有最佳适配、先进先出（FIFO）、最近最久未使用（LRU）、最近最少使用（LRU）、时钟（Clock）、抖动（Belady's Anomaly）。
#### 进程调度算法
进程调度算法是操作系统用来决定哪个进程、线程或任务需要访问处理器、磁盘等资源的一种算法。不同的进程调度算法目标不同，但是都会提高系统的吞吐量、减少响应时间、优化系统的资源利用率。常见的进程调度算法有轮转法（Round Robin）、最短作业优先（Shortest Job First）、高响应比优先（Highest Response Ratio Next）、最少损失优先（Least Lost Priority）、批处理（Batch Processing）等。
### 3.3.3 网络性能分析
网络性能分析是计算机网络技术人员对网络功能和效率进行分析，包括链路性能、路由选择算法、数据包处理、拥塞控制、网络安全、QoS支持等方面的内容。
#### 链路性能
链路性能分析主要关注链路的性能指标，包括发送速率、接收速率、丢包率、时延、抖动、吞吐量等。链路性能的差异主要在于网络质量、链路距离、线材损耗、电源问题、网卡驱动程序问题等方面。
#### 路由选择算法
路由选择算法用于在网络上传输数据包，它们涉及到寻址和路径选择。常见的路由选择算法有静态路由、动态路由、BGP动态路由、OSPF、RIP等。
#### 数据包处理
数据包处理是指数据从源点传输到终点，在网络中的过程。数据包处理的关键包括路由选择、分割、重传、发送窗口管理、确认机制、重排序等。数据包处理的性能指标包括时延、抖动、丢包率、重传率、吞吐量等。
#### 拥塞控制
拥塞控制是防止网络拥塞的过程，它试图保持网络畅通、顺利运行。拥塞控制的主要目标是在合理的利用网络资源的前提下，通过限制网络资源的使用，以减轻网络拥堵，提高网络的吞吐量。拥塞控制的手段包括流量控制、滑动窗口协议、拥塞预知、拥塞恢复等。
#### QoS支持
QoS（Quality of Service）是指网络服务质量，它是基于优先级的服务质量保证机制。QoS支持的意义在于让用户获得更好的网络服务。QoS支持主要包括分类、标记、保证、节拍控制等。QoS支持的目标在于保证应用在网络上的高可用性。
### 3.3.4 数据库性能分析
数据库性能分析是指对数据库管理系统（DBMS）性能进行评估、分析和监控，包括索引构建、查询优化、系统负载、锁管理、死锁处理、线程控制、缓冲池、日志管理、性能诊断工具等方面。
#### 索引构建
索引是一种数据结构，它帮助数据库管理系统快速定位数据所在的位置。索引的构建需要消耗额外的系统开销，因此，索引的构建应该进行优化。索引的构建需要考虑到索引的维护成本、索引更新频率、数据分布等因素。
#### 查询优化
查询优化是指根据查询需求、系统资源和数据库设计的特征，优化查询的过程。查询优化有多种方法，包括代价估算、规则引擎、列存和水平分区等。
#### 系统负载
系统负载是指系统中的任务的繁重程度，它反映了系统的处理能力、处理效率和系统的可靠性。系统负载过高，则表示系统的资源分配过度、线程调度不合理，会导致系统的性能急剧下降。
#### 锁管理
锁是操作系统提供的一种基本保护机制，用于同步访问共享资源。锁可以确保并发执行的任务具有正确的执行顺序，从而提高系统的并发度。锁的管理涉及锁的申请、分配、释放、升级、降级等。锁的性能也直接影响到整个系统的性能。
#### 死锁处理
死锁是指两个或多个进程在同一资源上互相等待，相互进一步阻塞的现象。为了避免死锁，系统必须采取一定的死锁预防、死锁检测和死锁超时等机制。死锁处理主要包括资源预留、超时释放、饥饿释放、回滚、资源回退、主从切换等。
#### 线程控制
线程控制是操作系统提供的一种进程调度策略，它可以将任务划分成独立的执行单元，并以调度的方式让这些执行单元按一定顺序执行。线程控制的目标在于避免线程间的相互影响，提高系统的并发度。
#### 消息传递
消息传递是一种通信模式，它依赖消息队列和通道。消息队列是用于存储消息的地方，通道是用于消息的传递。消息传递的性能直接影响到系统的整体性能。
#### 缓冲池
缓冲池是操作系统提供的一种机制，它提供临时存储空间，用于缓冲那些暂时不能立即访问的资源。缓冲池的大小、使用频率和缓冲对象的大小会影响到缓冲池的命中率，从而影响到整个系统的性能。
#### 日志管理
日志管理是操作系统提供的一种机制，用于记录系统运行过程中的信息。日志管理的目的是分析系统运行过程中的异常、故障、错误，从而对系统进行维护和优化。日志管理的目标在于快速定位故障、跟踪系统运行轨迹、提升系统的可靠性。
#### 性能诊断工具
性能诊断工具是用于诊断、监控和优化数据库性能的工具。性能诊断工具的目的在于提升数据库的整体性能，发现系统瓶颈、定位优化的方向和措施。常见的性能诊断工具有Sysbench、TCMalloc、MySQLTuner、Oracle Enterprise Manager、DSTAT、Solaris Studio等。
# 4.具体代码实例和详细解释说明
## 4.1 并发和同步——生产者消费者模式
生产者消费者模式是多线程并发编程中经典的模型。它包含一个生产者（Producer）、多个消费者（Consumer）以及共享资源（Shared Resource）。生产者生产共享资源的消息，消费者消费共享资源的消息。生产者和消费者通过缓冲区（Buffer）进行通信。当缓冲区为空时，生产者等待，当缓冲区满时，消费者等待。生产者和消费者通过一个标识符（Identifier）进行通信。当标识符为0时，消费者获取资源，标识符为n时，生产者释放资源。
```java
class SharedResource {
    private int buffer[];
    private int in; // next available input position for producer
    private int out; // next occupied output position for consumer
    
    public SharedResource() {
        this.buffer = new int[10];
        this.in = 0;
        this.out = 0;
    }
    
    public synchronized void produce() throws InterruptedException {
        while (isFull()) {
            wait();
        }
        
        incrementIn();
        buffer[getIn()] = getInput();
        
        notifyAll();
    }
    
    public synchronized void consume() throws InterruptedException {
        while (isEmpty()) {
            wait();
        }
        
        decrementOut();
        setOutput(buffer[getOut()]);
        
        notifyAll();
    }

    private boolean isFull() {
        return ((in + 1) % buffer.length == out);
    }

    private boolean isEmpty() {
        return (in == out);
    }
    
    private int getIn() {
        return in;
    }

    private void incrementIn() {
        in = (in + 1) % buffer.length;
    }

    private int getOut() {
        return out;
    }

    private void decrementOut() {
        out = (out - 1 + buffer.length) % buffer.length;
    }

    private int getInput() {
        // generate random integer as an example
        Random rand = new Random();
        return rand.nextInt(100);
    }

    private void setOutput(int val) {
        // print the consumed value as an example
        System.out.println("Consumed " + val);
    }
    
}

class Consumer implements Runnable {
    private SharedResource sharedRes;
    
    public Consumer(SharedResource res) {
        this.sharedRes = res;
    }

    @Override
    public void run() {
        try {
            while (true) {
                sharedRes.consume();
            }
        } catch (InterruptedException e) {}
    }
}

class Producer implements Runnable {
    private SharedResource sharedRes;
    private static final int MAX_INPUTS = 1000;
    
    public Producer(SharedResource res) {
        this.sharedRes = res;
    }

    @Override
    public void run() {
        try {
            for (int i = 0; i < MAX_INPUTS; i++) {
                sharedRes.produce();
            }
        } catch (InterruptedException e) {}
    }
}


public class Main {
    public static void main(String[] args) {
        SharedResource sharedRes = new SharedResource();

        Thread cThread = new Thread(new Consumer(sharedRes));
        Thread pThread = new Thread(new Producer(sharedRes));

        cThread.start();
        pThread.start();
    }
}
```
## 4.2 内存管理——内存分配器
内存分配器是操作系统提供的一种机制，用于动态地分配和回收内存。当进程申请内存时，内存分配器返回一个指向空闲内存区域的指针；当进程释放内存时，内存分配器通知内存回收机制将该内存区域归还给操作系统。内存分配器的目标在于减少内存碎片，提高内存的利用率。
```c++
// Simple memory allocator using first fit algorithm

struct Node {
    size_t size;
    bool used;
    struct Node* prev;
    struct Node* next;
};

Node* head;
size_t totalMemSize; // total physical memory size

void initAllocator() {
    std::cout << "Initializing allocator..." << std::endl;
    head = nullptr;
    totalMemSize = sysconf(_SC_PAGESIZE)*sysconf(_SC_PHYS_PAGES);
    std::cout << "Total physical memory: " << totalMemSize << " bytes." << std::endl;
}

void deinitAllocator() {
    std::cout << "Deinitializing allocator..." << std::endl;
    freeAll();
    head = nullptr;
    std::cout << "Done." << std::endl;
}

void* alloc(size_t size) {
    if (!head ||!findFreeBlock(size)) {
        expandHeap(size * sizeof(Node));
    }

    Node* newNode = findFreeBlock(size);
    newNode->used = true;
    splitBlock(newNode, size);

    std::cout << "Allocated block at " << reinterpret_cast<void*>(newNode)
              << ", size " << size << "." << std::endl;

    return &newNode->next; // points to allocated area inside node
}

void free(void* ptr) {
    Node* toBeFreed = reinterpret_cast<Node*>(ptr)-1;

    assert(toBeFreed >= head && toBeFreed <= tail());

    mergeBlocks(toBeFreed);
    toBeFreed->used = false;

    std::cout << "Freed block at " << ptr << "." << std::endl;
}

Node* findFreeBlock(size_t size) const {
    Node* curr = head;

    while (curr!= nullptr) {
        if (!curr->used && curr->size > size) {
            return curr;
        }

        curr = curr->next;
    }

    return nullptr;
}

void splitBlock(Node* n, size_t size) {
    n->next = reinterpret_cast<Node*>(reinterpret_cast<char*>(n)+sizeof(Node)+size);
    n->next->prev = n;
    n->next->size = n->size - size - sizeof(Node);
}

void mergeBlocks(Node* a) {
    auto b = a->next;

    if (&a->next!= &tail()) {
        b->prev->next = b->next;
        b->next->prev = b->prev;
    } else {
        b->prev->next = nullptr;
    }

    delete a;
}

void expandHeap(size_t size) {
    size_t pageSize = sysconf(_SC_PAGESIZE);
    char* newArea = new char[pageSize];
    memset(newArea, '\0', pageSize);

    addNewArea(newArea, size);
}

void addNewArea(char* area, size_t size) {
    size_t blockSize = alignToPageBoundary(size + sizeof(Node));
    Node* newNode = reinterpret_cast<Node*>(area);

    newNode->size = blockSize;
    newNode->used = false;
    newNode->prev = tail()->prev;
    newNode->next = nullptr;

    if (tail()) {
        tail()->prev->next = newNode;
    }

    newNode->prev->next = newNode;
    newNode->next = tail();
}

Node& tail() const {
    return *(--end());
}

auto end() const {
    return std::remove_const_t<decltype(head)>::iterator{};
}

static size_t alignToPageBoundary(size_t sz) {
    return ((sz+(sysconf(_SC_PAGESIZE)-1))/sysconf(_SC_PAGESIZE))*sysconf(_SC_PAGESIZE);
}
```