
作者：禅与计算机程序设计艺术                    

# 1.背景介绍


计算机视觉领域的应用日益广泛，但仅靠工程师自己设计和训练模型无法处理复杂场景下的图像识别任务。近年来，出现了一些通过利用大量已有的预训练模型（Pre-trained models）来解决新类别识别的问题。迁移学习是利用已有的模型对新的任务进行快速训练的方法，其优点在于可以在一定程度上减少训练时间、提高准确率，可以大幅度缩短新任务的开发周期。

随着人工智能技术的发展，机器学习的发展给计算机视觉领域带来了巨大的变革，也促进了机器学习与图像识别领域的交叉融合。目前，深度神经网络（DNNs）、卷积神经网络（CNNs）、循环神经网络（RNNs）及其他深度学习方法已成为解决图像识别问题的有效工具。迁移学习就是利用这些方法所训练好的模型去解决新任务的过程，其基本思想是将源领域的预训练模型的参数复制到目标领域中，然后微调参数以适应目标领域的数据分布。

本文主要介绍迁移学习的基本知识和技术，以及如何通过迁移学习的方式实现图像分类任务。文章首先回顾了迁移学习的相关理论基础和方法，包括线性迁移学习、特征提取器（Feature Extractor）、深度神经网络（DNNs），特征权重迁移、最小化分类误差（Optimization for Classification Error）等。接着，文章详细阐述了迁移学习在图像分类中的具体流程，包括数据集准备、建立一个基于AlexNet的特征提取器、微调AlexNet的最后两个全连接层的参数、微调过程的评价指标和模型效果分析等。最后，通过实际代码示例展示了迁移学习在图像分类任务中的具体应用。

# 2.核心概念与联系
## 2.1 概念
### 2.1.1 迁移学习
迁移学习（Transfer Learning）是机器学习的一个重要分支，它把从某个任务中学到的知识应用到另一个类似的任务中。迁移学习通常用于解决从新类别到旧类别的分类问题。利用已经训练好的模型对新任务进行快速的训练，可以显著地降低训练时间和资源消耗，而且可以取得很好的性能。

例如，将训练过的VGG-16模型应用于新任务时，就可以得到相当不错的效果。训练过的VGG-16模型在ImageNet数据集上预训练完成后，能够识别出不同的对象，并具有高度的抽象概念。因此，VGG-16模型可以非常有效地作为迁移学习的源模型，用来预测新的任务中的图像内容。

迁移学习的基本思想是在源领域（Source Domain）上的模型参数被迁移到目标领域（Target Domain）上。由于源领域和目标领域可能存在着不同的物理属性（如空间位置、光照条件等），所以迁移学习需要考虑到各个领域之间共享不通的特性。迁移学习的典型流程如下图所示。


图1 迁移学习的流程图

迁移学习可以帮助我们在不同的任务中利用相同的知识。通过预训练模型，可以减少我们的时间成本，而且可以达到比较好的结果。但是，迁移学习也存在很多局限性，比如以下几点：

1. 缺乏充足的训练数据：迁移学习依赖于源领域的训练数据，如果源领域的数据不够丰富或者训练样本数量不够多，就会导致模型欠拟合。
2. 模型容量限制：迁移学习会把源模型的参数全部复制到目标领域中，这样会导致目标领域的模型大小变得更大，使得其在内存或计算资源方面有更高的要求。
3. 数据分布差异：迁移学习往往需要对源领域和目标领域的数据分布有所了解，如果数据的分布不同，可能会导致模型性能下降。

### 2.1.2 AlexNet
AlexNet是深度神经网络（DNN）的开山之作。它在深度学习竞赛ImageNet上取得了极好成绩，并成为许多成功的CNN模型的基础。AlexNet由五个模块组成，分别是卷积层、最大池化层、归一化层、全连接层和dropout层。每个模块之间有ReLU激活函数的跳跃连接。

AlexNet在Imagenet数据集上取得了高精度的成果，其中L层（layer）表示第L层，而N表示层的编号。AlexNet共有八层，其中第一层为卷积层，输入为224*224像素，输出为96通道；第二层为最大池化层，输出为65通道；第三层为卷积层，输出为192通道；第四层为最大池化层，输出为192通道；第五层为卷积层，输出为384通道；第六层为卷积层，输出为384通道；第七层为卷积层，输出为256通道；第八层为卷积层，输出为256通道。

AlexNet的特点：

- 采用多个GPU加速训练
- 使用Dropout正则化防止过拟合
- 使用ReLU激活函数
- 每一层都有BN层（Batch Normalization Layer）

### 2.1.3 数据集
#### 2.1.3.1 ImageNet
ImageNet数据集是计算机视觉领域最具代表性的公开数据集，是一个包含1,000种类别的超过一千万张图片的数据集。ImageNet数据集是斯坦福大学、麻省理工学院、南京大学、中科院计算所联合发布的。它的规模已经超越了其他数据集。

ImageNet数据集包含大约一百万张训练图片和一千张验证图片，每张图片均为彩色的。每张图片的尺寸大小都是224*224，颜色空间是RGB。训练集中包含十万至一百万张图片，验证集则包含一千张图片。ImageNet数据集被划分为不同的子集：训练集、验证集、测试集。训练集用于训练模型，验证集用于调整模型的参数，测试集用于最终确定模型的准确度。

#### 2.1.3.2 Caltech-UCSD Birds-200-2011
Caltech-UCSD Birds-200-2011是一个鸟类的图像数据集，包含200个物种，包含约3000张图片。该数据集的生成方式与ImageNet数据集类似，采用224*224的尺寸大小，所有图片都已剪裁成正方形。该数据集用于测试鸟类的分类性能。

## 2.2 方法
### 2.2.1 线性迁移学习
线性迁移学习是迁移学习的一种简单形式，它只是把源模型的最后一层的权重复制到目标模型中，然后再微调一下最后两层的权重。该方法不需要修改模型结构，直接把参数拷贝过去即可。

源模型和目标模型的最后一层的权重需要维度匹配。由于源模型最后一层的权重矩阵的列数较小，所以不能直接拷贝过去，因此需要重新训练目标模型的最后两层。经过目标模型的最后两层微调，可以获得较好的性能。

线性迁移学习的步骤如下：

1. 从源模型中选择最后一层权重，并保存。
2. 在目标模型中定义新的最后两层的权重，维度需要与源模型的最后一层的权重相同。
3. 将源模型的最后一层权重赋值给目标模型的最后两层权重。
4. 对目标模型的最后两层权重进行微调，使其能学习目标任务。

### 2.2.2 特征提取器
特征提取器（Feature Extractor）是迁移学习的一个重要的方法，它可以将源模型的中间层的输出直接映射到目标模型上。一般来说，源模型的中间层包括卷积层、池化层和全连接层。这些层的输出可以直接作为目标模型的输入。特征提取器的目的是保留源模型中有用的信息，而不是完全复制。

特征提取器的两种类型：

1. 共享特征提取器：源模型的中间层输出共享到目标模型中，因此它们可以直接复用。这种方法不需要微调任何参数。
2. 非共享特征提取器：源模型的中间层输出独立于目标模型，因此它们需要单独训练。这种方法需要微调一些参数。

### 2.2.3 深度神经网络
深度神经网络（DNNs）是机器学习的主要方法，被广泛用于图像分类任务。这些模型以多层的方式堆叠节点，每个节点接收前面的某些节点的信息并且产生自己的输出。这使得模型能够学习到不同模式之间的差异。

深度神经网络有很多种形式，包括卷积神经网络（CNNs）、循环神经网络（RNNs）、GANs（Generative Adversarial Networks）。本文将主要讨论迁移学习与图像分类相关的CNNs。

### 2.2.4 特征权重迁移
特征权重迁移（Feature Weight Transfer）是迁移学习中最常用的方法。特征权重迁移通过共享底层的特征提取器，从源模型中获取中间层的权重，然后把它们分配到目标模型的相应层中。一般来说，使用特征权重迁移的方法会比非共享特征提取器的效果要好。

具体地说，步骤如下：

1. 提取源模型的中间层的输出作为特征，并训练一个分类器（classifier）。
2. 把分类器的参数转换成目标模型的对应层的参数。
3. 用目标模型去预测新任务的图像，观察准确率。

### 2.2.5 最小化分类误差
在迁移学习过程中，如何衡量模型在目标任务上的性能，并且使模型知道如何正确迁移权重是迁移学习的关键。一般来说，迁移学习需要满足以下几点：

1. 模型性能：迁移学习需要尽量保证源模型和目标模型的性能尽量接近，这是迁移学习的目的。
2. 权重迁移：迁移学习需要把源模型的权重迁移到目标模型，使其知道如何正确迁移权重。
3. 学习能力：迁移学习应该具备良好的学习能力，能利用源模型的知识进行迁移，并且需要对目标模型的性能有一个追踪记录。

基于以上原因，迁移学习通常采用最小化分类误差的方法。具体地说，为了在源领域和目标领域上最小化分类误差，需要对源模型的参数进行微调，使其在目标领域上能正确分类。

# 3.核心算法原理和具体操作步骤以及数学模型公式详细讲解
## 3.1 迁移学习的理论基础
### 3.1.1 特征提取器
特征提取器是迁移学习中的重要方法。它的基本思想是从源模型的中间层的输出直接映射到目标模型中，因此它们可以直接复用。特征提取器可以使用随机初始化的权重，也可以使用源模型的训练好的参数。

以AlexNet为例，AlexNet的中间层输出分为三类：卷积层、最大池化层、全连接层。卷积层的输出通过ReLU激活函数得到，之后经过最大池化层、归一化层和dropout层得到。全连接层的输出没有经过任何处理，因此可以直接复用。

在迁移学习中，特征提取器的作用是从源模型中提取图像特征，然后将其作为输入送入目标模型中进行分类。

### 3.1.2 微调
微调（Fine Tuning）是迁移学习中的重要方法。它通过调整源模型的最后几个全连接层的参数，让模型针对目标任务做出调整。通常情况下，微调可以获得相当不错的效果。

与特征提取器一样，微调的基本思想也是复用源模型的知识。与特征提取器不同的是，微调不会完全复制源模型的参数，而是通过微调参数来对目标模型进行微调。

在迁移学习中，微调的主要目的是为了在目标任务上优化模型。微调后的模型可以根据新的图像数据进行更新，因此它可以提升性能。

### 3.1.3 迁移学习的损失函数
迁移学习使用最小化分类误差（Loss function）来衡量模型的性能。一般来说，迁移学习使用的损失函数是经验风险最小化。

对于分类问题，经验风险最小化损失函数可以定义为：

$$\mathcal{L}_{CE}=\frac{1}{n}\sum_{i=1}^{n}[\log(p_{\theta}(y^{(i)}|x^{(i)}))+\lambda R(\theta)]+\mu R(\omega), \quad where~\lambda,\mu >0.$$ 

- $[\log(p_{\theta}(y^{(i)}|x^{(i)}))+R(\theta)]$ 表示经验风险（empirical risk）：给定一个样本 $(x^{(i)}, y^{(i)})$ ，模型 $\theta$ 的真实概率是多少？
- $\mu R(\omega)$ 表示正则化项（regularization term）：模型 $\theta$ 和权重 $\omega$ 是不是太复杂？是否有必要减少它们？
- $\lambda R(\theta)$ 表示惩罚项（penalty term）：模型 $\theta$ 是否适合于迁移学习？

总体来说，最小化经验风险与模型适合于迁移学习之间存在一个tradeoff关系。即，复杂的模型可能适合于迁移学习，但同时也会带来更多的训练时间和资源消耗。因此，在选择模型的时候需要考虑速度、资源消耗、准确率之间的平衡。

## 3.2 数据准备
### 3.2.1 ImageNet数据集
ImageNet数据集是计算机视觉领域最具代表性的公开数据集，包含超过一千万张训练图片和一千张验证图片。ImageNet数据集的目录结构如下：

```
└── ILSVRC
    ├── train            # 训练集
    │   ├── n01440764    # 飞机
    │   ├── n01443537    # 卡车
    │   ├──...          #...
    └── val              # 验证集
        ├── n01440764    # 飞机
        ├── n01443537    # 卡车
        ├──...          #...
```

其中，子目录`train`和`val`分别存储了训练集和验证集的文件夹。每个子目录中的文件名对应着ImageNet数据集的类别标签。

ImageNet数据集已经按照类别分割好，因此所有的训练图片都放在对应的子文件夹中。为了方便代码编写，我们还可以将ImageNet数据集按照8:1:1的比例划分为训练集、验证集和测试集。

### 3.2.2 Caltech-UCSD Birds-200-2011数据集
Caltech-UCSD Birds-200-2011是一个鸟类的图像数据集，包含200个物种，包含约3000张图片。该数据集的生成方式与ImageNet数据集类似，采用224*224的尺寸大小，所有图片都已剪裁成正方形。该数据集用于测试鸟类的分类性能。

## 3.3 AlexNet的特征提取器
AlexNet是深度神经网络（DNN）的开山之作。它在ImageNet数据集上取得了极好成绩，并成为许多成功的CNN模型的基础。AlexNet的网络结构如图2所示。


图2 AlexNet的网络结构

AlexNet的卷积层由5个模块组成，包括卷积层、最大池化层、归一化层、全连接层、dropout层。第一个卷积层有96个卷积核，每个卷积核大小为11×11。第二个卷积层有256个卷积核，每个卷积核大小为5×5。第三个卷积层有384个卷积核，每个卷积核大小为3×3。第四个卷积层有384个卷积核，每个卷积核大小为3×3。第五个卷积层有256个卷积核，每个卷积核大小为3×3。

AlexNet的全连接层包括两层，第一层为4096个神经元，第二层为4096个神经元。AlexNet通过全局平均池化层（Global Average Pooling Layer）将每个通道的特征映射归一化到同一尺度，然后通过ReLU激活函数产生输出。

## 3.4 基于AlexNet的迁移学习
AlexNet作为深度神经网络的开山之作，其中间层输出提供了丰富的图像特征。基于AlexNet的迁移学习可以直接复用AlexNet的中间层的输出，而不需要重新设计模型。

### 3.4.1 数据加载器
AlexNet的中间层输出由`features`输出。我们可以通过读取预训练的模型`alexnet`中的权重，然后运行其前向传播来得到中间层的输出。由于AlexNet的输入大小是224*224，所以我们需要对输入图像进行预处理，尤其是在移动端上，进行图像的裁剪和缩放。

```python
import torch
from torchvision import transforms, datasets
from PIL import Image

transform = transforms.Compose([
    transforms.Resize((224, 224)),      # 图片resize到224*224
    transforms.CenterCrop(224),         # 以中心对齐裁剪图片
    transforms.ToTensor(),             # 将图片转为tensor形式
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])   # 归一化图片
])

data_root = '/path/to/dataset'       # 设置数据集路径
trainset = datasets.ImageFolder(os.path.join(data_root, 'train'), transform=transform)        # 创建训练集数据加载器
valset = datasets.ImageFolder(os.path.join(data_root, 'val'), transform=transform)            # 创建验证集数据加载器
testset = datasets.ImageFolder(os.path.join(data_root, 'test'), transform=transform)          # 创建测试集数据加载器
```

### 3.4.2 载入源模型
这里，我们使用开源的PyTorch框架，通过`torchvision.models`加载源模型`alexnet`。

```python
import torchvision.models as models

source_model = models.alexnet()     # 载入源模型
source_model.eval()                # 测试模式
```

### 3.4.3 获取源模型的中间层输出
源模型的中间层输出通过前向传播获取，即调用`forward()`方法。此处，只获取中间层的输出。

```python
def get_source_output():
    with torch.no_grad():           # 不跟踪梯度
        source_outputs = []
        for data in trainloader:
            inputs, labels = data
            outputs = source_model(inputs)[-1]  # 只获取中间层的输出
            source_outputs.append(outputs.cpu())
            
    return torch.cat(source_outputs, dim=0).numpy()
```

### 3.4.4 建立目标模型
在构建目标模型时，不使用源模型的最后两层的权重，而是定义新的全连接层，并且与源模型的中间层的输出进行连接。

```python
class TargetModel(nn.Module):
    def __init__(self):
        super().__init__()

        self.features = nn.Sequential(*list(source_model.children())[:-2])    # 除了最后两层外的所有层
        self.classifier = nn.Linear(in_features=9216, out_features=200)          # 定义新的全连接层

    def forward(self, x):
        output = self.features(x)                    # 获取源模型的中间层输出
        output = output.view(-1, 9216)               # 拉平输出
        output = self.classifier(output)             # 通过新的全连接层分类
        return output

target_model = TargetModel().cuda()                  # 定义目标模型并转到GPU
optimizer = optim.SGD(params=target_model.parameters(), lr=lr, momentum=momentum)  # 创建优化器
criterion = nn.CrossEntropyLoss()                   # 创建损失函数
```

### 3.4.5 微调目标模型
目标模型使用源模型的最后两个全连接层的参数，并微调新定义的全连接层。

```python
for epoch in range(num_epochs):
    print('Epoch {}/{}'.format(epoch+1, num_epochs))
    print('-'*10)
    
    target_model.train()                            # 训练模式
    running_loss = 0.0
    total = len(trainloader)                         # 总样本数
    
    for i, data in enumerate(trainloader, 0):
        # 获取数据
        inputs, labels = data
        
        # 训练模型
        optimizer.zero_grad()                        # 清空梯度
        outputs = target_model(inputs)                # 获取模型输出
        loss = criterion(outputs, labels)             # 计算损失
        loss.backward()                              # 反向传播梯度
        optimizer.step()                             # 更新权重
        
        # 显示日志
        running_loss += loss.item()*inputs.size(0)
        if (i+1)%print_freq == 0:
            avg_loss = running_loss / total
            print('[%d, %5d] loss: %.3f'%(epoch+1, i+1, avg_loss))
            running_loss = 0.0
        
    # 验证模型
    correct = 0
    total = 0
    target_model.eval()                             # 测试模式
    with torch.no_grad():                           # 不跟踪梯度
        for data in testloader:
            images, labels = data                     # 获取数据
            outputs = target_model(images)            # 获取模型输出
            
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
            
    accuracy = float(correct)/float(total)*100.0
    print('Accuracy of the network on the test images: %.2f %%' %accuracy)
```

# 4.具体代码实例
## 4.1 图像分类案例
本节介绍迁移学习的具体应用——图像分类。我们将以迁移学习来解决ImageNet数据集上的鸟类分类问题。

### 4.1.1 数据加载
ImageNet数据集中包含大约一百万张训练图片和一千张验证图片，共有1000个类别。为了方便演示，我们只选取包含两个类别（飞机和鸟类）的数据作为训练集。

```python
import os
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torchvision import transforms, datasets


# 定义数据加载器
def load_data(batch_size):
    data_dir = './data/'                          # 数据集路径
    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])   # 归一化数据
    transform = transforms.Compose([transforms.RandomResizedCrop(224),
                                    transforms.RandomHorizontalFlip(),
                                    transforms.ToTensor(),
                                    normalize])
    
    trainset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)
    valset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform)
    
    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=4)
    valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=4)
    class_names = trainset.classes                      # 获取类别名称列表
    return trainloader, valloader, class_names
```

### 4.1.2 定义AlexNet模型
为了快速演示，我们先使用AlexNet进行特征提取，然后再使用迁移学习进行分类。

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models


# AlexNet模型定义
class AlexNet(nn.Module):
    def __init__(self):
        super(AlexNet, self).__init__()
        model_ft = models.alexnet(pretrained=True)

        self.features = model_ft.features
        self.avgpool = model_ft.avgpool
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, 2)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x


# 定义特征提取器
def feature_extractor(model, device='cuda'):
    """
    提取模型的特征
    :param model: 需要提取特征的模型
    :param device: 指定运行设备
    :return: 返回提取出的特征
    """
    features = list(model.children())[0][:-1]     # 提取除最后一层外的所有层
    model = nn.Sequential(*features)              # 修改模型结构，只提取中间层的输出

    # 切换到指定设备
    model.to(device)
    model.eval()                                  # 评估模式

    # 遍历数据集获取特征
    data_iter = iter(dataloader)                 # 生成迭代器
    first_image = next(data_iter)[0].unsqueeze_(0)   # 获取第一个图像数据
    global feat
    feat = None

    def copy_data(m, i, o):
        nonlocal feat
        feat = o.detach().clone()

    h = layer.register_forward_hook(copy_data)
    with torch.no_grad():                           # 不跟踪梯度
        _ = model(first_image.to(device))
    h.remove()                                      # 删除钩子
    
    return feat                                    # 返回特征


if __name__ == '__main__':
    # 加载数据集
    batch_size = 32
    dataloader, _, class_names = load_data(batch_size)
    
    # 初始化模型
    alexnet = AlexNet()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    alexnet.to(device)
    
    # 特征提取
    img = next(iter(dataloader))[0]
    feature = feature_extractor(alexnet, device)

    # 可视化特征
    plt.imshow(np.transpose(img[0].numpy(), (1, 2, 0)))
    plt.show()

    plt.matshow(feature[0].reshape(6, 6))
    plt.xlabel("Channels")
    plt.ylabel("Features")
    plt.xticks([])
    plt.yticks([])
    plt.title("Feature Map Example")
    plt.colorbar()
    plt.show()
```

### 4.1.3 训练迁移学习模型
由于ImageNet数据集包含多个类别，所以我们只选取飞机和鸟类进行迁移学习。

```python
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import classification_report


# 定义目标模型
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(256, 100)
        self.relu = nn.ReLU(inplace=True)
        self.fc2 = nn.Linear(100, 2)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x
    
    
# 定义分类器
def classifier(model, loader, device='cuda', criterion=None, optimizer=None):
    """
    训练分类器
    :param model: 需要训练的模型
    :param loader: 数据加载器
    :param device: 指定运行设备
    :param criterion: 损失函数
    :param optimizer: 优化器
    :return: 
    """
    if not criterion:
        criterion = nn.CrossEntropyLoss()

    if not optimizer:
        optimizer = optim.Adam(model.parameters(), lr=0.001)

    model.to(device)                                # 移动模型至指定设备
    model.train()                                   # 训练模式

    for e in range(10):
        running_loss = 0.0
        total = 0
        correct = 0
        
        for i, data in enumerate(loader, 0):
            inputs, labels = data

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward + backward + optimize
            outputs = model(inputs.to(device))
            loss = criterion(outputs, labels.to(device))
            loss.backward()
            optimizer.step()

            # 统计指标
            _, pred = torch.max(outputs.data, 1)
            running_loss += loss.item() * inputs.size(0)
            total += labels.size(0)
            correct += (pred == labels.to(device)).sum().item()
        
        # 打印日志
        log = '[{}/{}, step:{}] loss:{:.3f}'.format(e+1, epochs, i+1, running_loss/(len(loader)*batch_size))
        acc = round(100*correct/total, 2)
        log += ', acc:{:.2f}%'.format(acc)
        print(log)

    # 验证模型
    model.eval()                                     # 测试模式
    preds = []                                       # 预测结果列表
    gts = []                                         # 真实标签列表
    
    with torch.no_grad():                               # 不跟踪梯度
        for data in testloader:
            inputs, labels = data
            outputs = model(inputs.to(device))
            
            _, pred = torch.max(outputs, 1)
            gt = labels.tolist()
            pr = pred.tolist()
            
            preds.extend(pr)
            gts.extend(gt)

    # 显示分类报告
    report = classification_report(gts, preds, target_names=class_names)
    print('\nClassification Report:\n')
    print(report)


if __name__ == '__main__':
    # 参数设置
    batch_size = 32
    num_workers = 4
    pin_memory = True
    
    # 加载数据集
    trainloader, valloader, class_names = load_data(batch_size, num_workers, pin_memory)
    testloader = DataLoader(datasets.ImageFolder('./data/test/', 
                                                transform=transforms.Compose([
                                                    transforms.Resize(224),
                                                    transforms.CenterCrop(224),
                                                    transforms.ToTensor(),
                                                    transforms.Normalize(
                                                        mean=[0.485, 0.456, 0.406], 
                                                        std=[0.229, 0.224, 0.225]
                                                    ),
                                                ])
                                            ), 
                            batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=pin_memory)

    # 定义AlexNet模型
    alexnet = AlexNet()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    alexnet.to(device)
    
    # 提取特征
    feature = feature_extractor(alexnet, device)

    # 定义目标模型
    net = Net()
    net.to(device)

    # 训练目标模型
    epochs = 10
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(net.parameters(), lr=0.001)

    # 训练分类器
    classifier(net, trainloader, device, criterion, optimizer)

    # 测试分类器
    classifier(net, testloader, device)
```