                 

# 1.背景介绍


## 分布式文件系统与存储简介
计算机文件系统（File System）是用于管理、组织和存储数据的文件集合，它在现代操作系统中的位置如同指甲刀一般，对存储、检索、共享和保护数据至关重要。当今的应用环境下，各种数据类型的数据量越来越多，单个文件已经无法存储所有信息。因此，人们开始寻找新的解决方案，将大型数据集分割成多个小型文件，并分布存储在不同的服务器上。由于每个文件都存储在独立的物理设备上，因此可以有效地利用存储空间，加快数据搜索和读取速度。分布式文件系统便是这样一种分布式存储技术。
### 分布式文件系统特点
- 数据分布式存储：将数据存储到不同的服务器节点上，提供高可用性。不同节点上的相同数据不会重复存储，使得系统具有良好的容错性。
- 负载均衡调度：根据负载情况自动分配数据块到不同的节点，提升数据的处理效率。
- 动态数据访问：只读或只写操作可以直接在任意节点上进行，无需跨越网段。
- 可扩展性：系统的扩展能力好于传统单机文件系统。
- 数据安全性：文件的存储、传输过程加密，保证数据的完整性。
- 支持海量数据：分布式文件系统不仅支持百亿字节级别的数据，还能应对万亿字节级别的数据。
### 分布式文件系统的应用场景
- 大规模数据集处理：如视频、音频、图像等超大型数据集处理，如Google的MapReduce；
- 在线文档编辑：开源的协作编辑软件Evernote，采用分布式文件系统，降低网络延迟、提升用户体验；
- 数据备份与同步：Hadoop、HDFS、GlusterFS、Ceph，这些分布式文件系统经过多年的发展，已经成为大型数据中心的标配技术；
- 分布式计算平台：Apache Hadoop、Apache Spark，通过分布式文件系统的支持，实现了海量数据的并行计算；
- 移动设备文件共享：Android系统支持通过NFC协议访问外接SD卡，可以通过分布式文件系统实现移动端设备之间的文件共享；
- 其他大数据分析相关业务场景。
## 2.核心概念与联系
### 数据分片
数据分片是指将一个大文件按照一定规则，分割成多个小文件。其中，每一个小文件称之为数据分片（Chunk），具有相同的数据编码方式，但不同的数据块。如下图所示，一个大文件被划分为5个数据分片。
数据分片可以进一步细分为数据块（Data Block）与数据页（Data Page）。数据块是指数据分片中一个连续的区域，通常由8KB至64KB大小。数据页是指数据块中的一组连续的字节，通常为1KB或2KB。如下图所示，一个数据块中包含三个数据页。
### 数据冗余与副本
数据冗余是指对数据进行备份而非简单地存档。数据冗余可以降低数据损坏的风险，提高数据可靠性。例如，在不同磁盘阵列之间设置备份，或者在数据中心设置多台机器作为备份。
数据副本是在多个节点上存储相同数据的多个拷贝。副本数量越多，就越有助于抵御各种异常，提高系统可靠性。但同时也增加了存储开销，因此需要合理配置副本数量。
### 文件系统的层次结构
文件系统一般分为三层：最底层为磁盘驱动器，中间层为文件系统，最上层为应用程序接口（API）。如下图所示：
文件系统层次结构的设计目标包括：
- 提供高性能：文件系统层次结构的各层职责分明，性能较高。
- 提供易用性：接口友好，易于学习和使用，开发人员能够快速上手。
- 方便维护：各层功能模块化，容易维护和升级。
- 防止错误：保障数据一致性、可靠性及数据安全性。
### 名字节点
名字节点（Name Node）是 Hadoop 中心组件，它负责管理文件系统的命名空间。文件系统的命名空间是一个树状结构，树顶部是“/”，表示根目录；树的内部节点表示目录，树的叶子结点则表示文件。
名字节点主要负责两个工作：
- 文件名与块 ID 的映射表：名字节点记录着文件名与块 ID 的对应关系，并负责维护数据块分布信息。
- 锁管理：控制对文件的并发访问，确保数据的一致性。
### 数据节点
数据节点（DataNode）是 Hadoop 集群中的存储节点，它负责存储实际的数据块。每个数据节点可以存储多块数据，并负责数据块的读写操作。
数据节点主要负责以下几个方面：
- 数据存储：主要负责数据的存储，并保证数据块的完整性。
- 数据传输：主要负责向其它数据节点转移数据块。
- 数据复制：如果数据节点损坏或丢失，则可以从其它数据节点复制数据。
- 数据块定位：数据节点定期向名字节点发送心跳包，告诉名字节点自己的存在。
- 失败检测：检测数据节点是否发生故障，及时通知名字节点。
## 3.核心算法原理和具体操作步骤以及数学模型公式详细讲解
### 分布式文件系统概念及原理
在分布式文件系统中，客户端首先连接到主节点（NameNode）获取文件元信息，然后根据元信息获取数据块（Block）的位置列表，再从相应的数据节点（DataNode）上下载数据块，最后合并得到整个文件的原始数据。
#### 分布式文件系统原理图示
#### 文件上传流程
客户端上传文件到主节点后，主节点首先验证该文件是否符合规范，然后生成唯一的文件标识符（fid），再将文件切割成固定大小的 Block，再对 Block 进行编号，并记录 Block 的位置。最后，主节点将每个 Block 的元数据信息写入 NameNode 的元数据库中。
#### 文件下载流程
客户端查询 NameNode 获取文件元信息，根据元信息获取数据块（Block）的位置列表，然后从对应的 DataNode 上下载数据块，最后将多个数据块组合成原始文件。
#### 数据块合并与块寻址
数据块合并的目的是为了减少网络带宽占用，避免向多个节点发送请求。块寻址的目的是定位数据块所在的数据节点，以完成数据的读写操作。
### 数据块定位
数据块定位是指在 HDFS 集群中找到特定数据块的所在位置。HDFS 中的数据块大小默认为 128M，并且每个块都会给出多个副本，这些副本分布在多个节点上。文件上传时，NameNode 会为每一个数据块分配多个副本，这些副本均匀分布在 Hadoop 集群的所有 DataNode 节点上。当客户端要从某个数据块读取数据时，它可以直接从任何一个副本上读取。如果某些副本出现故障，NameNode 可以通过心跳机制来发现它们并重新分布数据块。
#### 数据块定位方式
HDFS 使用两种方式定位数据块：一种是根据文件名查找，另一种是根据块 ID 查找。
##### 根据文件名查找
当客户端通过文件路径访问文件时，客户端首先会解析出文件名，然后询问 NameNode 获取文件的元信息。元信息中包括文件的所有数据块的标识符（Block IDs）。客户端首先从其缓存中查找元信息，若没有找到，则向 NameNode 发起 RPC 请求，NameNode 返回当前文件的所有数据块标识符。客户端从这些数据块标识符中选取其中一个，请求对应的 DataNode 上的元数据。DataNode 返回数据块所在的数据节点的地址列表，客户端随机选择一个地址，再连接这个 DataNode，并向它发送读取数据块的命令。当接收到数据块后，客户端校验数据块的完整性，将数据块的内容缓存起来。
##### 根据块 ID 查找
当客户端需要从某个数据块中读取数据时，它会先查看本地缓存中是否有该数据块的副本。若没有，则向 NameNode 查询该数据块的位置。NameNode 返回数据块所在的数据节点的地址列表，客户端随机选择一个地址，再连接这个 DataNode，并向它发送读取数据块的命令。当接收到数据块后，客户端校验数据块的完整性，将数据块的内容缓存起来。
### 文件分块策略
在分布式文件系统中，文件上传前需要对文件进行分块，然后每个块分配多个副本，分布到集群的所有 DataNode 节点上。文件分块的目的是为了方便将文件划分成固定大小的块，方便数据块的管理与复制。HDFS 使用默认的块大小为 128M。块大小可以由用户自己定义，但建议不要太小，因为这会导致产生很多的小块，浪费网络资源；块大小也不能太大，因为这会影响文件的平均大小，影响磁盘使用效率。
HDFS 支持两种文件分块策略：
- 固定块大小策略：每次创建一个新的块时，分配指定大小的块，直到达到预设值。该策略提供了最简单的切分策略，缺点是可能会创建大量小块，导致产生很多垃圾，浪费存储空间。
- 内存中块计算策略：以内存中的数据为单位，对文件计算哈希值，每次计算哈希值的间隔也是固定的。内存中块计算策略不需要建立磁盘块，可以节省存储空间。但是，这种方法每次都需要计算整个文件，不能充分利用文件系统的缓存机制。
#### 文件上传过程
文件上传到 HDFS 时，NameNode 对文件进行分块，并为每个块分配多个副本。假设文件上传者指定分块大小为 1MB，则一次上传的文件为多个 1MB 的块，并为每个块分配多个副本。块的分配方式如下：
- 每个 DataNode 节点会存储一定数量的块（默认为 3 个），当新加入的块超过此限制时，NameNode 将移除某些老块，腾出空间容纳新块。
- 当客户端向 HDFS 集群上传文件时，除去文件头尾两块以外，所有的块都有相同的副本数量。除此之外，还有一些热点块，这些块距离最后访问时间较近，具有更高的优先级。
- 每个块都有一个唯一的编号，叫做 blockId。blockId 是文件在 HDFS 中以数字形式表示的偏移量，即 blockId=offset/128MB。
- 每个 DataNode 节点都有一个唯一的节点名称（Node ID），用于标识自身。
- 每个块在磁盘上以文件形式存储，命名格式为 blk_xxxxxx，其中 x 表示 blockId 的十六进制字符串。
- 每个块都会保存其块大小、块 ID、块在 HDFS 中的位置（包括主机名、端口号）、存储模式（本地还是远程）、创建时间、最后修改时间、块副本的个数等元数据信息。
#### 文件读取过程
当客户端需要读取某个文件时，首先检查本地缓存中是否有该文件的最新版本，若没有，则向 NameNode 获取该文件的最新版本的元信息，然后从 MetaTree 中找到对应的 DataNode 的地址列表，随机选择其中一个 DataNode，打开该文件的 TCP 连接，并发送读取命令。DataNode 返回文件中某个数据块的内容，客户端接收数据，然后校验数据块的完整性。当收到文件的所有数据块的内容后，客户端合并成原始文件。
### 文件拆分策略
文件拆分策略是指当一个文件太大时，如何拆分成多个小文件。HDFS 使用两种文件拆分策略：
- 按时间戳拆分策略：在客户端上传文件时，先将文件切割成固定大小的 Block，再对 Block 进行编号，编号的方法是按照文件创建时间戳进行排序。
- 自定义拆分策略：可以在客户端上传文件时指定每个 Block 的大小和副本数量。
#### 文件拆分过程
客户端上传文件到 HDFS 时，如果文件太大，就会根据拆分策略进行文件拆分。假设文件上传者指定每个 Block 的大小为 1GB，副本数量为 3，则一次上传的文件会被拆分为多个 1GB 的块，并为每个块分配多个副本。如果文件包含 N 个块，则 N/(3+1)=X，其中 X 为整数。那么第一个块会有 X+1 个副本，第二个块会有 X 个副本，依次类推。除了第一个块之外，其他每个块都会有 3 个副本。
#### 文件下载过程
当客户端需要下载某个文件时，首先向 NameNode 获取该文件的最新版本的元信息，然后从 MetaTree 中找到对应的 DataNode 的地址列表，随机选择其中一个 DataNode，打开该文件的 TCP 连接，并发送下载命令。DataNode 发送文件中某个数据块的内容，客户端接收数据，然后校验数据块的完整性。当收到文件的所有数据块的内容后，客户端合并成原始文件。
### 数据备份与恢复策略
HDFS 在数据存储时，将文件数据以块（block）的方式存储，每个块有多个副本，块的位置分布在集群的所有 DataNode 上。HDFS 通过一个称为 JPS（Journaling Persistent Storage）的机制，实现数据备份与恢复策略。
JPS 把文件的操作记录称为事务（transaction），并记录在日志文件中。日志文件的最大长度为 128MB，日志文件按时间顺序写入磁盘。当数据节点发生崩溃或重启时，会把日志文件中的事务记录回放到数据节点，从而恢复数据的一致性。
#### 数据备份
在 HDFS 中，每个文件都有多个副本，一个数据块的多个副本分布在集群的所有 DataNode 节点上，数据备份策略就是在多个数据节点上保存数据块的多个副本，避免数据丢失。HDFS 支持两种数据备份策略：
- 标准备份：一个数据块的多个副本分布在不同的磁盘阵列上。当磁盘发生损坏时，数据块仍然可以保持可用性。
- EC（Erasure Coding）：将数据块的多个副本分别编码，然后一起存储。当某个磁盘出现故障时，可以自动从剩余的数据块中重新构建数据。
#### 数据恢复
当发生数据丢失时，HDFS 可以通过日志文件中的事务记录恢复数据的一致性。HDFS 存储每个文件的数据块信息，包括每个块的编号、块大小、数据节点列表等，包括块的创建时间、最后修改时间等，当发生数据丢失时，HDFS 可以通过日志文件中的事务记录恢复数据块的创建时间、最后修改时间等信息，并通过块的大小、块编号等信息判断出丢失的数据块，然后向数据节点发送指令，请求其进行数据恢复。
### 数据安全性
HDFS 使用基于 Token 的权限认证机制，对客户端的操作进行授权。HDFS 中的每个用户都有一个 Token，Token 是通过用户名和密码对用户身份进行认证之后生成的一串随机字符，每个 Token 的有效期默认为 7 小时，客户端必须在有效期内才可以使用 Token 来访问 HDFS。
HDFS 使用 Kerberos 协议支持跨域用户的认证。Kerberos 服务部署在 Hadoop 集群的每一个节点，并对客户端的请求进行响应，生成 Ticket，Ticket 是针对客户端认证的票据，票据中包含用户的凭证，包括 UID 和 GID。当客户端访问 HDFS 时，客户端携带 Ticket 向 HDFS 节点请求服务。HDFS 节点通过 Ticket 中包含的 UID 和 GID 进行用户认证，认证成功后才能访问文件。HDFS 不支持匿名访问。
HDFS 默认不支持用户数据完全加密，但可以通过安装第三方安全工具来实现加密。HDFS 支持 HDFS 数据块的访问控制列表（ACLs）来控制对文件的访问权限。HDFS ACLs 有三个级别：
- 用户级 ACLs：允许用户访问文件。
- 组级 ACLs：允许群组访问文件。
- 其他人 ACLs：允许其他用户访问文件。
HDFS ACLs 的继承性非常强，父目录的 ACLs 被继承到子目录。
## 4.具体代码实例和详细解释说明
### 安装配置 Hadoop 集群
这里以 CentOS 7 操作系统为例，配置两台 CentOS 7 服务器，分别作为 NameNode、DataNode、Yarn ResourceManager、Yarn NodeManager、Zookeeper 节点。具体步骤如下：
1. 安装 Java JDK，配置 JAVA_HOME 环境变量。
```bash
sudo yum install java-1.8.0-openjdk -y
export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_8.x86_64
echo "export JAVA_HOME=$JAVA_HOME" >> ~/.bashrc && source ~/.bashrc
```
2. 配置 Maven，配置 MAVEN_HOME 环境变量。
```bash
sudo yum install maven -y
export MAVEN_HOME=/usr/share/maven
echo "export MAVEN_HOME=$MAVEN_HOME" >> ~/.bashrc && source ~/.bashrc
```
3. 下载 Hadoop 源码包。
```bash
wget https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
tar zxvf hadoop-3.3.0.tar.gz
cd hadoop-3.3.0
```
4. 修改配置文件 core-site.xml。
```xml
<configuration>
    <property>
        <name>fs.default.name</name>
        <value>hdfs://namenode:9000/</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/hadoop/temp</value>
    </property>
</configuration>
```
5. 修改配置文件 hdfs-site.xml。
```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.nameservices</name>
        <value>mycluster</value>
    </property>
    <property>
        <name>dfs.ha.namenodes.mycluster</name>
        <value>nn1,nn2</value>
    </property>
    <property>
        <name>dfs.namenode.shared.edits.dir</name>
        <value>qjournal://zk1:2181,zk2:2181,zk3:2181/mycluster</value>
    </property>
    <property>
        <name>dfs.client.failover.proxy.provider.mycluster</name>
        <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>
    <!-- 指定 HA 的 journal node -->
    <property>
        <name>dfs.ha.automatic-failover.enabled</name>
        <value>true</value>
    </property>

    <property>
        <name>dfs.ha.fencing.methods</name>
        <value>sshfence</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mycluster.nn1</name>
        <value>namenode1:50070</value>
    </property>
    <property>
        <name>dfs.namenode.http-address.mycluster.nn2</name>
        <value>namenode2:50070</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mycluster.nn1</name>
        <value>namenode1:8020</value>
    </property>
    <property>
        <name>dfs.namenode.rpc-address.mycluster.nn2</name>
        <value>namenode2:8020</value>
    </property>
</configuration>
```
6. 创建 Zookeeper 目录。
```bash
sudo mkdir /var/lib/zookeeper
sudo chown zookeeper:zookeeper /var/lib/zookeeper
```
7. 配置 Zookeeper。
```bash
cp conf/zoo_sample.cfg conf/zoo.cfg
sed -i '/dataDir/d' conf/zoo.cfg
echo 'dataDir=/var/lib/zookeeper' >> conf/zoo.cfg
```
8. 设置免密登录。
```bash
su root
ssh-keygen -t rsa
cat.ssh/id_rsa.pub > authorized_keys
exit
chmod a-w /etc/ssh
```
9. 分别启动 NameNode 和 DataNode。
```bash
sbin/start-dfs.sh
sbin/start-yarn.sh
```
10. 浏览器访问 http://namenode:50070 ，确认 Hadoop 是否正常运行。

### Hadoop 命令行操作
#### ls
显示文件系统中文件和目录的信息。
语法：
```bash
hdfs dfs [-ls] [-h] [-R] <path>...
```
参数说明：
- `-l`：以详细信息方式显示文件或目录的属性。
- `-h`：以人类可读的方式显示文件大小。
- `-R`：递归打印输出子目录。

示例：
```bash
# 显示当前目录下的所有文件和目录信息
hdfs dfs -ls /

# 显示指定目录下的文件和目录信息
hdfs dfs -ls /user/root

# 以人类可读的方式显示文件大小
hdfs dfs -h -ls /user/root

# 递归打印输出子目录
hdfs dfs -R -ls /user/root
```
#### touch
创建空文件或更新已存在的文件的时间戳。
语法：
```bash
hdfs dfs [-touchz] <paths>...
```
参数说明：
- `-touchz`：只创建文件，且文件内容为空。

示例：
```bash
# 创建空文件或更新已存在的文件的时间戳
hdfs dfs -touchz file1.txt
```
#### get
从 HDFS 下载文件到本地。
语法：
```bash
hdfs dfs [-get [-p]] [-f] [-t <timestamp>] <src>... <localdst>
```
参数说明：
- `-p`：保留原文件的所有权和权限。
- `-f`：强制覆盖本地文件。
- `-t <timestamp>`：指定下载文件的时间戳，以 Unix 时间戳方式。

示例：
```bash
# 从 HDFS 下载文件到本地
hdfs dfs -get /file1.txt ~/Desktop/file1.txt

# 下载 HDFS 目录到本地
hdfs dfs -get /user/root ~/Desktop/user/root

# 保留原文件的所有权和权限
hdfs dfs -get -p /file1.txt ~/Desktop/file1.txt

# 强制覆盖本地文件
hdfs dfs -get -f /file1.txt ~/Desktop/file1.txt

# 指定下载文件的时间戳
hdfs dfs -get -t 1565161200000 /file1.txt ~/Desktop/file1.txt
```
#### put
上传本地文件到 HDFS。
语法：
```bash
hdfs dfs [-put [-p]] [-f] [-l] [-d] <localsrc>... <dst>
```
参数说明：
- `-p`：保留原文件的所有权和权限。
- `-f`：强制覆盖 HDFS 文件。
- `-l`：创建硬链接。
- `-d`：创建目录。

示例：
```bash
# 上传本地文件到 HDFS
hdfs dfs -put ~/Desktop/file1.txt /file1.txt

# 上传本地目录到 HDFS
hdfs dfs -put ~/Desktop/user/root /user/root

# 保留原文件的所有权和权限
hdfs dfs -put -p ~/Desktop/file1.txt /file1.txt

# 强制覆盖 HDFS 文件
hdfs dfs -put -f ~/Desktop/file1.txt /file1.txt

# 创建硬链接
hdfs dfs -put -l ~/Desktop/file1.txt /link1.txt

# 创建目录
hdfs dfs -mkdir /test/dir
```
#### cat
查看文件的内容。
语法：
```bash
hdfs dfs [-cat [-ignoreCrc]] <src>...
```
参数说明：
- `-ignoreCrc`：忽略 CRC 校验错误。

示例：
```bash
# 查看文件的内容
hdfs dfs -cat /file1.txt
```
#### head
查看文件开始的几行。
语法：
```bash
hdfs dfs [-head [-n lines]] <src>...
```
参数说明：
- `-n lines`：指定要查看的行数。

示例：
```bash
# 查看文件开始的几行
hdfs dfs -head -n 5 /file1.txt
```
#### tail
查看文件结尾的几行。
语法：
```bash
hdfs dfs [-tail [-f]] [-n lines] <src>...
```
参数说明：
- `-f`：跟随实时增长输出。
- `-n lines`：指定要查看的行数。

示例：
```bash
# 查看文件结尾的几行
hdfs dfs -tail -n 5 /file1.txt

# 跟随实时增长输出
hdfs dfs -tail -f /file1.txt
```
#### du
显示指定路径的大小。
语法：
```bash
hdfs dfs [-du] [-s] [-h] <path>...
```
参数说明：
- `-s`：显示指定路径总大小。
- `-h`：以人类可读的方式显示大小。

示例：
```bash
# 显示指定路径的大小
hdfs dfs -du /user/root

# 显示指定路径总大小
hdfs dfs -du -s /user/root

# 以人类可读的方式显示大小
hdfs dfs -du -h /user/root
```
#### chmod
更改文件或目录的权限。
语法：
```bash
hdfs dfs [-chmod [<MODE> |ugo=<USER>:<GROUP>][:[-r][-w][-xs]]] <paths>...
```
参数说明：
- `<MODE>`：八进制表示的文件权限，如 `777`。
- `u`、`g`、`o`：表示用户、组、其他用户。
- `-`：表示无权限。
- `r`、`w`、`x`：表示可读、可写、可执行权限。

示例：
```bash
# 更改文件或目录的权限
hdfs dfs -chmod g+rw /file1.txt

# 更改目录权限
hdfs dfs -chmod 777 /user/root

# 添加权限
hdfs dfs -chmod o+rx /file1.txt

# 删除权限
hdfs dfs -chmod u-x /file1.txt
```
#### chown
更改文件或目录的拥有者和组。
语法：
```bash
hdfs dfs [-chown [OWNER][:[GROUP]] <paths>...
```
参数说明：
- `[OWNER]`：更改文件或目录的拥有者。
- `[[GROUP]]`：更改文件或目录的所属组。

示例：
```bash
# 更改文件或目录的拥有者和组
hdfs dfs -chown user:group /file1.txt

# 只更改文件或目录的拥有者
hdfs dfs -chown user /file1.txt
```
#### df
显示 HDFS 中各个数据节点的使用状态。
语法：
```bash
hdfs dfs [-df [-h]] [<path>...]
```
参数说明：
- `-h`：以人类可读的方式显示大小。

示例：
```bash
# 显示 HDFS 中各个数据节点的使用状态
hdfs dfs -df
```
#### count
显示文件个数和总大小。
语法：
```bash
hdfs dfs [-count [-q] [-h] <path>...
```
参数说明：
- `-q`：只显示总大小。
- `-h`：以人类可读的方式显示大小。

示例：
```bash
# 显示文件个数和总大小
hdfs dfs -count -q /user/root

# 以人类可读的方式显示大小
hdfs dfs -count -q -h /user/root
```
#### rm
删除文件或目录。
语法：
```bash
hdfs dfs [-rm [-skipTrash] [-r|-R] [-f] <src>...]
```
参数说明：
- `-skipTrash`：不经过 Trash 回收站。
- `-r`：递归删除目录。
- `-R`：递归删除目录及其子目录。
- `-f`：强制删除文件。

示例：
```bash
# 删除文件
hdfs dfs -rm /file1.txt

# 递归删除目录及其子目录
hdfs dfs -rm -R /user/root

# 强制删除文件
hdfs dfs -rm -f /file1.txt

# 不经过 Trash 回收站
hdfs dfs -rm -skipTrash /file1.txt
```
#### rmr
删除文件或目录。
语法：
```bash
hdfs dfs [-rmr [-skipTrash] <src>...]
```
参数说明：
- `-skipTrash`：不经过 Trash 回收站。

示例：
```bash
# 删除文件
hdfs dfs -rmr /file1.txt

# 不经过 Trash 回收站
hdfs dfs -rmr -skipTrash /file1.txt
```